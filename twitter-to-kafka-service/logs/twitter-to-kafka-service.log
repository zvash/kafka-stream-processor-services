2023-03-04 00:00:30 [SpringApplicationShutdownHook] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Closing kafka producer!
2023-03-04 00:00:30 [kafka-admin-client-thread | adminclient-1] INFO  o.a.kafka.common.utils.AppInfoParser - App info kafka.admin.client for adminclient-1 unregistered
2023-03-04 00:00:30 [kafka-admin-client-thread | adminclient-1] INFO  o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2023-03-04 00:00:30 [kafka-admin-client-thread | adminclient-1] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2023-03-04 00:00:30 [kafka-admin-client-thread | adminclient-1] INFO  o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2023-03-04 00:02:18 [main] INFO  x.g.m.d.t.t.k.s.TwitterToKafkaServiceApplication - Starting TwitterToKafkaServiceApplication using Java 17.0.6 with PID 29184 (/Users/admin/Documents/EventDeriventMicroservices/microservices-demo/twitter-to-kafka-service/target/classes started by admin in /Users/admin/Documents/EventDeriventMicroservices/microservices-demo)
2023-03-04 00:02:18 [main] INFO  x.g.m.d.t.t.k.s.TwitterToKafkaServiceApplication - No active profile set, falling back to 1 default profile: "default"
2023-03-04 00:02:18 [main] WARN  o.s.c.a.AnnotationTypeMapping - Support for convention-based annotation attribute overrides is deprecated and will be removed in Spring Framework 6.1. Please annotate the following attributes in @org.springframework.retry.annotation.EnableRetry with appropriate @AliasFor declarations: [proxyTargetClass]
2023-03-04 00:02:19 [main] INFO  o.a.k.c.admin.AdminClientConfig - AdminClientConfig values: 
	bootstrap.servers = [localhost:19092, localhost:29092, localhost:39092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2023-03-04 00:02:19 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.3.2
2023-03-04 00:02:19 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: b66af662e61082cb
2023-03-04 00:02:19 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1677875539556
2023-03-04 00:02:19 [main] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - <<<<<DEFAULT TOPIC: org.springframework.kafka.core.KafkaTemplate@f1dd5b4>>>>>>>
2023-03-04 00:02:20 [main] INFO  o.s.b.w.e.netty.NettyWebServer - Netty started on port 8080
2023-03-04 00:02:20 [main] INFO  x.g.m.d.t.t.k.s.TwitterToKafkaServiceApplication - Started TwitterToKafkaServiceApplication in 2.269 seconds (process running for 3.261)
2023-03-04 00:02:20 [main] INFO  x.g.m.d.t.t.k.s.TwitterToKafkaServiceApplication - Application started!
2023-03-04 00:02:20 [main] INFO  x.g.m.d.k.a.client.KafkaAdminClient - Creating 1 topic(s), attempt 0
2023-03-04 00:02:20 [main] INFO  x.g.m.d.k.a.client.KafkaAdminClient - Reading kafka topic [twitter-topic], attempt 0
2023-03-04 00:02:20 [main] INFO  x.g.m.d.t.t.k.s.i.i.KafkaStreamInitializer - Topics with name twitter-topic is ready for operations.
2023-03-04 00:02:20 [main] INFO  x.g.m.d.t.t.k.s.r.i.MockKafkaStreamRunner - Start to mock twitter stream for keywords: [Java, Microservices, Spring, Kafka, Elasticsearch]
2023-03-04 00:02:20 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text lacinia arcu non lacinia ante dictum sed metus Java non feugiat sed metus at ante a sending to kafka topic twitter-topic
2023-03-04 00:02:20 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 1429034567672930907, "id": 8807256837653234157, "text": "lacinia arcu non lacinia ante dictum sed metus Java non feugiat sed metus at ante a", "createdAt": 1677875540000}' to topic = 'twitter-topic'
2023-03-04 00:02:20 [pool-3-thread-1] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = -1
	batch.size = 1638400
	bootstrap.servers = [localhost:19092, localhost:29092, localhost:39092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = snappy
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.LongSerializer
	linger.ms = 5
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 60000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer

2023-03-04 00:02:21 [pool-3-thread-1] INFO  o.a.k.clients.producer.KafkaProducer - [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 0 ms.
2023-03-04 00:02:21 [pool-3-thread-1] INFO  o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2023-03-04 00:02:21 [pool-3-thread-1] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2023-03-04 00:02:21 [pool-3-thread-1] INFO  o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2023-03-04 00:02:21 [pool-3-thread-1] INFO  o.a.kafka.common.utils.AppInfoParser - App info kafka.producer for producer-1 unregistered
2023-03-04 00:05:39 [SpringApplicationShutdownHook] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Closing kafka producer!
2023-03-04 00:05:39 [kafka-admin-client-thread | adminclient-1] INFO  o.a.kafka.common.utils.AppInfoParser - App info kafka.admin.client for adminclient-1 unregistered
2023-03-04 00:05:39 [kafka-admin-client-thread | adminclient-1] INFO  o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2023-03-04 00:05:39 [kafka-admin-client-thread | adminclient-1] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2023-03-04 00:05:39 [kafka-admin-client-thread | adminclient-1] INFO  o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2023-03-04 00:05:56 [main] INFO  x.g.m.d.t.t.k.s.TwitterToKafkaServiceApplication - Starting TwitterToKafkaServiceApplication using Java 17.0.6 with PID 31422 (/Users/admin/Documents/EventDeriventMicroservices/microservices-demo/twitter-to-kafka-service/target/classes started by admin in /Users/admin/Documents/EventDeriventMicroservices/microservices-demo)
2023-03-04 00:05:56 [main] INFO  x.g.m.d.t.t.k.s.TwitterToKafkaServiceApplication - No active profile set, falling back to 1 default profile: "default"
2023-03-04 00:05:56 [main] WARN  o.s.c.a.AnnotationTypeMapping - Support for convention-based annotation attribute overrides is deprecated and will be removed in Spring Framework 6.1. Please annotate the following attributes in @org.springframework.retry.annotation.EnableRetry with appropriate @AliasFor declarations: [proxyTargetClass]
2023-03-04 00:05:57 [main] INFO  o.a.k.c.admin.AdminClientConfig - AdminClientConfig values: 
	bootstrap.servers = [localhost:19092, localhost:29092, localhost:39092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2023-03-04 00:05:57 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.3.2
2023-03-04 00:05:57 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: b66af662e61082cb
2023-03-04 00:05:57 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1677875757783
2023-03-04 00:05:58 [main] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - <<<<<DEFAULT TOPIC: org.springframework.kafka.core.KafkaTemplate@6dc9da2d>>>>>>>
2023-03-04 00:05:58 [main] INFO  o.s.b.w.e.netty.NettyWebServer - Netty started on port 8080
2023-03-04 00:05:58 [main] INFO  x.g.m.d.t.t.k.s.TwitterToKafkaServiceApplication - Started TwitterToKafkaServiceApplication in 2.226 seconds (process running for 3.092)
2023-03-04 00:05:58 [main] INFO  x.g.m.d.t.t.k.s.TwitterToKafkaServiceApplication - Application started!
2023-03-04 00:05:58 [main] INFO  x.g.m.d.k.a.client.KafkaAdminClient - Creating 1 topic(s), attempt 0
2023-03-04 00:05:58 [main] INFO  x.g.m.d.k.a.client.KafkaAdminClient - Reading kafka topic [twitter-topic], attempt 0
2023-03-04 00:05:59 [main] INFO  x.g.m.d.t.t.k.s.i.i.KafkaStreamInitializer - Topics with name twitter-topic is ready for operations.
2023-03-04 00:05:59 [main] INFO  x.g.m.d.t.t.k.s.r.i.MockKafkaStreamRunner - Start to mock twitter stream for keywords: [Java, Microservices, Spring, Kafka, Elasticsearch]
2023-03-04 00:05:59 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text at a metus lacus metus at a Kafka tempor odio quis a lacinia at sending to kafka topic twitter-topic
2023-03-04 00:05:59 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 1531342628626273175, "id": 3357490632193607972, "text": "at a metus lacus metus at a Kafka tempor odio quis a lacinia at", "createdAt": 1677875759000}' to topic = 'twitter-topic'
2023-03-04 00:05:59 [pool-3-thread-1] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = -1
	batch.size = 1638400
	bootstrap.servers = [localhost:19092, localhost:29092, localhost:39092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = snappy
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.LongSerializer
	linger.ms = 5
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 60000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer

2023-03-04 00:05:59 [pool-3-thread-1] INFO  o.a.k.clients.producer.KafkaProducer - [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 0 ms.
2023-03-04 00:05:59 [pool-3-thread-1] INFO  o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2023-03-04 00:05:59 [pool-3-thread-1] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2023-03-04 00:05:59 [pool-3-thread-1] INFO  o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2023-03-04 00:05:59 [pool-3-thread-1] INFO  o.a.kafka.common.utils.AppInfoParser - App info kafka.producer for producer-1 unregistered
2023-03-04 00:05:59 [pool-3-thread-1] DEBUG o.a.k.clients.producer.KafkaProducer - [Producer clientId=producer-1] Kafka producer has been closed
2023-03-04 00:06:17 [SpringApplicationShutdownHook] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Closing kafka producer!
2023-03-04 00:06:17 [kafka-admin-client-thread | adminclient-1] INFO  o.a.kafka.common.utils.AppInfoParser - App info kafka.admin.client for adminclient-1 unregistered
2023-03-04 00:06:17 [kafka-admin-client-thread | adminclient-1] INFO  o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2023-03-04 00:06:17 [kafka-admin-client-thread | adminclient-1] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2023-03-04 00:06:17 [kafka-admin-client-thread | adminclient-1] INFO  o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2023-03-04 00:06:26 [main] INFO  x.g.m.d.t.t.k.s.TwitterToKafkaServiceApplication - Starting TwitterToKafkaServiceApplication using Java 17.0.6 with PID 31644 (/Users/admin/Documents/EventDeriventMicroservices/microservices-demo/twitter-to-kafka-service/target/classes started by admin in /Users/admin/Documents/EventDeriventMicroservices/microservices-demo)
2023-03-04 00:06:26 [main] INFO  x.g.m.d.t.t.k.s.TwitterToKafkaServiceApplication - No active profile set, falling back to 1 default profile: "default"
2023-03-04 00:06:27 [main] WARN  o.s.c.a.AnnotationTypeMapping - Support for convention-based annotation attribute overrides is deprecated and will be removed in Spring Framework 6.1. Please annotate the following attributes in @org.springframework.retry.annotation.EnableRetry with appropriate @AliasFor declarations: [proxyTargetClass]
2023-03-04 00:06:28 [main] INFO  o.a.k.c.admin.AdminClientConfig - AdminClientConfig values: 
	bootstrap.servers = [localhost:19092, localhost:29092, localhost:39092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2023-03-04 00:06:28 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.3.2
2023-03-04 00:06:28 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: b66af662e61082cb
2023-03-04 00:06:28 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1677875788075
2023-03-04 00:06:28 [main] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - <<<<<DEFAULT TOPIC: org.springframework.kafka.core.KafkaTemplate@79518e00>>>>>>>
2023-03-04 00:06:28 [main] INFO  o.s.b.w.e.netty.NettyWebServer - Netty started on port 8080
2023-03-04 00:06:28 [main] INFO  x.g.m.d.t.t.k.s.TwitterToKafkaServiceApplication - Started TwitterToKafkaServiceApplication in 2.144 seconds (process running for 3.0)
2023-03-04 00:06:28 [main] INFO  x.g.m.d.t.t.k.s.TwitterToKafkaServiceApplication - Application started!
2023-03-04 00:06:28 [main] INFO  x.g.m.d.k.a.client.KafkaAdminClient - Creating 1 topic(s), attempt 0
2023-03-04 00:06:28 [main] INFO  x.g.m.d.k.a.client.KafkaAdminClient - Reading kafka topic [twitter-topic], attempt 0
2023-03-04 00:06:29 [main] INFO  x.g.m.d.t.t.k.s.i.i.KafkaStreamInitializer - Topics with name twitter-topic is ready for operations.
2023-03-04 00:06:29 [main] INFO  x.g.m.d.t.t.k.s.r.i.MockKafkaStreamRunner - Start to mock twitter stream for keywords: [Java, Microservices, Spring, Kafka, Elasticsearch]
2023-03-04 00:06:29 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text lacinia vestibulum arcu Elasticsearch a euismod sending to kafka topic twitter-topic
2023-03-04 00:06:29 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 6465085278117407494, "id": 1298857178180595698, "text": "lacinia vestibulum arcu Elasticsearch a euismod", "createdAt": 1677875789000}' to topic = 'twitter-topic'
2023-03-04 00:06:29 [pool-3-thread-1] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = -1
	batch.size = 1638400
	bootstrap.servers = [localhost:19092, localhost:29092, localhost:39092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = snappy
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.LongSerializer
	linger.ms = 5
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 60000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer

2023-03-04 00:06:29 [pool-3-thread-1] TRACE o.a.k.clients.producer.KafkaProducer - [Producer clientId=producer-1] Starting the Kafka producer
2023-03-04 00:06:29 [pool-3-thread-1] INFO  o.a.k.clients.producer.KafkaProducer - [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 0 ms.
2023-03-04 00:06:29 [pool-3-thread-1] INFO  o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2023-03-04 00:06:29 [pool-3-thread-1] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2023-03-04 00:06:29 [pool-3-thread-1] INFO  o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2023-03-04 00:06:29 [pool-3-thread-1] INFO  o.a.kafka.common.utils.AppInfoParser - App info kafka.producer for producer-1 unregistered
2023-03-04 00:06:29 [pool-3-thread-1] DEBUG o.a.k.clients.producer.KafkaProducer - [Producer clientId=producer-1] Kafka producer has been closed
2023-03-04 00:07:30 [SpringApplicationShutdownHook] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Closing kafka producer!
2023-03-04 00:07:30 [kafka-admin-client-thread | adminclient-1] INFO  o.a.kafka.common.utils.AppInfoParser - App info kafka.admin.client for adminclient-1 unregistered
2023-03-04 00:07:30 [kafka-admin-client-thread | adminclient-1] INFO  o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2023-03-04 00:07:30 [kafka-admin-client-thread | adminclient-1] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2023-03-04 00:07:30 [kafka-admin-client-thread | adminclient-1] INFO  o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2023-03-04 00:07:38 [main] INFO  x.g.m.d.t.t.k.s.TwitterToKafkaServiceApplication - Starting TwitterToKafkaServiceApplication using Java 17.0.6 with PID 32395 (/Users/admin/Documents/EventDeriventMicroservices/microservices-demo/twitter-to-kafka-service/target/classes started by admin in /Users/admin/Documents/EventDeriventMicroservices/microservices-demo)
2023-03-04 00:07:38 [main] INFO  x.g.m.d.t.t.k.s.TwitterToKafkaServiceApplication - No active profile set, falling back to 1 default profile: "default"
2023-03-04 00:07:38 [main] WARN  o.s.c.a.AnnotationTypeMapping - Support for convention-based annotation attribute overrides is deprecated and will be removed in Spring Framework 6.1. Please annotate the following attributes in @org.springframework.retry.annotation.EnableRetry with appropriate @AliasFor declarations: [proxyTargetClass]
2023-03-04 00:07:39 [main] INFO  o.a.k.c.admin.AdminClientConfig - AdminClientConfig values: 
	bootstrap.servers = [localhost:19092, localhost:29092, localhost:39092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2023-03-04 00:07:39 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.3.2
2023-03-04 00:07:39 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: b66af662e61082cb
2023-03-04 00:07:39 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1677875859894
2023-03-04 00:07:40 [main] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - <<<<<DEFAULT TOPIC: org.springframework.kafka.core.KafkaTemplate@30c4e352>>>>>>>
2023-03-04 00:07:40 [main] INFO  o.s.b.w.e.netty.NettyWebServer - Netty started on port 8080
2023-03-04 00:07:40 [main] INFO  x.g.m.d.t.t.k.s.TwitterToKafkaServiceApplication - Started TwitterToKafkaServiceApplication in 2.019 seconds (process running for 2.87)
2023-03-04 00:07:40 [main] INFO  x.g.m.d.t.t.k.s.TwitterToKafkaServiceApplication - Application started!
2023-03-04 00:07:40 [main] INFO  x.g.m.d.k.a.client.KafkaAdminClient - Creating 1 topic(s), attempt 0
2023-03-04 00:07:40 [main] INFO  x.g.m.d.k.a.client.KafkaAdminClient - Reading kafka topic [twitter-topic], attempt 0
2023-03-04 00:07:40 [main] INFO  x.g.m.d.t.t.k.s.i.i.KafkaStreamInitializer - Topics with name twitter-topic is ready for operations.
2023-03-04 00:07:40 [main] INFO  x.g.m.d.t.t.k.s.r.i.MockKafkaStreamRunner - Start to mock twitter stream for keywords: [Java, Microservices, Spring, Kafka, Elasticsearch]
2023-03-04 00:07:40 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text ullamcorper sed at Kafka euismod lacinia sending to kafka topic twitter-topic
2023-03-04 00:07:41 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 6919315232491107077, "id": 6944073805829198323, "text": "ullamcorper sed at Kafka euismod lacinia", "createdAt": 1677875860000}' to topic = 'twitter-topic'
2023-03-04 00:07:41 [pool-3-thread-1] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = -1
	batch.size = 1638400
	bootstrap.servers = [localhost:19092, localhost:29092, localhost:39092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = snappy
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.LongSerializer
	linger.ms = 5
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 60000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer

2023-03-04 00:07:41 [pool-3-thread-1] TRACE o.a.k.clients.producer.KafkaProducer - [Producer clientId=producer-1] Starting the Kafka producer
2023-03-04 00:07:41 [pool-3-thread-1] INFO  o.a.k.clients.producer.KafkaProducer - [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 0 ms.
2023-03-04 00:07:41 [pool-3-thread-1] INFO  o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2023-03-04 00:07:41 [pool-3-thread-1] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2023-03-04 00:07:41 [pool-3-thread-1] INFO  o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2023-03-04 00:07:41 [pool-3-thread-1] INFO  o.a.kafka.common.utils.AppInfoParser - App info kafka.producer for producer-1 unregistered
2023-03-04 00:07:41 [pool-3-thread-1] DEBUG o.a.k.clients.producer.KafkaProducer - [Producer clientId=producer-1] Kafka producer has been closed
2023-03-04 00:12:40 [kafka-admin-client-thread | adminclient-1] INFO  o.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Node -1 disconnected.
2023-03-04 00:13:30 [SpringApplicationShutdownHook] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Closing kafka producer!
2023-03-04 00:13:30 [kafka-admin-client-thread | adminclient-1] INFO  o.a.kafka.common.utils.AppInfoParser - App info kafka.admin.client for adminclient-1 unregistered
2023-03-04 00:13:30 [kafka-admin-client-thread | adminclient-1] INFO  o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2023-03-04 00:13:30 [kafka-admin-client-thread | adminclient-1] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2023-03-04 00:13:30 [kafka-admin-client-thread | adminclient-1] INFO  o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2023-03-04 00:14:06 [main] INFO  x.g.m.d.t.t.k.s.TwitterToKafkaServiceApplication - Starting TwitterToKafkaServiceApplication using Java 17.0.6 with PID 36354 (/Users/admin/Documents/EventDeriventMicroservices/microservices-demo/twitter-to-kafka-service/target/classes started by admin in /Users/admin/Documents/EventDeriventMicroservices/microservices-demo)
2023-03-04 00:14:06 [main] INFO  x.g.m.d.t.t.k.s.TwitterToKafkaServiceApplication - No active profile set, falling back to 1 default profile: "default"
2023-03-04 00:14:06 [main] DEBUG o.s.boot.SpringApplication - Loading source class xyz.gouril.microservices.demo.twitter.to.kafka.service.TwitterToKafkaServiceApplication
2023-03-04 00:14:06 [main] DEBUG o.s.b.w.r.c.AnnotationConfigReactiveWebServerApplicationContext - Refreshing org.springframework.boot.web.reactive.context.AnnotationConfigReactiveWebServerApplicationContext@15cafec7
2023-03-04 00:14:06 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.context.annotation.internalConfigurationAnnotationProcessor'
2023-03-04 00:14:06 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.internalCachingMetadataReaderFactory'
2023-03-04 00:14:06 [main] DEBUG o.s.c.a.ClassPathBeanDefinitionScanner - Identified candidate component class: file [/Users/admin/Documents/EventDeriventMicroservices/microservices-demo/twitter-to-kafka-service/target/classes/xyz/gouril/microservices/demo/twitter/to/kafka/service/init/impl/KafkaStreamInitializer.class]
2023-03-04 00:14:06 [main] DEBUG o.s.c.a.ClassPathBeanDefinitionScanner - Identified candidate component class: file [/Users/admin/Documents/EventDeriventMicroservices/microservices-demo/twitter-to-kafka-service/target/classes/xyz/gouril/microservices/demo/twitter/to/kafka/service/listener/TwitterKafkaStatusListener.class]
2023-03-04 00:14:06 [main] DEBUG o.s.c.a.ClassPathBeanDefinitionScanner - Identified candidate component class: file [/Users/admin/Documents/EventDeriventMicroservices/microservices-demo/twitter-to-kafka-service/target/classes/xyz/gouril/microservices/demo/twitter/to/kafka/service/runner/impl/MockKafkaStreamRunner.class]
2023-03-04 00:14:06 [main] DEBUG o.s.c.a.ClassPathBeanDefinitionScanner - Identified candidate component class: file [/Users/admin/Documents/EventDeriventMicroservices/microservices-demo/twitter-to-kafka-service/target/classes/xyz/gouril/microservices/demo/twitter/to/kafka/service/transformer/TwitterStatusToAvroTransformer.class]
2023-03-04 00:14:06 [main] DEBUG o.s.c.a.ClassPathBeanDefinitionScanner - Identified candidate component class: file [/Users/admin/Documents/EventDeriventMicroservices/microservices-demo/app-config-data/target/classes/xyz/gouril/microservices/demo/config/KafkaConfigData.class]
2023-03-04 00:14:06 [main] DEBUG o.s.c.a.ClassPathBeanDefinitionScanner - Identified candidate component class: file [/Users/admin/Documents/EventDeriventMicroservices/microservices-demo/app-config-data/target/classes/xyz/gouril/microservices/demo/config/KafkaProducerConfigData.class]
2023-03-04 00:14:06 [main] DEBUG o.s.c.a.ClassPathBeanDefinitionScanner - Identified candidate component class: file [/Users/admin/Documents/EventDeriventMicroservices/microservices-demo/app-config-data/target/classes/xyz/gouril/microservices/demo/config/RetryConfigData.class]
2023-03-04 00:14:06 [main] DEBUG o.s.c.a.ClassPathBeanDefinitionScanner - Identified candidate component class: file [/Users/admin/Documents/EventDeriventMicroservices/microservices-demo/app-config-data/target/classes/xyz/gouril/microservices/demo/config/TwitterToKafkaServiceConfigData.class]
2023-03-04 00:14:06 [main] DEBUG o.s.c.a.ClassPathBeanDefinitionScanner - Identified candidate component class: file [/Users/admin/Documents/EventDeriventMicroservices/microservices-demo/kafka/kafka-admin/target/classes/xyz/gouril/microservices/demo/kafka/admin/client/KafkaAdminClient.class]
2023-03-04 00:14:06 [main] WARN  o.s.c.a.AnnotationTypeMapping - Support for convention-based annotation attribute overrides is deprecated and will be removed in Spring Framework 6.1. Please annotate the following attributes in @org.springframework.retry.annotation.EnableRetry with appropriate @AliasFor declarations: [proxyTargetClass]
2023-03-04 00:14:06 [main] DEBUG o.s.c.a.ClassPathBeanDefinitionScanner - Identified candidate component class: file [/Users/admin/Documents/EventDeriventMicroservices/microservices-demo/kafka/kafka-admin/target/classes/xyz/gouril/microservices/demo/kafka/admin/config/KafkaAdminConfig.class]
2023-03-04 00:14:06 [main] DEBUG o.s.c.a.ClassPathBeanDefinitionScanner - Identified candidate component class: file [/Users/admin/Documents/EventDeriventMicroservices/microservices-demo/kafka/kafka-admin/target/classes/xyz/gouril/microservices/demo/kafka/admin/config/WebClientConfig.class]
2023-03-04 00:14:06 [main] DEBUG o.s.c.a.ClassPathBeanDefinitionScanner - Identified candidate component class: file [/Users/admin/Documents/EventDeriventMicroservices/microservices-demo/common-config/target/classes/xyz/gouril/microservices/demo/common/config/RetryConfig.class]
2023-03-04 00:14:06 [main] DEBUG o.s.c.a.ClassPathBeanDefinitionScanner - Identified candidate component class: file [/Users/admin/Documents/EventDeriventMicroservices/microservices-demo/kafka/kafka-producer/target/classes/xyz/gouril/microservices/demo/kafka/producer/config/KafkaProducerConfig.class]
2023-03-04 00:14:06 [main] DEBUG o.s.c.a.ClassPathBeanDefinitionScanner - Identified candidate component class: file [/Users/admin/Documents/EventDeriventMicroservices/microservices-demo/kafka/kafka-producer/target/classes/xyz/gouril/microservices/demo/kafka/producer/service/impl/TwitterKafkaProducer.class]
2023-03-04 00:14:07 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'propertySourcesPlaceholderConfigurer'
2023-03-04 00:14:07 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.boot.sql.init.dependency.DatabaseInitializationDependencyConfigurer$DependsOnDatabaseInitializationPostProcessor'
2023-03-04 00:14:07 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.context.event.internalEventListenerProcessor'
2023-03-04 00:14:07 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.context.event.internalEventListenerFactory'
2023-03-04 00:14:07 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.context.annotation.internalAutowiredAnnotationProcessor'
2023-03-04 00:14:07 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.context.annotation.internalCommonAnnotationProcessor'
2023-03-04 00:14:07 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.boot.context.properties.ConfigurationPropertiesBindingPostProcessor'
2023-03-04 00:14:07 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.boot.context.internalConfigurationPropertiesBinder'
2023-03-04 00:14:07 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.aop.config.internalAutoProxyCreator'
2023-03-04 00:14:07 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'persistenceExceptionTranslationPostProcessor'
2023-03-04 00:14:07 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'persistenceExceptionTranslationPostProcessor' via factory method to bean named 'environment'
2023-03-04 00:14:07 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.kafka.config.internalKafkaListenerAnnotationProcessor'
2023-03-04 00:14:07 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'webServerFactoryCustomizerBeanPostProcessor'
2023-03-04 00:14:07 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'nettyReactiveWebServerFactory'
2023-03-04 00:14:07 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.retry.annotation.RetryConfiguration'
2023-03-04 00:14:07 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.web.reactive.ReactiveWebServerFactoryConfiguration$EmbeddedNetty'
2023-03-04 00:14:07 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'reactorResourceFactory'
2023-03-04 00:14:07 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.reactor.netty.ReactorNettyConfigurations$ReactorResourceFactoryConfiguration'
2023-03-04 00:14:07 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'spring.reactor.netty-org.springframework.boot.autoconfigure.reactor.netty.ReactorNettyProperties'
2023-03-04 00:14:07 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.boot.context.properties.BoundConfigurationProperties'
2023-03-04 00:14:07 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'reactorResourceFactory' via factory method to bean named 'spring.reactor.netty-org.springframework.boot.autoconfigure.reactor.netty.ReactorNettyProperties'
2023-03-04 00:14:07 [main] DEBUG reactor.util.Loggers - Using Slf4j logging framework
2023-03-04 00:14:07 [main] DEBUG i.n.u.i.l.InternalLoggerFactory - Using SLF4J as the default logging framework
2023-03-04 00:14:07 [main] DEBUG i.n.util.internal.PlatformDependent0 - -Dio.netty.noUnsafe: false
2023-03-04 00:14:07 [main] DEBUG i.n.util.internal.PlatformDependent0 - Java version: 17
2023-03-04 00:14:07 [main] DEBUG i.n.util.internal.PlatformDependent0 - sun.misc.Unsafe.theUnsafe: available
2023-03-04 00:14:07 [main] DEBUG i.n.util.internal.PlatformDependent0 - sun.misc.Unsafe.copyMemory: available
2023-03-04 00:14:07 [main] DEBUG i.n.util.internal.PlatformDependent0 - sun.misc.Unsafe.storeFence: available
2023-03-04 00:14:07 [main] DEBUG i.n.util.internal.PlatformDependent0 - java.nio.Buffer.address: available
2023-03-04 00:14:07 [main] DEBUG i.n.util.internal.PlatformDependent0 - direct buffer constructor: unavailable: Reflective setAccessible(true) disabled
2023-03-04 00:14:07 [main] DEBUG i.n.util.internal.PlatformDependent0 - java.nio.Bits.unaligned: available, true
2023-03-04 00:14:07 [main] DEBUG i.n.util.internal.PlatformDependent0 - jdk.internal.misc.Unsafe.allocateUninitializedArray(int): unavailable: class io.netty.util.internal.PlatformDependent0$7 cannot access class jdk.internal.misc.Unsafe (in module java.base) because module java.base does not export jdk.internal.misc to unnamed module @2473d930
2023-03-04 00:14:07 [main] DEBUG i.n.util.internal.PlatformDependent0 - java.nio.DirectByteBuffer.<init>(long, int): unavailable
2023-03-04 00:14:07 [main] DEBUG i.n.util.internal.PlatformDependent - sun.misc.Unsafe: available
2023-03-04 00:14:07 [main] DEBUG i.n.util.internal.PlatformDependent - maxDirectMemory: 4294967296 bytes (maybe)
2023-03-04 00:14:07 [main] DEBUG i.n.util.internal.PlatformDependent - -Dio.netty.tmpdir: /var/folders/zx/4g777wp55pg8j62jnpqrd9dh0000gn/T (java.io.tmpdir)
2023-03-04 00:14:07 [main] DEBUG i.n.util.internal.PlatformDependent - -Dio.netty.bitMode: 64 (sun.arch.data.model)
2023-03-04 00:14:07 [main] DEBUG i.n.util.internal.PlatformDependent - Platform: MacOS
2023-03-04 00:14:07 [main] DEBUG i.n.util.internal.PlatformDependent - -Dio.netty.maxDirectMemory: -1 bytes
2023-03-04 00:14:07 [main] DEBUG i.n.util.internal.PlatformDependent - -Dio.netty.uninitializedArrayAllocationThreshold: -1
2023-03-04 00:14:07 [main] DEBUG io.netty.util.internal.CleanerJava9 - java.nio.ByteBuffer.cleaner(): available
2023-03-04 00:14:07 [main] DEBUG i.n.util.internal.PlatformDependent - -Dio.netty.noPreferDirect: false
2023-03-04 00:14:07 [main] DEBUG reactor.netty.tcp.TcpResources - [http] resources will use the default LoopResources: DefaultLoopResources {prefix=reactor-http, daemon=true, selectCount=8, workerCount=8}
2023-03-04 00:14:07 [main] DEBUG reactor.netty.tcp.TcpResources - [http] resources will use the default ConnectionProvider: reactor.netty.resources.DefaultPooledConnectionProvider@6a48a7f3
2023-03-04 00:14:07 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'nettyReactiveWebServerFactory' via factory method to bean named 'reactorResourceFactory'
2023-03-04 00:14:07 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'reactiveWebServerFactoryCustomizer'
2023-03-04 00:14:07 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.web.reactive.ReactiveWebServerFactoryAutoConfiguration'
2023-03-04 00:14:07 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'server-org.springframework.boot.autoconfigure.web.ServerProperties'
2023-03-04 00:14:07 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'reactiveWebServerFactoryCustomizer' via factory method to bean named 'server-org.springframework.boot.autoconfigure.web.ServerProperties'
2023-03-04 00:14:07 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'nettyWebServerFactoryCustomizer'
2023-03-04 00:14:07 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.web.embedded.EmbeddedWebServerFactoryCustomizerAutoConfiguration$NettyWebServerFactoryCustomizerConfiguration'
2023-03-04 00:14:07 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'nettyWebServerFactoryCustomizer' via factory method to bean named 'environment'
2023-03-04 00:14:07 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'nettyWebServerFactoryCustomizer' via factory method to bean named 'server-org.springframework.boot.autoconfigure.web.ServerProperties'
2023-03-04 00:14:07 [main] DEBUG i.n.u.i.InternalThreadLocalMap - -Dio.netty.threadLocalMap.stringBuilder.initialSize: 1024
2023-03-04 00:14:07 [main] DEBUG i.n.u.i.InternalThreadLocalMap - -Dio.netty.threadLocalMap.stringBuilder.maxSize: 4096
2023-03-04 00:14:07 [main] DEBUG io.netty.util.ResourceLeakDetector - -Dio.netty.leakDetection.level: simple
2023-03-04 00:14:07 [main] DEBUG io.netty.util.ResourceLeakDetector - -Dio.netty.leakDetection.targetRecords: 4
2023-03-04 00:14:07 [main] DEBUG i.n.u.concurrent.GlobalEventExecutor - -Dio.netty.globalEventExecutor.quietPeriodSeconds: 1
2023-03-04 00:14:07 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'twitterToKafkaServiceApplication'
2023-03-04 00:14:07 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'kafkaStreamInitializer'
2023-03-04 00:14:07 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'kafkaConfigData'
2023-03-04 00:14:07 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'kafkaAdminClient'
2023-03-04 00:14:07 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'retryConfigData'
2023-03-04 00:14:07 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'adminClient'
2023-03-04 00:14:07 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'kafkaAdminConfig'
2023-03-04 00:14:07 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'kafkaAdminConfig' via constructor to bean named 'kafkaConfigData'
2023-03-04 00:14:07 [main] INFO  o.a.k.c.admin.AdminClientConfig - AdminClientConfig values: 
	bootstrap.servers = [localhost:19092, localhost:29092, localhost:39092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2023-03-04 00:14:07 [main] DEBUG o.a.k.c.a.i.AdminMetadataManager - [AdminClient clientId=adminclient-1] Setting bootstrap cluster metadata Cluster(id = null, nodes = [localhost:19092 (id: -1 rack: null), localhost:39092 (id: -3 rack: null), localhost:29092 (id: -2 rack: null)], partitions = [], controller = null).
2023-03-04 00:14:07 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.3.2
2023-03-04 00:14:07 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: b66af662e61082cb
2023-03-04 00:14:07 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1677876247989
2023-03-04 00:14:07 [main] DEBUG o.a.k.clients.admin.KafkaAdminClient - [AdminClient clientId=adminclient-1] Kafka admin client initialized
2023-03-04 00:14:07 [kafka-admin-client-thread | adminclient-1] DEBUG o.a.k.clients.admin.KafkaAdminClient - [AdminClient clientId=adminclient-1] Thread starting
2023-03-04 00:14:07 [kafka-admin-client-thread | adminclient-1] DEBUG o.apache.kafka.clients.ClientUtils - Resolved host localhost as 127.0.0.1
2023-03-04 00:14:07 [kafka-admin-client-thread | adminclient-1] DEBUG o.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Initiating connection to node localhost:39092 (id: -3 rack: null) using address localhost/127.0.0.1
2023-03-04 00:14:08 [kafka-admin-client-thread | adminclient-1] DEBUG o.a.kafka.common.network.Selector - [AdminClient clientId=adminclient-1] Created socket with SO_RCVBUF = 342972, SO_SNDBUF = 146988, SO_TIMEOUT = 0 to node -3
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'retryTemplate'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'retryConfig'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'retryConfig' via constructor to bean named 'retryConfigData'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'webClient'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'webClientConfig'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'kafkaAdminClient' via constructor to bean named 'kafkaConfigData'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'kafkaAdminClient' via constructor to bean named 'retryConfigData'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'kafkaAdminClient' via constructor to bean named 'adminClient'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'kafkaAdminClient' via constructor to bean named 'retryTemplate'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'kafkaAdminClient' via constructor to bean named 'webClient'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'kafkaStreamInitializer' via constructor to bean named 'kafkaConfigData'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'kafkaStreamInitializer' via constructor to bean named 'kafkaAdminClient'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'mockKafkaStreamRunner'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'twitterToKafkaServiceConfigData'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'twitterKafkaStatusListener'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'twitterKafkaProducer'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'kafkaTemplate'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'kafkaProducerConfig'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'kafkaProducerConfigData'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'kafkaProducerConfig' via constructor to bean named 'kafkaConfigData'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'kafkaProducerConfig' via constructor to bean named 'kafkaProducerConfigData'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'producerFactory'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'producerConfig'
2023-03-04 00:14:08 [kafka-admin-client-thread | adminclient-1] DEBUG o.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Completed connection to node -3. Fetching API versions.
2023-03-04 00:14:08 [kafka-admin-client-thread | adminclient-1] DEBUG o.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Initiating API versions fetch from node -3.
2023-03-04 00:14:08 [kafka-admin-client-thread | adminclient-1] DEBUG o.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Sending API_VERSIONS request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=adminclient-1, correlationId=0) and timeout 3600000 to node -3: ApiVersionsRequestData(clientSoftwareName='apache-kafka-java', clientSoftwareVersion='3.3.2')
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'twitterKafkaProducer' via constructor to bean named 'kafkaTemplate'
2023-03-04 00:14:08 [main] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - <<<<<DEFAULT TOPIC: org.springframework.kafka.core.KafkaTemplate@17ba57f0>>>>>>>
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'twitterStatusToAvroTransformer'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'twitterKafkaStatusListener' via constructor to bean named 'kafkaConfigData'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'twitterKafkaStatusListener' via constructor to bean named 'twitterKafkaProducer'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'twitterKafkaStatusListener' via constructor to bean named 'twitterStatusToAvroTransformer'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'mockKafkaStreamRunner' via constructor to bean named 'twitterToKafkaServiceConfigData'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'mockKafkaStreamRunner' via constructor to bean named 'twitterKafkaStatusListener'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'twitterToKafkaServiceApplication' via constructor to bean named 'kafkaStreamInitializer'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'twitterToKafkaServiceApplication' via constructor to bean named 'mockKafkaStreamRunner'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.AutoConfigurationPackages'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.context.PropertyPlaceholderAutoConfiguration'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.boot.context.properties.EnableConfigurationPropertiesRegistrar.methodValidationExcludeFilter'
2023-03-04 00:14:08 [kafka-admin-client-thread | adminclient-1] DEBUG o.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Received API_VERSIONS response from node -3 for request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=adminclient-1, correlationId=0): ApiVersionsResponseData(errorCode=35, apiKeys=[], throttleTimeMs=0, supportedFeatures=[], finalizedFeaturesEpoch=-1, finalizedFeatures=[])
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.jackson.JacksonAutoConfiguration$Jackson2ObjectMapperBuilderCustomizerConfiguration'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'standardJacksonObjectMapperBuilderCustomizer'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'spring.jackson-org.springframework.boot.autoconfigure.jackson.JacksonProperties'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'standardJacksonObjectMapperBuilderCustomizer' via factory method to bean named 'spring.jackson-org.springframework.boot.autoconfigure.jackson.JacksonProperties'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'parameterNamesModule'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.jackson.JacksonAutoConfiguration$ParameterNamesModuleConfiguration'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'jsonMixinModule'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.jackson.JacksonAutoConfiguration$JacksonMixinConfiguration'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'jsonMixinModuleEntries'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'jsonMixinModuleEntries' via factory method to bean named 'org.springframework.boot.web.reactive.context.AnnotationConfigReactiveWebServerApplicationContext@15cafec7'
2023-03-04 00:14:08 [main] DEBUG o.s.b.a.AutoConfigurationPackages - @EnableAutoConfiguration was declared on a class in the package 'xyz.gouril.microservices.demo.twitter.to.kafka.service'. Automatic @Repository and @Entity scanning is enabled.
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'jsonMixinModule' via factory method to bean named 'org.springframework.boot.web.reactive.context.AnnotationConfigReactiveWebServerApplicationContext@15cafec7'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'jsonMixinModule' via factory method to bean named 'jsonMixinModuleEntries'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'jsonComponentModule'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.jackson.JacksonAutoConfiguration'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.jackson.JacksonAutoConfiguration$JacksonObjectMapperBuilderConfiguration'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.jackson.JacksonAutoConfiguration$JacksonObjectMapperConfiguration'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'jacksonObjectMapper'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'jacksonObjectMapperBuilder' via factory method to bean named 'org.springframework.boot.web.reactive.context.AnnotationConfigReactiveWebServerApplicationContext@15cafec7'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'jacksonObjectMapperBuilder' via factory method to bean named 'standardJacksonObjectMapperBuilderCustomizer'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'jacksonObjectMapper' via factory method to bean named 'jacksonObjectMapperBuilder'
2023-03-04 00:14:08 [kafka-admin-client-thread | adminclient-1] DEBUG o.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Initiating API versions fetch from node -3.
2023-03-04 00:14:08 [kafka-admin-client-thread | adminclient-1] DEBUG o.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Sending API_VERSIONS request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=0, clientId=adminclient-1, correlationId=1) and timeout 3600000 to node -3: ApiVersionsRequestData(clientSoftwareName='apache-kafka-java', clientSoftwareVersion='3.3.2')
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.http.codec.CodecsAutoConfiguration$DefaultCodecsConfiguration'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'defaultCodecCustomizer'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'spring.codec-org.springframework.boot.autoconfigure.codec.CodecProperties'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'defaultCodecCustomizer' via factory method to bean named 'spring.codec-org.springframework.boot.autoconfigure.codec.CodecProperties'
2023-03-04 00:14:08 [kafka-admin-client-thread | adminclient-1] DEBUG o.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Received API_VERSIONS response from node -3 for request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=0, clientId=adminclient-1, correlationId=1): ApiVersionsResponseData(errorCode=0, apiKeys=[ApiVersion(apiKey=0, minVersion=0, maxVersion=6), ApiVersion(apiKey=1, minVersion=0, maxVersion=8), ApiVersion(apiKey=2, minVersion=0, maxVersion=3), ApiVersion(apiKey=3, minVersion=0, maxVersion=6), ApiVersion(apiKey=4, minVersion=0, maxVersion=1), ApiVersion(apiKey=5, minVersion=0, maxVersion=0), ApiVersion(apiKey=6, minVersion=0, maxVersion=4), ApiVersion(apiKey=7, minVersion=0, maxVersion=1), ApiVersion(apiKey=8, minVersion=0, maxVersion=4), ApiVersion(apiKey=9, minVersion=0, maxVersion=4), ApiVersion(apiKey=10, minVersion=0, maxVersion=2), ApiVersion(apiKey=11, minVersion=0, maxVersion=3), ApiVersion(apiKey=12, minVersion=0, maxVersion=2), ApiVersion(apiKey=13, minVersion=0, maxVersion=2), ApiVersion(apiKey=14, minVersion=0, maxVersion=2), ApiVersion(apiKey=15, minVersion=0, maxVersion=2), ApiVersion(apiKey=16, minVersion=0, maxVersion=2), ApiVersion(apiKey=17, minVersion=0, maxVersion=1), ApiVersion(apiKey=18, minVersion=0, maxVersion=2), ApiVersion(apiKey=19, minVersion=0, maxVersion=3), ApiVersion(apiKey=20, minVersion=0, maxVersion=2), ApiVersion(apiKey=21, minVersion=0, maxVersion=1), ApiVersion(apiKey=22, minVersion=0, maxVersion=1), ApiVersion(apiKey=23, minVersion=0, maxVersion=1), ApiVersion(apiKey=24, minVersion=0, maxVersion=1), ApiVersion(apiKey=25, minVersion=0, maxVersion=1), ApiVersion(apiKey=26, minVersion=0, maxVersion=1), ApiVersion(apiKey=27, minVersion=0, maxVersion=0), ApiVersion(apiKey=28, minVersion=0, maxVersion=1), ApiVersion(apiKey=29, minVersion=0, maxVersion=1), ApiVersion(apiKey=30, minVersion=0, maxVersion=1), ApiVersion(apiKey=31, minVersion=0, maxVersion=1), ApiVersion(apiKey=32, minVersion=0, maxVersion=2), ApiVersion(apiKey=33, minVersion=0, maxVersion=1), ApiVersion(apiKey=34, minVersion=0, maxVersion=1), ApiVersion(apiKey=35, minVersion=0, maxVersion=1), ApiVersion(apiKey=36, minVersion=0, maxVersion=0), ApiVersion(apiKey=37, minVersion=0, maxVersion=1), ApiVersion(apiKey=38, minVersion=0, maxVersion=1), ApiVersion(apiKey=39, minVersion=0, maxVersion=1), ApiVersion(apiKey=40, minVersion=0, maxVersion=1), ApiVersion(apiKey=41, minVersion=0, maxVersion=1), ApiVersion(apiKey=42, minVersion=0, maxVersion=1)], throttleTimeMs=0, supportedFeatures=[], finalizedFeaturesEpoch=-1, finalizedFeatures=[])
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.http.codec.CodecsAutoConfiguration$JacksonCodecConfiguration'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'jacksonCodecCustomizer'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'jacksonCodecCustomizer' via factory method to bean named 'jacksonObjectMapper'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.http.codec.CodecsAutoConfiguration'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.web.reactive.ReactiveMultipartAutoConfiguration'
2023-03-04 00:14:08 [kafka-admin-client-thread | adminclient-1] DEBUG o.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Node -3 has finalized features epoch: -1, finalized features: [], supported features: [], API versions: (Produce(0): 0 to 6 [usable: 6], Fetch(1): 0 to 8 [usable: 8], ListOffsets(2): 0 to 3 [usable: 3], Metadata(3): 0 to 6 [usable: 6], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 4 [usable: 4], OffsetFetch(9): 0 to 4 [usable: 4], FindCoordinator(10): 0 to 2 [usable: 2], JoinGroup(11): 0 to 3 [usable: 3], Heartbeat(12): 0 to 2 [usable: 2], LeaveGroup(13): 0 to 2 [usable: 2], SyncGroup(14): 0 to 2 [usable: 2], DescribeGroups(15): 0 to 2 [usable: 2], ListGroups(16): 0 to 2 [usable: 2], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 2], CreateTopics(19): 0 to 3 [usable: 3], DeleteTopics(20): 0 to 2 [usable: 2], DeleteRecords(21): 0 to 1 [usable: 1], InitProducerId(22): 0 to 1 [usable: 1], OffsetForLeaderEpoch(23): 0 to 1 [usable: 1], AddPartitionsToTxn(24): 0 to 1 [usable: 1], AddOffsetsToTxn(25): 0 to 1 [usable: 1], EndTxn(26): 0 to 1 [usable: 1], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 1 [usable: 1], DescribeAcls(29): 0 to 1 [usable: 1], CreateAcls(30): 0 to 1 [usable: 1], DeleteAcls(31): 0 to 1 [usable: 1], DescribeConfigs(32): 0 to 2 [usable: 2], AlterConfigs(33): 0 to 1 [usable: 1], AlterReplicaLogDirs(34): 0 to 1 [usable: 1], DescribeLogDirs(35): 0 to 1 [usable: 1], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 1], CreateDelegationToken(38): 0 to 1 [usable: 1], RenewDelegationToken(39): 0 to 1 [usable: 1], ExpireDelegationToken(40): 0 to 1 [usable: 1], DescribeDelegationToken(41): 0 to 1 [usable: 1], DeleteGroups(42): 0 to 1 [usable: 1], ElectLeaders(43): UNSUPPORTED, IncrementalAlterConfigs(44): UNSUPPORTED, AlterPartitionReassignments(45): UNSUPPORTED, ListPartitionReassignments(46): UNSUPPORTED, OffsetDelete(47): UNSUPPORTED, DescribeClientQuotas(48): UNSUPPORTED, AlterClientQuotas(49): UNSUPPORTED, DescribeUserScramCredentials(50): UNSUPPORTED, AlterUserScramCredentials(51): UNSUPPORTED, AlterPartition(56): UNSUPPORTED, UpdateFeatures(57): UNSUPPORTED, DescribeCluster(60): UNSUPPORTED, DescribeProducers(61): UNSUPPORTED, DescribeTransactions(65): UNSUPPORTED, ListTransactions(66): UNSUPPORTED, AllocateProducerIds(67): UNSUPPORTED).
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'defaultPartHttpMessageReaderCustomizer'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'spring.webflux.multipart-org.springframework.boot.autoconfigure.web.reactive.ReactiveMultipartProperties'
2023-03-04 00:14:08 [kafka-admin-client-thread | adminclient-1] DEBUG o.a.k.clients.admin.KafkaAdminClient - [AdminClient clientId=adminclient-1] Sending MetadataRequestData(topics=[], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to localhost:39092 (id: -3 rack: null). correlationId=2, timeoutMs=29600
2023-03-04 00:14:08 [kafka-admin-client-thread | adminclient-1] DEBUG o.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Sending METADATA request with header RequestHeader(apiKey=METADATA, apiVersion=6, clientId=adminclient-1, correlationId=2) and timeout 29600 to node -3: MetadataRequestData(topics=[], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false)
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'defaultPartHttpMessageReaderCustomizer' via factory method to bean named 'spring.webflux.multipart-org.springframework.boot.autoconfigure.web.reactive.ReactiveMultipartProperties'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.web.reactive.WebSessionIdResolverAutoConfiguration'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'spring.webflux-org.springframework.boot.autoconfigure.web.reactive.WebFluxProperties'
2023-03-04 00:14:08 [kafka-admin-client-thread | adminclient-1] DEBUG o.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Received METADATA response from node -3 for request with header RequestHeader(apiKey=METADATA, apiVersion=6, clientId=adminclient-1, correlationId=2): MetadataResponseData(throttleTimeMs=0, brokers=[MetadataResponseBroker(nodeId=2, host='localhost', port=29092, rack=null), MetadataResponseBroker(nodeId=1, host='localhost', port=19092, rack=null), MetadataResponseBroker(nodeId=3, host='localhost', port=39092, rack=null)], clusterId='QGDYypu5SSGtA9Bc36Rjow', controllerId=3, topics=[], clusterAuthorizedOperations=-2147483648)
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'org.springframework.boot.autoconfigure.web.reactive.WebSessionIdResolverAutoConfiguration' via constructor to bean named 'server-org.springframework.boot.autoconfigure.web.ServerProperties'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'org.springframework.boot.autoconfigure.web.reactive.WebSessionIdResolverAutoConfiguration' via constructor to bean named 'spring.webflux-org.springframework.boot.autoconfigure.web.reactive.WebFluxProperties'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'webSessionIdResolver'
2023-03-04 00:14:08 [kafka-admin-client-thread | adminclient-1] DEBUG o.a.k.c.a.i.AdminMetadataManager - [AdminClient clientId=adminclient-1] Updating cluster metadata to Cluster(id = QGDYypu5SSGtA9Bc36Rjow, nodes = [localhost:29092 (id: 2 rack: null), localhost:19092 (id: 1 rack: null), localhost:39092 (id: 3 rack: null)], partitions = [], controller = localhost:39092 (id: 3 rack: null))
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.web.reactive.error.ErrorWebFluxAutoConfiguration'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'org.springframework.boot.autoconfigure.web.reactive.error.ErrorWebFluxAutoConfiguration' via constructor to bean named 'server-org.springframework.boot.autoconfigure.web.ServerProperties'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'errorWebExceptionHandler'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'errorAttributes'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'spring.web-org.springframework.boot.autoconfigure.web.WebProperties'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'serverCodecConfigurer'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.web.reactive.WebFluxAutoConfiguration$EnableWebFluxConfiguration'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'org.springframework.boot.autoconfigure.web.reactive.WebFluxAutoConfiguration$EnableWebFluxConfiguration' via constructor to bean named 'spring.webflux-org.springframework.boot.autoconfigure.web.reactive.WebFluxProperties'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'org.springframework.boot.autoconfigure.web.reactive.WebFluxAutoConfiguration$EnableWebFluxConfiguration' via constructor to bean named 'spring.web-org.springframework.boot.autoconfigure.web.WebProperties'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'org.springframework.boot.autoconfigure.web.reactive.WebFluxAutoConfiguration$EnableWebFluxConfiguration' via constructor to bean named 'server-org.springframework.boot.autoconfigure.web.ServerProperties'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.web.reactive.WebFluxAutoConfiguration$WebFluxConfig'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'org.springframework.boot.autoconfigure.web.reactive.WebFluxAutoConfiguration$WebFluxConfig' via constructor to bean named 'spring.web-org.springframework.boot.autoconfigure.web.WebProperties'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'org.springframework.boot.autoconfigure.web.reactive.WebFluxAutoConfiguration$WebFluxConfig' via constructor to bean named 'spring.webflux-org.springframework.boot.autoconfigure.web.reactive.WebFluxProperties'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'org.springframework.boot.autoconfigure.web.reactive.WebFluxAutoConfiguration$WebFluxConfig' via constructor to bean named 'org.springframework.beans.factory.support.DefaultListableBeanFactory@8a589a2'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'errorWebExceptionHandler' via factory method to bean named 'errorAttributes'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'errorWebExceptionHandler' via factory method to bean named 'spring.web-org.springframework.boot.autoconfigure.web.WebProperties'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'errorWebExceptionHandler' via factory method to bean named 'serverCodecConfigurer'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'errorWebExceptionHandler' via factory method to bean named 'org.springframework.boot.web.reactive.context.AnnotationConfigReactiveWebServerApplicationContext@15cafec7'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'webFluxConversionService'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'webFluxValidator'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'localeContextResolver'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'webSessionManager'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'webHandler'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'requestMappingHandlerMapping'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'webFluxContentTypeResolver'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'requestMappingHandlerMapping' via factory method to bean named 'webFluxContentTypeResolver'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'routerFunctionMapping'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'routerFunctionMapping' via factory method to bean named 'serverCodecConfigurer'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'resourceHandlerMapping'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'resourceUrlProvider'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'resourceHandlerMapping' via factory method to bean named 'resourceUrlProvider'
2023-03-04 00:14:08 [main] DEBUG _.s.w.r.HandlerMapping.Mappings - 'resourceHandlerMapping' {/webjars/**=ResourceWebHandler [classpath [META-INF/resources/webjars/]], /**=ResourceWebHandler [classpath [META-INF/resources/], classpath [resources/], classpath [static/], classpath [public/]]}
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'welcomePageRouterFunctionMapping'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.web.reactive.WebFluxAutoConfiguration$WelcomePageConfiguration'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'welcomePageRouterFunctionMapping' via factory method to bean named 'org.springframework.boot.web.reactive.context.AnnotationConfigReactiveWebServerApplicationContext@15cafec7'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'welcomePageRouterFunctionMapping' via factory method to bean named 'spring.webflux-org.springframework.boot.autoconfigure.web.reactive.WebFluxProperties'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'welcomePageRouterFunctionMapping' via factory method to bean named 'spring.web-org.springframework.boot.autoconfigure.web.WebProperties'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'requestMappingHandlerAdapter'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'webFluxAdapterRegistry'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'requestMappingHandlerAdapter' via factory method to bean named 'webFluxAdapterRegistry'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'requestMappingHandlerAdapter' via factory method to bean named 'serverCodecConfigurer'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'requestMappingHandlerAdapter' via factory method to bean named 'webFluxConversionService'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'requestMappingHandlerAdapter' via factory method to bean named 'webFluxValidator'
2023-03-04 00:14:08 [main] DEBUG o.s.w.r.r.m.a.ControllerMethodResolver - ControllerAdvice beans: none
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'handlerFunctionAdapter'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'simpleHandlerAdapter'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'webFluxWebSocketHandlerAdapter'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'responseEntityResultHandler'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'responseEntityResultHandler' via factory method to bean named 'webFluxAdapterRegistry'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'responseEntityResultHandler' via factory method to bean named 'serverCodecConfigurer'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'responseEntityResultHandler' via factory method to bean named 'webFluxContentTypeResolver'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'responseBodyResultHandler'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'responseBodyResultHandler' via factory method to bean named 'webFluxAdapterRegistry'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'responseBodyResultHandler' via factory method to bean named 'serverCodecConfigurer'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'responseBodyResultHandler' via factory method to bean named 'webFluxContentTypeResolver'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'viewResolutionResultHandler'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'viewResolutionResultHandler' via factory method to bean named 'webFluxAdapterRegistry'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'viewResolutionResultHandler' via factory method to bean named 'webFluxContentTypeResolver'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'serverResponseResultHandler'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'serverResponseResultHandler' via factory method to bean named 'serverCodecConfigurer'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'responseStatusExceptionHandler'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.web.reactive.WebFluxAutoConfiguration'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.web.reactive.HttpHandlerAutoConfiguration$AnnotationConfig'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'org.springframework.boot.autoconfigure.web.reactive.HttpHandlerAutoConfiguration$AnnotationConfig' via constructor to bean named 'org.springframework.boot.web.reactive.context.AnnotationConfigReactiveWebServerApplicationContext@15cafec7'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'httpHandler'
2023-03-04 00:14:08 [main] DEBUG o.s.w.s.a.HttpWebHandlerAdapter - enableLoggingRequestDetails='false': form data and headers will be masked to prevent unsafe logging of potentially sensitive data
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.web.reactive.HttpHandlerAutoConfiguration'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.jmx.JmxAutoConfiguration'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'spring.jmx-org.springframework.boot.autoconfigure.jmx.JmxProperties'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'org.springframework.boot.autoconfigure.jmx.JmxAutoConfiguration' via constructor to bean named 'spring.jmx-org.springframework.boot.autoconfigure.jmx.JmxProperties'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'mbeanExporter'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'objectNamingStrategy'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'mbeanExporter' via factory method to bean named 'objectNamingStrategy'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'mbeanExporter' via factory method to bean named 'org.springframework.beans.factory.support.DefaultListableBeanFactory@8a589a2'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'mbeanServer'
2023-03-04 00:14:08 [main] DEBUG o.s.jmx.support.JmxUtils - Found MBeanServer: com.sun.jmx.mbeanserver.JmxMBeanServer@67f89fa3
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.admin.SpringApplicationAdminJmxAutoConfiguration'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'springApplicationAdminRegistrar'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'springApplicationAdminRegistrar' via factory method to bean named 'environment'
2023-03-04 00:14:08 [main] DEBUG o.s.b.a.SpringApplicationAdminMXBeanRegistrar$SpringApplicationAdmin - Application Admin MBean registered with name 'org.springframework.boot:type=Admin,name=SpringApplication'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.aop.AopAutoConfiguration$AspectJAutoProxyingConfiguration$CglibAutoProxyConfiguration'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.aop.AopAutoConfiguration$AspectJAutoProxyingConfiguration'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.aop.AopAutoConfiguration'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.availability.ApplicationAvailabilityAutoConfiguration'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'applicationAvailability'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.context.ConfigurationPropertiesAutoConfiguration'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.context.LifecycleAutoConfiguration'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'lifecycleProcessor'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'spring.lifecycle-org.springframework.boot.autoconfigure.context.LifecycleProperties'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'lifecycleProcessor' via factory method to bean named 'spring.lifecycle-org.springframework.boot.autoconfigure.context.LifecycleProperties'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.dao.PersistenceExceptionTranslationAutoConfiguration'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.info.ProjectInfoAutoConfiguration'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'spring.info-org.springframework.boot.autoconfigure.info.ProjectInfoProperties'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'org.springframework.boot.autoconfigure.info.ProjectInfoAutoConfiguration' via constructor to bean named 'spring.info-org.springframework.boot.autoconfigure.info.ProjectInfoProperties'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.kafka.KafkaAnnotationDrivenConfiguration$EnableKafkaConfiguration'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.kafka.config.internalKafkaListenerEndpointRegistry'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.kafka.KafkaAnnotationDrivenConfiguration'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'spring.kafka-org.springframework.boot.autoconfigure.kafka.KafkaProperties'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'org.springframework.boot.autoconfigure.kafka.KafkaAnnotationDrivenConfiguration' via constructor to bean named 'spring.kafka-org.springframework.boot.autoconfigure.kafka.KafkaProperties'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'kafkaListenerContainerFactoryConfigurer'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'kafkaListenerContainerFactory'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'kafkaListenerContainerFactory' via factory method to bean named 'kafkaListenerContainerFactoryConfigurer'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'kafkaConsumerFactory'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.kafka.KafkaAutoConfiguration'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'org.springframework.boot.autoconfigure.kafka.KafkaAutoConfiguration' via constructor to bean named 'spring.kafka-org.springframework.boot.autoconfigure.kafka.KafkaProperties'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'kafkaProducerListener'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'kafkaAdmin'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.netty.NettyAutoConfiguration'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'spring.netty-org.springframework.boot.autoconfigure.netty.NettyProperties'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'org.springframework.boot.autoconfigure.netty.NettyAutoConfiguration' via constructor to bean named 'spring.netty-org.springframework.boot.autoconfigure.netty.NettyProperties'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.sql.init.SqlInitializationAutoConfiguration'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'spring.sql.init-org.springframework.boot.autoconfigure.sql.init.SqlInitializationProperties'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.task.TaskExecutionAutoConfiguration'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'taskExecutorBuilder'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'spring.task.execution-org.springframework.boot.autoconfigure.task.TaskExecutionProperties'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'taskExecutorBuilder' via factory method to bean named 'spring.task.execution-org.springframework.boot.autoconfigure.task.TaskExecutionProperties'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.task.TaskSchedulingAutoConfiguration'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'taskSchedulerBuilder'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'spring.task.scheduling-org.springframework.boot.autoconfigure.task.TaskSchedulingProperties'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'taskSchedulerBuilder' via factory method to bean named 'spring.task.scheduling-org.springframework.boot.autoconfigure.task.TaskSchedulingProperties'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.transaction.TransactionAutoConfiguration'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'platformTransactionManagerCustomizers'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'spring.transaction-org.springframework.boot.autoconfigure.transaction.TransactionProperties'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.web.embedded.EmbeddedWebServerFactoryCustomizerAutoConfiguration'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.web.reactive.function.client.ClientHttpConnectorConfiguration$ReactorNetty'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.web.reactive.function.client.ClientHttpConnectorAutoConfiguration'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.web.reactive.function.client.WebClientAutoConfiguration$WebClientCodecsConfiguration'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'exchangeStrategiesCustomizer'
2023-03-04 00:14:08 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.web.reactive.function.client.WebClientAutoConfiguration'
2023-03-04 00:14:08 [main] DEBUG o.s.j.e.a.AnnotationMBeanExporter - Registering beans for JMX exposure on startup
2023-03-04 00:14:08 [main] DEBUG o.s.j.e.a.AnnotationMBeanExporter - Autodetecting user-defined JMX MBeans
2023-03-04 00:14:08 [main] DEBUG o.s.c.s.DefaultLifecycleProcessor - Starting beans in phase -2147483647
2023-03-04 00:14:08 [main] DEBUG o.s.c.s.DefaultLifecycleProcessor - Successfully started bean 'springBootLoggingLifecycle'
2023-03-04 00:14:08 [main] DEBUG o.s.c.s.DefaultLifecycleProcessor - Starting beans in phase 2147481599
2023-03-04 00:14:08 [main] DEBUG r.netty.resources.DefaultLoopIOUring - Default io_uring support : false
2023-03-04 00:14:08 [main] DEBUG r.netty.resources.DefaultLoopEpoll - Default Epoll support : false
2023-03-04 00:14:08 [main] DEBUG r.netty.resources.DefaultLoopKQueue - Default KQueue support : false
2023-03-04 00:14:08 [main] DEBUG i.n.c.MultithreadEventLoopGroup - -Dio.netty.eventLoopThreads: 16
2023-03-04 00:14:08 [main] DEBUG io.netty.channel.nio.NioEventLoop - -Dio.netty.noKeySetOptimization: false
2023-03-04 00:14:08 [main] DEBUG io.netty.channel.nio.NioEventLoop - -Dio.netty.selectorAutoRebuildThreshold: 512
2023-03-04 00:14:08 [main] DEBUG i.n.util.internal.PlatformDependent - org.jctools-core.MpscChunkedArrayQueue: available
2023-03-04 00:14:08 [main] DEBUG io.netty.channel.DefaultChannelId - -Dio.netty.processId: 36354 (auto-detected)
2023-03-04 00:14:08 [main] DEBUG io.netty.util.NetUtil - -Djava.net.preferIPv4Stack: false
2023-03-04 00:14:08 [main] DEBUG io.netty.util.NetUtil - -Djava.net.preferIPv6Addresses: false
2023-03-04 00:14:08 [main] DEBUG i.netty.util.NetUtilInitializations - Loopback interface: lo0 (lo0, 0:0:0:0:0:0:0:1%lo0)
2023-03-04 00:14:08 [main] DEBUG io.netty.util.NetUtil - Failed to get SOMAXCONN from sysctl and file /proc/sys/net/core/somaxconn. Default: 128
2023-03-04 00:14:08 [main] DEBUG io.netty.channel.DefaultChannelId - -Dio.netty.machineId: ac:de:48:ff:fe:00:11:22 (auto-detected)
2023-03-04 00:14:08 [main] DEBUG i.n.buffer.PooledByteBufAllocator - -Dio.netty.allocator.numHeapArenas: 16
2023-03-04 00:14:08 [main] DEBUG i.n.buffer.PooledByteBufAllocator - -Dio.netty.allocator.numDirectArenas: 16
2023-03-04 00:14:08 [main] DEBUG i.n.buffer.PooledByteBufAllocator - -Dio.netty.allocator.pageSize: 8192
2023-03-04 00:14:08 [main] DEBUG i.n.buffer.PooledByteBufAllocator - -Dio.netty.allocator.maxOrder: 9
2023-03-04 00:14:08 [main] DEBUG i.n.buffer.PooledByteBufAllocator - -Dio.netty.allocator.chunkSize: 4194304
2023-03-04 00:14:08 [main] DEBUG i.n.buffer.PooledByteBufAllocator - -Dio.netty.allocator.smallCacheSize: 256
2023-03-04 00:14:08 [main] DEBUG i.n.buffer.PooledByteBufAllocator - -Dio.netty.allocator.normalCacheSize: 64
2023-03-04 00:14:08 [main] DEBUG i.n.buffer.PooledByteBufAllocator - -Dio.netty.allocator.maxCachedBufferCapacity: 32768
2023-03-04 00:14:08 [main] DEBUG i.n.buffer.PooledByteBufAllocator - -Dio.netty.allocator.cacheTrimInterval: 8192
2023-03-04 00:14:08 [main] DEBUG i.n.buffer.PooledByteBufAllocator - -Dio.netty.allocator.cacheTrimIntervalMillis: 0
2023-03-04 00:14:08 [main] DEBUG i.n.buffer.PooledByteBufAllocator - -Dio.netty.allocator.useCacheForAllThreads: false
2023-03-04 00:14:08 [main] DEBUG i.n.buffer.PooledByteBufAllocator - -Dio.netty.allocator.maxCachedByteBuffersPerChunk: 1023
2023-03-04 00:14:08 [main] DEBUG io.netty.buffer.ByteBufUtil - -Dio.netty.allocator.type: pooled
2023-03-04 00:14:08 [main] DEBUG io.netty.buffer.ByteBufUtil - -Dio.netty.threadLocalDirectBufferSize: 0
2023-03-04 00:14:08 [main] DEBUG io.netty.buffer.ByteBufUtil - -Dio.netty.maxThreadLocalCharBufferSize: 16384
2023-03-04 00:14:08 [reactor-http-nio-1] DEBUG r.netty.transport.ServerTransport - [570fa5c4, L:/[0:0:0:0:0:0:0:0]:8080] Bound new server
2023-03-04 00:14:08 [main] INFO  o.s.b.w.e.netty.NettyWebServer - Netty started on port 8080
2023-03-04 00:14:08 [main] DEBUG o.s.c.s.DefaultLifecycleProcessor - Successfully started bean 'webServerStartStop'
2023-03-04 00:14:08 [main] DEBUG o.s.c.s.DefaultLifecycleProcessor - Starting beans in phase 2147482623
2023-03-04 00:14:08 [main] DEBUG o.s.c.s.DefaultLifecycleProcessor - Successfully started bean 'webServerGracefulShutdown'
2023-03-04 00:14:08 [main] DEBUG o.s.c.s.DefaultLifecycleProcessor - Starting beans in phase 2147483547
2023-03-04 00:14:08 [main] DEBUG o.s.c.s.DefaultLifecycleProcessor - Successfully started bean 'org.springframework.kafka.config.internalKafkaListenerEndpointRegistry'
2023-03-04 00:14:08 [main] DEBUG o.s.b.a.l.ConditionEvaluationReportLogger - 


============================
CONDITIONS EVALUATION REPORT
============================


Positive matches:
-----------------

   AopAutoConfiguration matched:
      - @ConditionalOnProperty (spring.aop.auto=true) matched (OnPropertyCondition)

   AopAutoConfiguration.AspectJAutoProxyingConfiguration matched:
      - @ConditionalOnClass found required class 'org.aspectj.weaver.Advice' (OnClassCondition)

   AopAutoConfiguration.AspectJAutoProxyingConfiguration.CglibAutoProxyConfiguration matched:
      - @ConditionalOnProperty (spring.aop.proxy-target-class=true) matched (OnPropertyCondition)

   ClientHttpConnectorAutoConfiguration matched:
      - @ConditionalOnClass found required class 'org.springframework.web.reactive.function.client.WebClient' (OnClassCondition)

   ClientHttpConnectorAutoConfiguration#clientConnectorCustomizer matched:
      - @ConditionalOnBean (types: org.springframework.http.client.reactive.ClientHttpConnector; SearchStrategy: all) found bean 'reactorClientHttpConnector' (OnBeanCondition)

   ClientHttpConnectorConfiguration.ReactorNetty matched:
      - @ConditionalOnClass found required class 'reactor.netty.http.client.HttpClient' (OnClassCondition)
      - @ConditionalOnMissingBean (types: org.springframework.http.client.reactive.ClientHttpConnector; SearchStrategy: all) did not find any beans (OnBeanCondition)

   CodecsAutoConfiguration matched:
      - @ConditionalOnClass found required classes 'org.springframework.http.codec.CodecConfigurer', 'org.springframework.web.reactive.function.client.WebClient' (OnClassCondition)

   CodecsAutoConfiguration.JacksonCodecConfiguration matched:
      - @ConditionalOnClass found required class 'com.fasterxml.jackson.databind.ObjectMapper' (OnClassCondition)

   CodecsAutoConfiguration.JacksonCodecConfiguration#jacksonCodecCustomizer matched:
      - @ConditionalOnBean (types: com.fasterxml.jackson.databind.ObjectMapper; SearchStrategy: all) found bean 'jacksonObjectMapper' (OnBeanCondition)

   EmbeddedWebServerFactoryCustomizerAutoConfiguration matched:
      - @ConditionalOnWebApplication (required) found ConfigurableReactiveWebEnvironment (OnWebApplicationCondition)

   EmbeddedWebServerFactoryCustomizerAutoConfiguration.NettyWebServerFactoryCustomizerConfiguration matched:
      - @ConditionalOnClass found required class 'reactor.netty.http.server.HttpServer' (OnClassCondition)

   ErrorWebFluxAutoConfiguration matched:
      - @ConditionalOnClass found required class 'org.springframework.web.reactive.config.WebFluxConfigurer' (OnClassCondition)
      - found ConfigurableReactiveWebEnvironment (OnWebApplicationCondition)

   ErrorWebFluxAutoConfiguration#errorAttributes matched:
      - @ConditionalOnMissingBean (types: org.springframework.boot.web.reactive.error.ErrorAttributes; SearchStrategy: current) did not find any beans (OnBeanCondition)

   ErrorWebFluxAutoConfiguration#errorWebExceptionHandler matched:
      - @ConditionalOnMissingBean (types: org.springframework.boot.web.reactive.error.ErrorWebExceptionHandler; SearchStrategy: current) did not find any beans (OnBeanCondition)

   GenericCacheConfiguration matched:
      - Cache org.springframework.boot.autoconfigure.cache.GenericCacheConfiguration automatic cache type (CacheCondition)

   HttpHandlerAutoConfiguration matched:
      - @ConditionalOnClass found required classes 'org.springframework.web.reactive.DispatcherHandler', 'org.springframework.http.server.reactive.HttpHandler' (OnClassCondition)
      - found ConfigurableReactiveWebEnvironment (OnWebApplicationCondition)
      - @ConditionalOnMissingBean (types: org.springframework.http.server.reactive.HttpHandler; SearchStrategy: all) did not find any beans (OnBeanCondition)

   JacksonAutoConfiguration matched:
      - @ConditionalOnClass found required class 'com.fasterxml.jackson.databind.ObjectMapper' (OnClassCondition)

   JacksonAutoConfiguration.Jackson2ObjectMapperBuilderCustomizerConfiguration matched:
      - @ConditionalOnClass found required class 'org.springframework.http.converter.json.Jackson2ObjectMapperBuilder' (OnClassCondition)

   JacksonAutoConfiguration.JacksonObjectMapperBuilderConfiguration matched:
      - @ConditionalOnClass found required class 'org.springframework.http.converter.json.Jackson2ObjectMapperBuilder' (OnClassCondition)

   JacksonAutoConfiguration.JacksonObjectMapperBuilderConfiguration#jacksonObjectMapperBuilder matched:
      - @ConditionalOnMissingBean (types: org.springframework.http.converter.json.Jackson2ObjectMapperBuilder; SearchStrategy: all) did not find any beans (OnBeanCondition)

   JacksonAutoConfiguration.JacksonObjectMapperConfiguration matched:
      - @ConditionalOnClass found required class 'org.springframework.http.converter.json.Jackson2ObjectMapperBuilder' (OnClassCondition)

   JacksonAutoConfiguration.JacksonObjectMapperConfiguration#jacksonObjectMapper matched:
      - @ConditionalOnMissingBean (types: com.fasterxml.jackson.databind.ObjectMapper; SearchStrategy: all) did not find any beans (OnBeanCondition)

   JacksonAutoConfiguration.ParameterNamesModuleConfiguration matched:
      - @ConditionalOnClass found required class 'com.fasterxml.jackson.module.paramnames.ParameterNamesModule' (OnClassCondition)

   JacksonAutoConfiguration.ParameterNamesModuleConfiguration#parameterNamesModule matched:
      - @ConditionalOnMissingBean (types: com.fasterxml.jackson.module.paramnames.ParameterNamesModule; SearchStrategy: all) did not find any beans (OnBeanCondition)

   JmxAutoConfiguration matched:
      - @ConditionalOnClass found required class 'org.springframework.jmx.export.MBeanExporter' (OnClassCondition)
      - @ConditionalOnProperty (spring.jmx.enabled=true) matched (OnPropertyCondition)

   JmxAutoConfiguration#mbeanExporter matched:
      - @ConditionalOnMissingBean (types: org.springframework.jmx.export.MBeanExporter; SearchStrategy: current) did not find any beans (OnBeanCondition)

   JmxAutoConfiguration#mbeanServer matched:
      - @ConditionalOnMissingBean (types: javax.management.MBeanServer; SearchStrategy: all) did not find any beans (OnBeanCondition)

   JmxAutoConfiguration#objectNamingStrategy matched:
      - @ConditionalOnMissingBean (types: org.springframework.jmx.export.naming.ObjectNamingStrategy; SearchStrategy: current) did not find any beans (OnBeanCondition)

   KafkaAnnotationDrivenConfiguration matched:
      - @ConditionalOnClass found required class 'org.springframework.kafka.annotation.EnableKafka' (OnClassCondition)

   KafkaAnnotationDrivenConfiguration#kafkaListenerContainerFactory matched:
      - @ConditionalOnMissingBean (names: kafkaListenerContainerFactory; SearchStrategy: all) did not find any beans (OnBeanCondition)

   KafkaAnnotationDrivenConfiguration#kafkaListenerContainerFactoryConfigurer matched:
      - @ConditionalOnMissingBean (types: org.springframework.boot.autoconfigure.kafka.ConcurrentKafkaListenerContainerFactoryConfigurer; SearchStrategy: all) did not find any beans (OnBeanCondition)

   KafkaAnnotationDrivenConfiguration.EnableKafkaConfiguration matched:
      - @ConditionalOnMissingBean (names: org.springframework.kafka.config.internalKafkaListenerAnnotationProcessor; SearchStrategy: all) did not find any beans (OnBeanCondition)

   KafkaAutoConfiguration matched:
      - @ConditionalOnClass found required class 'org.springframework.kafka.core.KafkaTemplate' (OnClassCondition)

   KafkaAutoConfiguration#kafkaAdmin matched:
      - @ConditionalOnMissingBean (types: org.springframework.kafka.core.KafkaAdmin; SearchStrategy: all) did not find any beans (OnBeanCondition)

   KafkaAutoConfiguration#kafkaConsumerFactory matched:
      - @ConditionalOnMissingBean (types: org.springframework.kafka.core.ConsumerFactory; SearchStrategy: all) did not find any beans (OnBeanCondition)

   KafkaAutoConfiguration#kafkaProducerListener matched:
      - @ConditionalOnMissingBean (types: org.springframework.kafka.support.ProducerListener; SearchStrategy: all) did not find any beans (OnBeanCondition)

   LifecycleAutoConfiguration#defaultLifecycleProcessor matched:
      - @ConditionalOnMissingBean (names: lifecycleProcessor; SearchStrategy: current) did not find any beans (OnBeanCondition)

   MockKafkaStreamRunner matched:
      - @ConditionalOnProperty (twitter-to-kafka-service.enable-mock-tweets=true) matched (OnPropertyCondition)

   NettyAutoConfiguration matched:
      - @ConditionalOnClass found required class 'io.netty.util.NettyRuntime' (OnClassCondition)

   NoOpCacheConfiguration matched:
      - Cache org.springframework.boot.autoconfigure.cache.NoOpCacheConfiguration automatic cache type (CacheCondition)

   PersistenceExceptionTranslationAutoConfiguration matched:
      - @ConditionalOnClass found required class 'org.springframework.dao.annotation.PersistenceExceptionTranslationPostProcessor' (OnClassCondition)

   PersistenceExceptionTranslationAutoConfiguration#persistenceExceptionTranslationPostProcessor matched:
      - @ConditionalOnProperty (spring.dao.exceptiontranslation.enabled) matched (OnPropertyCondition)
      - @ConditionalOnMissingBean (types: org.springframework.dao.annotation.PersistenceExceptionTranslationPostProcessor; SearchStrategy: all) did not find any beans (OnBeanCondition)

   PropertyPlaceholderAutoConfiguration#propertySourcesPlaceholderConfigurer matched:
      - @ConditionalOnMissingBean (types: org.springframework.context.support.PropertySourcesPlaceholderConfigurer; SearchStrategy: current) did not find any beans (OnBeanCondition)

   ReactiveMultipartAutoConfiguration matched:
      - @ConditionalOnClass found required classes 'org.springframework.http.codec.multipart.DefaultPartHttpMessageReader', 'org.springframework.web.reactive.config.WebFluxConfigurer' (OnClassCondition)
      - found ConfigurableReactiveWebEnvironment (OnWebApplicationCondition)

   ReactiveWebServerFactoryAutoConfiguration matched:
      - @ConditionalOnClass found required class 'org.springframework.http.ReactiveHttpInputMessage' (OnClassCondition)
      - found ConfigurableReactiveWebEnvironment (OnWebApplicationCondition)

   ReactiveWebServerFactoryConfiguration.EmbeddedNetty matched:
      - @ConditionalOnClass found required class 'reactor.netty.http.server.HttpServer' (OnClassCondition)
      - @ConditionalOnMissingBean (types: org.springframework.boot.web.reactive.server.ReactiveWebServerFactory; SearchStrategy: all) did not find any beans (OnBeanCondition)

   ReactorNettyConfigurations.ReactorResourceFactoryConfiguration#reactorResourceFactory matched:
      - @ConditionalOnMissingBean (types: org.springframework.http.client.reactive.ReactorResourceFactory; SearchStrategy: all) did not find any beans (OnBeanCondition)

   SimpleCacheConfiguration matched:
      - Cache org.springframework.boot.autoconfigure.cache.SimpleCacheConfiguration automatic cache type (CacheCondition)

   SpringApplicationAdminJmxAutoConfiguration matched:
      - @ConditionalOnProperty (spring.application.admin.enabled=true) matched (OnPropertyCondition)

   SpringApplicationAdminJmxAutoConfiguration#springApplicationAdminRegistrar matched:
      - @ConditionalOnMissingBean (types: org.springframework.boot.admin.SpringApplicationAdminMXBeanRegistrar; SearchStrategy: all) did not find any beans (OnBeanCondition)

   SqlInitializationAutoConfiguration matched:
      - @ConditionalOnProperty (spring.sql.init.enabled) matched (OnPropertyCondition)
      - NoneNestedConditions 0 matched 1 did not; NestedCondition on SqlInitializationAutoConfiguration.SqlInitializationModeCondition.ModeIsNever @ConditionalOnProperty (spring.sql.init.mode=never) did not find property 'mode' (SqlInitializationAutoConfiguration.SqlInitializationModeCondition)

   TaskExecutionAutoConfiguration matched:
      - @ConditionalOnClass found required class 'org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor' (OnClassCondition)

   TaskExecutionAutoConfiguration#applicationTaskExecutor matched:
      - @ConditionalOnMissingBean (types: java.util.concurrent.Executor; SearchStrategy: all) did not find any beans (OnBeanCondition)

   TaskExecutionAutoConfiguration#taskExecutorBuilder matched:
      - @ConditionalOnMissingBean (types: org.springframework.boot.task.TaskExecutorBuilder; SearchStrategy: all) did not find any beans (OnBeanCondition)

   TaskSchedulingAutoConfiguration matched:
      - @ConditionalOnClass found required class 'org.springframework.scheduling.concurrent.ThreadPoolTaskScheduler' (OnClassCondition)

   TaskSchedulingAutoConfiguration#taskSchedulerBuilder matched:
      - @ConditionalOnMissingBean (types: org.springframework.boot.task.TaskSchedulerBuilder; SearchStrategy: all) did not find any beans (OnBeanCondition)

   TransactionAutoConfiguration matched:
      - @ConditionalOnClass found required class 'org.springframework.transaction.PlatformTransactionManager' (OnClassCondition)

   TransactionAutoConfiguration#platformTransactionManagerCustomizers matched:
      - @ConditionalOnMissingBean (types: org.springframework.boot.autoconfigure.transaction.TransactionManagerCustomizers; SearchStrategy: all) did not find any beans (OnBeanCondition)

   WebClientAutoConfiguration matched:
      - @ConditionalOnClass found required class 'org.springframework.web.reactive.function.client.WebClient' (OnClassCondition)

   WebClientAutoConfiguration#webClientBuilder matched:
      - @ConditionalOnMissingBean (types: org.springframework.web.reactive.function.client.WebClient$Builder; SearchStrategy: all) did not find any beans (OnBeanCondition)

   WebClientAutoConfiguration.WebClientCodecsConfiguration matched:
      - @ConditionalOnBean (types: org.springframework.boot.web.codec.CodecCustomizer; SearchStrategy: all) found beans 'jacksonCodecCustomizer', 'defaultCodecCustomizer', 'defaultPartHttpMessageReaderCustomizer' (OnBeanCondition)

   WebClientAutoConfiguration.WebClientCodecsConfiguration#exchangeStrategiesCustomizer matched:
      - @ConditionalOnMissingBean (types: org.springframework.boot.autoconfigure.web.reactive.function.client.WebClientCodecCustomizer; SearchStrategy: all) did not find any beans (OnBeanCondition)

   WebFluxAutoConfiguration matched:
      - @ConditionalOnClass found required class 'org.springframework.web.reactive.config.WebFluxConfigurer' (OnClassCondition)
      - found ConfigurableReactiveWebEnvironment (OnWebApplicationCondition)
      - @ConditionalOnMissingBean (types: org.springframework.web.reactive.config.WebFluxConfigurationSupport; SearchStrategy: all) did not find any beans (OnBeanCondition)

   WebFluxAutoConfiguration.EnableWebFluxConfiguration#localeContextResolver matched:
      - @ConditionalOnMissingBean (names: localeContextResolver; SearchStrategy: all) did not find any beans (OnBeanCondition)

   WebFluxAutoConfiguration.EnableWebFluxConfiguration#webSessionManager matched:
      - @ConditionalOnMissingBean (names: webSessionManager; SearchStrategy: all) did not find any beans (OnBeanCondition)

   WebSessionIdResolverAutoConfiguration matched:
      - @ConditionalOnClass found required classes 'org.springframework.web.server.session.WebSessionManager', 'reactor.core.publisher.Mono' (OnClassCondition)
      - found ConfigurableReactiveWebEnvironment (OnWebApplicationCondition)

   WebSessionIdResolverAutoConfiguration#webSessionIdResolver matched:
      - @ConditionalOnMissingBean (types: org.springframework.web.server.session.WebSessionIdResolver; SearchStrategy: all) did not find any beans (OnBeanCondition)


Negative matches:
-----------------

   AopAutoConfiguration.AspectJAutoProxyingConfiguration.JdkDynamicAutoProxyConfiguration:
      Did not match:
         - @ConditionalOnProperty (spring.aop.proxy-target-class=false) did not find property 'proxy-target-class' (OnPropertyCondition)

   AopAutoConfiguration.ClassProxyingConfiguration:
      Did not match:
         - @ConditionalOnMissingClass found unwanted class 'org.aspectj.weaver.Advice' (OnClassCondition)

   ArtemisAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'jakarta.jms.ConnectionFactory' (OnClassCondition)

   BatchAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.batch.core.launch.JobLauncher' (OnClassCondition)

   Cache2kCacheConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.cache2k.Cache2kBuilder' (OnClassCondition)

   CacheAutoConfiguration:
      Did not match:
         - @ConditionalOnBean (types: org.springframework.cache.interceptor.CacheAspectSupport; SearchStrategy: all) did not find any beans of type org.springframework.cache.interceptor.CacheAspectSupport (OnBeanCondition)
      Matched:
         - @ConditionalOnClass found required class 'org.springframework.cache.CacheManager' (OnClassCondition)

   CacheAutoConfiguration.CacheManagerEntityManagerFactoryDependsOnPostProcessor:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean' (OnClassCondition)
         - Ancestor org.springframework.boot.autoconfigure.cache.CacheAutoConfiguration did not match (ConditionEvaluationReport.AncestorsMatchedCondition)

   CaffeineCacheConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.github.benmanes.caffeine.cache.Caffeine' (OnClassCondition)

   CassandraAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.datastax.oss.driver.api.core.CqlSession' (OnClassCondition)

   CassandraDataAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.datastax.oss.driver.api.core.CqlSession' (OnClassCondition)

   CassandraReactiveDataAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.datastax.oss.driver.api.core.CqlSession' (OnClassCondition)

   CassandraReactiveRepositoriesAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.data.cassandra.ReactiveSession' (OnClassCondition)

   CassandraRepositoriesAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.datastax.oss.driver.api.core.CqlSession' (OnClassCondition)

   ClientHttpConnectorConfiguration.HttpClient5:
      Did not match:
         - @ConditionalOnClass did not find required classes 'org.apache.hc.client5.http.impl.async.HttpAsyncClients', 'org.apache.hc.core5.http.nio.AsyncRequestProducer' (OnClassCondition)

   ClientHttpConnectorConfiguration.JdkClient:
      Did not match:
         - @ConditionalOnMissingBean (types: org.springframework.http.client.reactive.ClientHttpConnector; SearchStrategy: all) found beans of type 'org.springframework.http.client.reactive.ClientHttpConnector' reactorClientHttpConnector (OnBeanCondition)
      Matched:
         - @ConditionalOnClass found required class 'java.net.http.HttpClient' (OnClassCondition)

   ClientHttpConnectorConfiguration.JettyClient:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.eclipse.jetty.reactive.client.ReactiveRequest' (OnClassCondition)

   CouchbaseAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.couchbase.client.java.Cluster' (OnClassCondition)

   CouchbaseCacheConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.couchbase.client.java.Cluster' (OnClassCondition)

   CouchbaseDataAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.couchbase.client.java.Bucket' (OnClassCondition)

   CouchbaseReactiveDataAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.couchbase.client.java.Cluster' (OnClassCondition)

   CouchbaseReactiveRepositoriesAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.couchbase.client.java.Cluster' (OnClassCondition)

   CouchbaseRepositoriesAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.couchbase.client.java.Bucket' (OnClassCondition)

   DataSourceAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.jdbc.datasource.embedded.EmbeddedDatabaseType' (OnClassCondition)

   DataSourceInitializationConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.jdbc.datasource.init.DatabasePopulator' (OnClassCondition)

   DataSourceTransactionManagerAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.jdbc.core.JdbcTemplate' (OnClassCondition)

   DispatcherServletAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.web.servlet.DispatcherServlet' (OnClassCondition)

   ElasticsearchClientAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'co.elastic.clients.elasticsearch.ElasticsearchClient' (OnClassCondition)

   ElasticsearchDataAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.data.elasticsearch.client.elc.ElasticsearchTemplate' (OnClassCondition)

   ElasticsearchRepositoriesAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.data.elasticsearch.repository.ElasticsearchRepository' (OnClassCondition)

   ElasticsearchRestClientAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.elasticsearch.client.RestClientBuilder' (OnClassCondition)

   EmbeddedLdapAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.unboundid.ldap.listener.InMemoryDirectoryServer' (OnClassCondition)

   EmbeddedWebServerFactoryCustomizerAutoConfiguration.JettyWebServerFactoryCustomizerConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required classes 'org.eclipse.jetty.server.Server', 'org.eclipse.jetty.util.Loader', 'org.eclipse.jetty.webapp.WebAppContext' (OnClassCondition)

   EmbeddedWebServerFactoryCustomizerAutoConfiguration.TomcatWebServerFactoryCustomizerConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required classes 'org.apache.catalina.startup.Tomcat', 'org.apache.coyote.UpgradeProtocol' (OnClassCondition)

   EmbeddedWebServerFactoryCustomizerAutoConfiguration.UndertowWebServerFactoryCustomizerConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required classes 'io.undertow.Undertow', 'org.xnio.SslClientAuthMode' (OnClassCondition)

   ErrorMvcAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'jakarta.servlet.Servlet' (OnClassCondition)

   FlywayAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.flywaydb.core.Flyway' (OnClassCondition)

   FreeMarkerAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'freemarker.template.Configuration' (OnClassCondition)

   GraphQlAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'graphql.GraphQL' (OnClassCondition)

   GraphQlQueryByExampleAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'graphql.GraphQL' (OnClassCondition)

   GraphQlQuerydslAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'graphql.GraphQL' (OnClassCondition)

   GraphQlRSocketAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'graphql.GraphQL' (OnClassCondition)

   GraphQlReactiveQueryByExampleAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'graphql.GraphQL' (OnClassCondition)

   GraphQlReactiveQuerydslAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'graphql.GraphQL' (OnClassCondition)

   GraphQlWebFluxAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'graphql.GraphQL' (OnClassCondition)

   GraphQlWebFluxSecurityAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'graphql.GraphQL' (OnClassCondition)

   GraphQlWebMvcAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'graphql.GraphQL' (OnClassCondition)

   GraphQlWebMvcSecurityAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'graphql.GraphQL' (OnClassCondition)

   GroovyTemplateAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'groovy.text.markup.MarkupTemplateEngine' (OnClassCondition)

   GsonAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.google.gson.Gson' (OnClassCondition)

   H2ConsoleAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.h2.server.web.JakartaWebServlet' (OnClassCondition)

   HazelcastAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.hazelcast.core.HazelcastInstance' (OnClassCondition)

   HazelcastCacheConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.hazelcast.core.HazelcastInstance' (OnClassCondition)

   HazelcastJpaDependencyAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.hazelcast.core.HazelcastInstance' (OnClassCondition)

   HibernateJpaAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'jakarta.persistence.EntityManager' (OnClassCondition)

   HttpEncodingAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.web.filter.CharacterEncodingFilter' (OnClassCondition)

   HttpMessageConvertersAutoConfiguration:
      Did not match:
         - NoneNestedConditions 1 matched 0 did not; NestedCondition on HttpMessageConvertersAutoConfiguration.NotReactiveWebApplicationCondition.ReactiveWebApplication found ConfigurableReactiveWebEnvironment (HttpMessageConvertersAutoConfiguration.NotReactiveWebApplicationCondition)
      Matched:
         - @ConditionalOnClass found required class 'org.springframework.http.converter.HttpMessageConverter' (OnClassCondition)

   HypermediaAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.hateoas.EntityModel' (OnClassCondition)

   InfinispanCacheConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.infinispan.spring.embedded.provider.SpringEmbeddedCacheManager' (OnClassCondition)

   InfluxDbAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.influxdb.InfluxDB' (OnClassCondition)

   IntegrationAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.integration.config.EnableIntegration' (OnClassCondition)

   JCacheCacheConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'javax.cache.Caching' (OnClassCondition)

   JdbcRepositoriesAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.data.jdbc.repository.config.AbstractJdbcConfiguration' (OnClassCondition)

   JdbcTemplateAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.jdbc.core.JdbcTemplate' (OnClassCondition)

   JerseyAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'jakarta.servlet.ServletRegistration' (OnClassCondition)

   JmsAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'jakarta.jms.Message' (OnClassCondition)

   JndiConnectionFactoryAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.jms.core.JmsTemplate' (OnClassCondition)

   JndiDataSourceAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.jdbc.datasource.embedded.EmbeddedDatabaseType' (OnClassCondition)

   JooqAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.jooq.DSLContext' (OnClassCondition)

   JpaRepositoriesAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.data.jpa.repository.JpaRepository' (OnClassCondition)

   JsonbAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'jakarta.json.bind.Jsonb' (OnClassCondition)

   JtaAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'jakarta.transaction.Transaction' (OnClassCondition)

   KafkaAutoConfiguration#kafkaJaasInitializer:
      Did not match:
         - @ConditionalOnProperty (spring.kafka.jaas.enabled) did not find property 'spring.kafka.jaas.enabled' (OnPropertyCondition)

   KafkaAutoConfiguration#kafkaProducerFactory:
      Did not match:
         - @ConditionalOnMissingBean (types: org.springframework.kafka.core.ProducerFactory; SearchStrategy: all) found beans of type 'org.springframework.kafka.core.ProducerFactory' producerFactory (OnBeanCondition)

   KafkaAutoConfiguration#kafkaRetryTopicConfiguration:
      Did not match:
         - @ConditionalOnProperty (spring.kafka.retry.topic.enabled) did not find property 'spring.kafka.retry.topic.enabled' (OnPropertyCondition)

   KafkaAutoConfiguration#kafkaTemplate:
      Did not match:
         - @ConditionalOnMissingBean (types: org.springframework.kafka.core.KafkaTemplate; SearchStrategy: all) found beans of type 'org.springframework.kafka.core.KafkaTemplate' kafkaTemplate (OnBeanCondition)

   KafkaAutoConfiguration#kafkaTransactionManager:
      Did not match:
         - @ConditionalOnProperty (spring.kafka.producer.transaction-id-prefix) did not find property 'spring.kafka.producer.transaction-id-prefix' (OnPropertyCondition)

   KafkaStreamsAnnotationDrivenConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.apache.kafka.streams.StreamsBuilder' (OnClassCondition)

   LdapAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.ldap.core.ContextSource' (OnClassCondition)

   LdapRepositoriesAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.data.ldap.repository.LdapRepository' (OnClassCondition)

   LiquibaseAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'liquibase.change.DatabaseChange' (OnClassCondition)

   MailSenderAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'jakarta.activation.MimeType' (OnClassCondition)

   MailSenderValidatorAutoConfiguration:
      Did not match:
         - @ConditionalOnSingleCandidate did not find required type 'org.springframework.mail.javamail.JavaMailSenderImpl' (OnBeanCondition)

   MessageSourceAutoConfiguration:
      Did not match:
         - ResourceBundle did not find bundle with basename messages (MessageSourceAutoConfiguration.ResourceBundleCondition)

   MongoAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.mongodb.client.MongoClient' (OnClassCondition)

   MongoDataAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.mongodb.client.MongoClient' (OnClassCondition)

   MongoReactiveAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.mongodb.reactivestreams.client.MongoClient' (OnClassCondition)

   MongoReactiveDataAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.mongodb.reactivestreams.client.MongoClient' (OnClassCondition)

   MongoReactiveRepositoriesAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.mongodb.reactivestreams.client.MongoClient' (OnClassCondition)

   MongoRepositoriesAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.mongodb.client.MongoClient' (OnClassCondition)

   MultipartAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'jakarta.servlet.MultipartConfigElement' (OnClassCondition)

   MustacheAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.samskivert.mustache.Mustache' (OnClassCondition)

   Neo4jAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.neo4j.driver.Driver' (OnClassCondition)

   Neo4jDataAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.neo4j.driver.Driver' (OnClassCondition)

   Neo4jReactiveDataAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.neo4j.driver.Driver' (OnClassCondition)

   Neo4jReactiveRepositoriesAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.neo4j.driver.Driver' (OnClassCondition)

   Neo4jRepositoriesAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.neo4j.driver.Driver' (OnClassCondition)

   OAuth2ClientAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.security.config.annotation.web.configuration.EnableWebSecurity' (OnClassCondition)

   OAuth2ResourceServerAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.security.oauth2.server.resource.authentication.BearerTokenAuthenticationToken' (OnClassCondition)

   ProjectInfoAutoConfiguration#buildProperties:
      Did not match:
         - @ConditionalOnResource did not find resource '${spring.info.build.location:classpath:META-INF/build-info.properties}' (OnResourceCondition)

   ProjectInfoAutoConfiguration#gitProperties:
      Did not match:
         - GitResource did not find git info at classpath:git.properties (ProjectInfoAutoConfiguration.GitResourceAvailableCondition)

   QuartzAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.quartz.Scheduler' (OnClassCondition)

   R2dbcAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'io.r2dbc.spi.ConnectionFactory' (OnClassCondition)

   R2dbcDataAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.data.r2dbc.core.R2dbcEntityTemplate' (OnClassCondition)

   R2dbcInitializationConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required classes 'io.r2dbc.spi.ConnectionFactory', 'org.springframework.r2dbc.connection.init.DatabasePopulator' (OnClassCondition)

   R2dbcRepositoriesAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'io.r2dbc.spi.ConnectionFactory' (OnClassCondition)

   R2dbcTransactionManagerAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.r2dbc.connection.R2dbcTransactionManager' (OnClassCondition)

   RSocketGraphQlClientAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'graphql.GraphQL' (OnClassCondition)

   RSocketMessagingAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'io.rsocket.RSocket' (OnClassCondition)

   RSocketRequesterAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'io.rsocket.RSocket' (OnClassCondition)

   RSocketSecurityAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.security.rsocket.core.SecuritySocketAcceptorInterceptor' (OnClassCondition)

   RSocketServerAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'io.rsocket.core.RSocketServer' (OnClassCondition)

   RSocketStrategiesAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'io.rsocket.RSocket' (OnClassCondition)

   RabbitAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.rabbitmq.client.Channel' (OnClassCondition)

   ReactiveElasticsearchClientAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'co.elastic.clients.transport.ElasticsearchTransport' (OnClassCondition)

   ReactiveElasticsearchRepositoriesAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.data.elasticsearch.client.elc.ReactiveElasticsearchClient' (OnClassCondition)

   ReactiveOAuth2ClientAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.security.config.annotation.web.reactive.EnableWebFluxSecurity' (OnClassCondition)

   ReactiveOAuth2ResourceServerAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.security.config.annotation.web.reactive.EnableWebFluxSecurity' (OnClassCondition)

   ReactiveSecurityAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.security.config.annotation.web.reactive.EnableWebFluxSecurity' (OnClassCondition)

   ReactiveUserDetailsServiceAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.security.authentication.ReactiveAuthenticationManager' (OnClassCondition)

   ReactiveWebServerFactoryAutoConfiguration#forwardedHeaderTransformer:
      Did not match:
         - @ConditionalOnProperty (server.forward-headers-strategy=framework) did not find property 'server.forward-headers-strategy' (OnPropertyCondition)

   ReactiveWebServerFactoryAutoConfiguration#tomcatReactiveWebServerFactoryCustomizer:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.apache.catalina.startup.Tomcat' (OnClassCondition)

   ReactiveWebServerFactoryConfiguration.EmbeddedJetty:
      Did not match:
         - @ConditionalOnClass did not find required classes 'org.eclipse.jetty.server.Server', 'org.eclipse.jetty.servlet.ServletHolder' (OnClassCondition)

   ReactiveWebServerFactoryConfiguration.EmbeddedTomcat:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.apache.catalina.startup.Tomcat' (OnClassCondition)

   ReactiveWebServerFactoryConfiguration.EmbeddedUndertow:
      Did not match:
         - @ConditionalOnClass did not find required class 'io.undertow.Undertow' (OnClassCondition)

   RedisAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.data.redis.core.RedisOperations' (OnClassCondition)

   RedisCacheConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.data.redis.connection.RedisConnectionFactory' (OnClassCondition)

   RedisReactiveAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.data.redis.connection.ReactiveRedisConnectionFactory' (OnClassCondition)

   RedisRepositoriesAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.data.redis.repository.configuration.EnableRedisRepositories' (OnClassCondition)

   RepositoryRestMvcAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.data.rest.webmvc.config.RepositoryRestMvcConfiguration' (OnClassCondition)

   RestTemplateAutoConfiguration:
      Did not match:
         - NoneNestedConditions 1 matched 0 did not; NestedCondition on RestTemplateAutoConfiguration.NotReactiveWebApplicationCondition.ReactiveWebApplication found ConfigurableReactiveWebEnvironment (RestTemplateAutoConfiguration.NotReactiveWebApplicationCondition)
      Matched:
         - @ConditionalOnClass found required class 'org.springframework.web.client.RestTemplate' (OnClassCondition)

   Saml2RelyingPartyAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.security.saml2.provider.service.registration.RelyingPartyRegistrationRepository' (OnClassCondition)

   SecurityAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.security.authentication.DefaultAuthenticationEventPublisher' (OnClassCondition)

   SecurityFilterAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.security.config.http.SessionCreationPolicy' (OnClassCondition)

   SendGridAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.sendgrid.SendGrid' (OnClassCondition)

   ServletWebServerFactoryAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'jakarta.servlet.ServletRequest' (OnClassCondition)

   SessionAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.session.Session' (OnClassCondition)

   SpringDataWebAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.data.web.PageableHandlerMethodArgumentResolver' (OnClassCondition)

   TaskSchedulingAutoConfiguration#scheduledBeanLazyInitializationExcludeFilter:
      Did not match:
         - @ConditionalOnBean (names: org.springframework.context.annotation.internalScheduledAnnotationProcessor; SearchStrategy: all) did not find any beans named org.springframework.context.annotation.internalScheduledAnnotationProcessor (OnBeanCondition)

   TaskSchedulingAutoConfiguration#taskScheduler:
      Did not match:
         - @ConditionalOnBean (names: org.springframework.context.annotation.internalScheduledAnnotationProcessor; SearchStrategy: all) did not find any beans named org.springframework.context.annotation.internalScheduledAnnotationProcessor (OnBeanCondition)

   ThymeleafAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.thymeleaf.spring6.SpringTemplateEngine' (OnClassCondition)

   TransactionAutoConfiguration#transactionalOperator:
      Did not match:
         - @ConditionalOnSingleCandidate (types: org.springframework.transaction.ReactiveTransactionManager; SearchStrategy: all) did not find any beans (OnBeanCondition)

   TransactionAutoConfiguration.EnableTransactionManagementConfiguration:
      Did not match:
         - @ConditionalOnBean (types: org.springframework.transaction.TransactionManager; SearchStrategy: all) did not find any beans of type org.springframework.transaction.TransactionManager (OnBeanCondition)

   TransactionAutoConfiguration.EnableTransactionManagementConfiguration.CglibAutoProxyConfiguration:
      Did not match:
         - Ancestor org.springframework.boot.autoconfigure.transaction.TransactionAutoConfiguration$EnableTransactionManagementConfiguration did not match (ConditionEvaluationReport.AncestorsMatchedCondition)
      Matched:
         - @ConditionalOnProperty (spring.aop.proxy-target-class=true) matched (OnPropertyCondition)

   TransactionAutoConfiguration.EnableTransactionManagementConfiguration.JdkDynamicAutoProxyConfiguration:
      Did not match:
         - @ConditionalOnProperty (spring.aop.proxy-target-class=false) did not find property 'proxy-target-class' (OnPropertyCondition)
         - Ancestor org.springframework.boot.autoconfigure.transaction.TransactionAutoConfiguration$EnableTransactionManagementConfiguration did not match (ConditionEvaluationReport.AncestorsMatchedCondition)

   TransactionAutoConfiguration.TransactionTemplateConfiguration:
      Did not match:
         - @ConditionalOnSingleCandidate (types: org.springframework.transaction.PlatformTransactionManager; SearchStrategy: all) did not find any beans (OnBeanCondition)

   TwitterKafkaStreamRunner:
      Did not match:
         - @ConditionalOnProperty (twitter-to-kafka-service.enable-mock-tweets=false) found different value in property 'twitter-to-kafka-service.enable-mock-tweets' (OnPropertyCondition)

   UserDetailsServiceAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.security.authentication.AuthenticationManager' (OnClassCondition)

   ValidationAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'jakarta.validation.executable.ExecutableValidator' (OnClassCondition)

   WebFluxAutoConfiguration#hiddenHttpMethodFilter:
      Did not match:
         - @ConditionalOnProperty (spring.webflux.hiddenmethod.filter.enabled) did not find property 'enabled' (OnPropertyCondition)

   WebFluxAutoConfiguration.ProblemDetailsErrorHandlingConfiguration:
      Did not match:
         - @ConditionalOnProperty (spring.webflux.problemdetails.enabled=true) did not find property 'enabled' (OnPropertyCondition)

   WebFluxAutoConfiguration.ResourceChainCustomizerConfiguration:
      Did not match:
         - @ConditionalOnEnabledResourceChain did not find class org.webjars.WebJarAssetLocator (OnEnabledResourceChainCondition)

   WebMvcAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'jakarta.servlet.Servlet' (OnClassCondition)

   WebServiceTemplateAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.oxm.Marshaller' (OnClassCondition)

   WebServicesAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.ws.transport.http.MessageDispatcherServlet' (OnClassCondition)

   WebSocketMessagingAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.web.socket.config.annotation.WebSocketMessageBrokerConfigurer' (OnClassCondition)

   WebSocketReactiveAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'jakarta.servlet.Servlet' (OnClassCondition)

   WebSocketServletAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'jakarta.servlet.Servlet' (OnClassCondition)

   XADataSourceAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'jakarta.transaction.TransactionManager' (OnClassCondition)


Exclusions:
-----------

    None


Unconditional classes:
----------------------

    org.springframework.boot.autoconfigure.context.ConfigurationPropertiesAutoConfiguration

    org.springframework.boot.autoconfigure.context.LifecycleAutoConfiguration

    org.springframework.boot.autoconfigure.context.PropertyPlaceholderAutoConfiguration

    org.springframework.boot.autoconfigure.availability.ApplicationAvailabilityAutoConfiguration

    org.springframework.boot.autoconfigure.info.ProjectInfoAutoConfiguration



2023-03-04 00:14:08 [main] INFO  x.g.m.d.t.t.k.s.TwitterToKafkaServiceApplication - Started TwitterToKafkaServiceApplication in 2.489 seconds (process running for 3.451)
2023-03-04 00:14:08 [main] DEBUG o.s.b.a.ApplicationAvailabilityBean - Application availability state LivenessState changed to CORRECT
2023-03-04 00:14:08 [main] INFO  x.g.m.d.t.t.k.s.TwitterToKafkaServiceApplication - Application started!
2023-03-04 00:14:08 [main] DEBUG o.s.retry.support.RetryTemplate - Retry: count=0
2023-03-04 00:14:08 [main] INFO  x.g.m.d.k.a.client.KafkaAdminClient - Creating 1 topic(s), attempt 0
2023-03-04 00:14:08 [main] DEBUG o.a.k.clients.admin.KafkaAdminClient - [AdminClient clientId=adminclient-1] Queueing Call(callName=createTopics, deadlineMs=1677876308968, tries=0, nextAllowedTryMs=0) with a timeout 30000 ms from now.
2023-03-04 00:14:08 [main] DEBUG o.s.retry.support.RetryTemplate - Retry: count=0
2023-03-04 00:14:08 [kafka-admin-client-thread | adminclient-1] DEBUG o.apache.kafka.clients.ClientUtils - Resolved host localhost as 127.0.0.1
2023-03-04 00:14:08 [main] INFO  x.g.m.d.k.a.client.KafkaAdminClient - Reading kafka topic [twitter-topic], attempt 0
2023-03-04 00:14:08 [kafka-admin-client-thread | adminclient-1] DEBUG o.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Initiating connection to node localhost:39092 (id: 3 rack: null) using address localhost/127.0.0.1
2023-03-04 00:14:08 [main] DEBUG o.a.k.clients.admin.KafkaAdminClient - [AdminClient clientId=adminclient-1] Queueing Call(callName=listTopics, deadlineMs=1677876308973, tries=0, nextAllowedTryMs=0) with a timeout 30000 ms from now.
2023-03-04 00:14:08 [kafka-admin-client-thread | adminclient-1] DEBUG o.a.kafka.common.network.Selector - [AdminClient clientId=adminclient-1] Created socket with SO_RCVBUF = 342972, SO_SNDBUF = 146988, SO_TIMEOUT = 0 to node 3
2023-03-04 00:14:08 [kafka-admin-client-thread | adminclient-1] DEBUG o.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Completed connection to node 3. Fetching API versions.
2023-03-04 00:14:08 [kafka-admin-client-thread | adminclient-1] DEBUG o.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Initiating API versions fetch from node 3.
2023-03-04 00:14:08 [kafka-admin-client-thread | adminclient-1] DEBUG o.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Sending API_VERSIONS request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=adminclient-1, correlationId=3) and timeout 3600000 to node 3: ApiVersionsRequestData(clientSoftwareName='apache-kafka-java', clientSoftwareVersion='3.3.2')
2023-03-04 00:14:09 [kafka-admin-client-thread | adminclient-1] DEBUG o.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Received API_VERSIONS response from node 3 for request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=adminclient-1, correlationId=3): ApiVersionsResponseData(errorCode=35, apiKeys=[], throttleTimeMs=0, supportedFeatures=[], finalizedFeaturesEpoch=-1, finalizedFeatures=[])
2023-03-04 00:14:09 [kafka-admin-client-thread | adminclient-1] DEBUG o.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Initiating API versions fetch from node 3.
2023-03-04 00:14:09 [kafka-admin-client-thread | adminclient-1] DEBUG o.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Sending API_VERSIONS request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=0, clientId=adminclient-1, correlationId=4) and timeout 3600000 to node 3: ApiVersionsRequestData(clientSoftwareName='apache-kafka-java', clientSoftwareVersion='3.3.2')
2023-03-04 00:14:09 [kafka-admin-client-thread | adminclient-1] DEBUG o.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Received API_VERSIONS response from node 3 for request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=0, clientId=adminclient-1, correlationId=4): ApiVersionsResponseData(errorCode=0, apiKeys=[ApiVersion(apiKey=0, minVersion=0, maxVersion=6), ApiVersion(apiKey=1, minVersion=0, maxVersion=8), ApiVersion(apiKey=2, minVersion=0, maxVersion=3), ApiVersion(apiKey=3, minVersion=0, maxVersion=6), ApiVersion(apiKey=4, minVersion=0, maxVersion=1), ApiVersion(apiKey=5, minVersion=0, maxVersion=0), ApiVersion(apiKey=6, minVersion=0, maxVersion=4), ApiVersion(apiKey=7, minVersion=0, maxVersion=1), ApiVersion(apiKey=8, minVersion=0, maxVersion=4), ApiVersion(apiKey=9, minVersion=0, maxVersion=4), ApiVersion(apiKey=10, minVersion=0, maxVersion=2), ApiVersion(apiKey=11, minVersion=0, maxVersion=3), ApiVersion(apiKey=12, minVersion=0, maxVersion=2), ApiVersion(apiKey=13, minVersion=0, maxVersion=2), ApiVersion(apiKey=14, minVersion=0, maxVersion=2), ApiVersion(apiKey=15, minVersion=0, maxVersion=2), ApiVersion(apiKey=16, minVersion=0, maxVersion=2), ApiVersion(apiKey=17, minVersion=0, maxVersion=1), ApiVersion(apiKey=18, minVersion=0, maxVersion=2), ApiVersion(apiKey=19, minVersion=0, maxVersion=3), ApiVersion(apiKey=20, minVersion=0, maxVersion=2), ApiVersion(apiKey=21, minVersion=0, maxVersion=1), ApiVersion(apiKey=22, minVersion=0, maxVersion=1), ApiVersion(apiKey=23, minVersion=0, maxVersion=1), ApiVersion(apiKey=24, minVersion=0, maxVersion=1), ApiVersion(apiKey=25, minVersion=0, maxVersion=1), ApiVersion(apiKey=26, minVersion=0, maxVersion=1), ApiVersion(apiKey=27, minVersion=0, maxVersion=0), ApiVersion(apiKey=28, minVersion=0, maxVersion=1), ApiVersion(apiKey=29, minVersion=0, maxVersion=1), ApiVersion(apiKey=30, minVersion=0, maxVersion=1), ApiVersion(apiKey=31, minVersion=0, maxVersion=1), ApiVersion(apiKey=32, minVersion=0, maxVersion=2), ApiVersion(apiKey=33, minVersion=0, maxVersion=1), ApiVersion(apiKey=34, minVersion=0, maxVersion=1), ApiVersion(apiKey=35, minVersion=0, maxVersion=1), ApiVersion(apiKey=36, minVersion=0, maxVersion=0), ApiVersion(apiKey=37, minVersion=0, maxVersion=1), ApiVersion(apiKey=38, minVersion=0, maxVersion=1), ApiVersion(apiKey=39, minVersion=0, maxVersion=1), ApiVersion(apiKey=40, minVersion=0, maxVersion=1), ApiVersion(apiKey=41, minVersion=0, maxVersion=1), ApiVersion(apiKey=42, minVersion=0, maxVersion=1)], throttleTimeMs=0, supportedFeatures=[], finalizedFeaturesEpoch=-1, finalizedFeatures=[])
2023-03-04 00:14:09 [kafka-admin-client-thread | adminclient-1] DEBUG o.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Node 3 has finalized features epoch: -1, finalized features: [], supported features: [], API versions: (Produce(0): 0 to 6 [usable: 6], Fetch(1): 0 to 8 [usable: 8], ListOffsets(2): 0 to 3 [usable: 3], Metadata(3): 0 to 6 [usable: 6], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 4 [usable: 4], OffsetFetch(9): 0 to 4 [usable: 4], FindCoordinator(10): 0 to 2 [usable: 2], JoinGroup(11): 0 to 3 [usable: 3], Heartbeat(12): 0 to 2 [usable: 2], LeaveGroup(13): 0 to 2 [usable: 2], SyncGroup(14): 0 to 2 [usable: 2], DescribeGroups(15): 0 to 2 [usable: 2], ListGroups(16): 0 to 2 [usable: 2], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 2], CreateTopics(19): 0 to 3 [usable: 3], DeleteTopics(20): 0 to 2 [usable: 2], DeleteRecords(21): 0 to 1 [usable: 1], InitProducerId(22): 0 to 1 [usable: 1], OffsetForLeaderEpoch(23): 0 to 1 [usable: 1], AddPartitionsToTxn(24): 0 to 1 [usable: 1], AddOffsetsToTxn(25): 0 to 1 [usable: 1], EndTxn(26): 0 to 1 [usable: 1], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 1 [usable: 1], DescribeAcls(29): 0 to 1 [usable: 1], CreateAcls(30): 0 to 1 [usable: 1], DeleteAcls(31): 0 to 1 [usable: 1], DescribeConfigs(32): 0 to 2 [usable: 2], AlterConfigs(33): 0 to 1 [usable: 1], AlterReplicaLogDirs(34): 0 to 1 [usable: 1], DescribeLogDirs(35): 0 to 1 [usable: 1], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 1], CreateDelegationToken(38): 0 to 1 [usable: 1], RenewDelegationToken(39): 0 to 1 [usable: 1], ExpireDelegationToken(40): 0 to 1 [usable: 1], DescribeDelegationToken(41): 0 to 1 [usable: 1], DeleteGroups(42): 0 to 1 [usable: 1], ElectLeaders(43): UNSUPPORTED, IncrementalAlterConfigs(44): UNSUPPORTED, AlterPartitionReassignments(45): UNSUPPORTED, ListPartitionReassignments(46): UNSUPPORTED, OffsetDelete(47): UNSUPPORTED, DescribeClientQuotas(48): UNSUPPORTED, AlterClientQuotas(49): UNSUPPORTED, DescribeUserScramCredentials(50): UNSUPPORTED, AlterUserScramCredentials(51): UNSUPPORTED, AlterPartition(56): UNSUPPORTED, UpdateFeatures(57): UNSUPPORTED, DescribeCluster(60): UNSUPPORTED, DescribeProducers(61): UNSUPPORTED, DescribeTransactions(65): UNSUPPORTED, ListTransactions(66): UNSUPPORTED, AllocateProducerIds(67): UNSUPPORTED).
2023-03-04 00:14:09 [kafka-admin-client-thread | adminclient-1] DEBUG o.a.k.clients.admin.KafkaAdminClient - [AdminClient clientId=adminclient-1] Sending CreateTopicsRequestData(topics=[CreatableTopic(name='twitter-topic', numPartitions=3, replicationFactor=3, assignments=[], configs=[])], timeoutMs=29949, validateOnly=false) to localhost:39092 (id: 3 rack: null). correlationId=5, timeoutMs=29949
2023-03-04 00:14:09 [kafka-admin-client-thread | adminclient-1] DEBUG o.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Sending CREATE_TOPICS request with header RequestHeader(apiKey=CREATE_TOPICS, apiVersion=3, clientId=adminclient-1, correlationId=5) and timeout 29949 to node 3: CreateTopicsRequestData(topics=[CreatableTopic(name='twitter-topic', numPartitions=3, replicationFactor=3, assignments=[], configs=[])], timeoutMs=29949, validateOnly=false)
2023-03-04 00:14:09 [kafka-admin-client-thread | adminclient-1] DEBUG o.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Received CREATE_TOPICS response from node 3 for request with header RequestHeader(apiKey=CREATE_TOPICS, apiVersion=3, clientId=adminclient-1, correlationId=5): CreateTopicsResponseData(throttleTimeMs=0, topics=[CreatableTopicResult(name='twitter-topic', topicId=AAAAAAAAAAAAAAAAAAAAAA, errorCode=36, errorMessage='Topic 'twitter-topic' already exists.', topicConfigErrorCode=0, numPartitions=-1, replicationFactor=-1, configs=[])])
2023-03-04 00:14:09 [kafka-admin-client-thread | adminclient-1] DEBUG o.a.k.clients.admin.KafkaAdminClient - [AdminClient clientId=adminclient-1] Sending MetadataRequestData(topics=null, allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to localhost:39092 (id: 3 rack: null). correlationId=6, timeoutMs=30000
2023-03-04 00:14:09 [kafka-admin-client-thread | adminclient-1] DEBUG o.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Sending METADATA request with header RequestHeader(apiKey=METADATA, apiVersion=6, clientId=adminclient-1, correlationId=6) and timeout 30000 to node 3: MetadataRequestData(topics=null, allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false)
2023-03-04 00:14:09 [kafka-admin-client-thread | adminclient-1] DEBUG o.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Received METADATA response from node 3 for request with header RequestHeader(apiKey=METADATA, apiVersion=6, clientId=adminclient-1, correlationId=6): MetadataResponseData(throttleTimeMs=0, brokers=[MetadataResponseBroker(nodeId=2, host='localhost', port=29092, rack=null), MetadataResponseBroker(nodeId=1, host='localhost', port=19092, rack=null), MetadataResponseBroker(nodeId=3, host='localhost', port=39092, rack=null)], clusterId='QGDYypu5SSGtA9Bc36Rjow', controllerId=3, topics=[MetadataResponseTopic(errorCode=0, name='__confluent.support.metrics', topicId=AAAAAAAAAAAAAAAAAAAAAA, isInternal=false, partitions=[MetadataResponsePartition(errorCode=0, partitionIndex=0, leaderId=2, leaderEpoch=-1, replicaNodes=[2, 3], isrNodes=[2, 3], offlineReplicas=[])], topicAuthorizedOperations=-2147483648), MetadataResponseTopic(errorCode=0, name='_schemas', topicId=AAAAAAAAAAAAAAAAAAAAAA, isInternal=false, partitions=[MetadataResponsePartition(errorCode=0, partitionIndex=0, leaderId=3, leaderEpoch=-1, replicaNodes=[3, 1, 2], isrNodes=[3, 2, 1], offlineReplicas=[])], topicAuthorizedOperations=-2147483648), MetadataResponseTopic(errorCode=0, name='twitter-topic', topicId=AAAAAAAAAAAAAAAAAAAAAA, isInternal=false, partitions=[MetadataResponsePartition(errorCode=0, partitionIndex=2, leaderId=3, leaderEpoch=-1, replicaNodes=[3, 2, 1], isrNodes=[3, 2, 1], offlineReplicas=[]), MetadataResponsePartition(errorCode=0, partitionIndex=1, leaderId=1, leaderEpoch=-1, replicaNodes=[1, 3, 2], isrNodes=[1, 3, 2], offlineReplicas=[]), MetadataResponsePartition(errorCode=0, partitionIndex=0, leaderId=2, leaderEpoch=-1, replicaNodes=[2, 1, 3], isrNodes=[2, 1, 3], offlineReplicas=[])], topicAuthorizedOperations=-2147483648)], clusterAuthorizedOperations=-2147483648)
2023-03-04 00:14:09 [main] DEBUG o.s.w.r.f.client.ExchangeFunctions - [35bfa1bb] HTTP GET http://localhost:8081
2023-03-04 00:14:09 [main] DEBUG i.n.r.DefaultHostsFileEntriesResolver - -Dio.netty.hostsFileRefreshInterval: 0
2023-03-04 00:14:09 [main] DEBUG i.n.u.internal.NativeLibraryLoader - -Dio.netty.native.workdir: /var/folders/zx/4g777wp55pg8j62jnpqrd9dh0000gn/T (io.netty.tmpdir)
2023-03-04 00:14:09 [main] DEBUG i.n.u.internal.NativeLibraryLoader - -Dio.netty.native.deleteLibAfterLoading: true
2023-03-04 00:14:09 [main] DEBUG i.n.u.internal.NativeLibraryLoader - -Dio.netty.native.tryPatchShadedId: true
2023-03-04 00:14:09 [main] DEBUG i.n.u.internal.NativeLibraryLoader - -Dio.netty.native.detectNativeLibraryDuplicates: true
2023-03-04 00:14:09 [main] DEBUG i.n.u.internal.NativeLibraryLoader - Successfully loaded the library /var/folders/zx/4g777wp55pg8j62jnpqrd9dh0000gn/T/libnetty_resolver_dns_native_macos_x86_647281424250628094661.dylib
2023-03-04 00:14:09 [main] DEBUG i.n.r.d.DnsServerAddressStreamProviders - io.netty.resolver.dns.macos.MacOSDnsServerAddressStreamProvider: available
2023-03-04 00:14:09 [main] DEBUG r.n.r.PooledConnectionProvider - Creating a new [http] client pool [PoolFactory{evictionInterval=PT0S, leasingStrategy=fifo, maxConnections=500, maxIdleTime=-1, maxLifeTime=-1, metricsEnabled=false, pendingAcquireMaxCount=1000, pendingAcquireTimeout=45000}] for [localhost/<unresolved>:8081]
2023-03-04 00:14:09 [reactor-http-nio-3] DEBUG r.n.r.PooledConnectionProvider - [87a1735e] Created a new pooled channel, now: 0 active connections, 0 inactive connections and 0 pending acquire requests.
2023-03-04 00:14:09 [reactor-http-nio-3] DEBUG io.netty.buffer.AbstractByteBuf - -Dio.netty.buffer.checkAccessible: true
2023-03-04 00:14:09 [reactor-http-nio-3] DEBUG io.netty.buffer.AbstractByteBuf - -Dio.netty.buffer.checkBounds: true
2023-03-04 00:14:09 [reactor-http-nio-3] DEBUG i.n.util.ResourceLeakDetectorFactory - Loaded default ResourceLeakDetector: io.netty.util.ResourceLeakDetector@134a5fdf
2023-03-04 00:14:09 [reactor-http-nio-3] DEBUG r.netty.transport.TransportConfig - [87a1735e] Initialized pipeline DefaultChannelPipeline{(reactor.left.httpCodec = io.netty.handler.codec.http.HttpClientCodec), (reactor.left.httpDecompressor = io.netty.handler.codec.http.HttpContentDecompressor), (reactor.right.reactiveBridge = reactor.netty.channel.ChannelOperationsHandler)}
2023-03-04 00:14:09 [reactor-http-nio-3] DEBUG r.netty.transport.TransportConnector - [87a1735e] Connecting to [localhost/127.0.0.1:8081].
2023-03-04 00:14:09 [reactor-http-nio-3] DEBUG r.n.r.DefaultPooledConnectionProvider - [87a1735e, L:/127.0.0.1:51720 - R:localhost/127.0.0.1:8081] Registering pool release on close event for channel
2023-03-04 00:14:09 [reactor-http-nio-3] DEBUG r.n.r.PooledConnectionProvider - [87a1735e, L:/127.0.0.1:51720 - R:localhost/127.0.0.1:8081] Channel connected, now: 1 active connections, 0 inactive connections and 0 pending acquire requests.
2023-03-04 00:14:09 [reactor-http-nio-3] DEBUG r.n.r.DefaultPooledConnectionProvider - [87a1735e, L:/127.0.0.1:51720 - R:localhost/127.0.0.1:8081] onStateChange(PooledConnection{channel=[id: 0x87a1735e, L:/127.0.0.1:51720 - R:localhost/127.0.0.1:8081]}, [connected])
2023-03-04 00:14:09 [reactor-http-nio-3] DEBUG r.n.r.DefaultPooledConnectionProvider - [87a1735e-1, L:/127.0.0.1:51720 - R:localhost/127.0.0.1:8081] onStateChange(GET{uri=null, connection=PooledConnection{channel=[id: 0x87a1735e, L:/127.0.0.1:51720 - R:localhost/127.0.0.1:8081]}}, [configured])
2023-03-04 00:14:09 [reactor-http-nio-3] DEBUG r.n.http.client.HttpClientConnect - [87a1735e-1, L:/127.0.0.1:51720 - R:localhost/127.0.0.1:8081] Handler is being applied: {uri=http://localhost:8081/, method=GET}
2023-03-04 00:14:09 [reactor-http-nio-3] DEBUG r.n.r.DefaultPooledConnectionProvider - [87a1735e-1, L:/127.0.0.1:51720 - R:localhost/127.0.0.1:8081] onStateChange(GET{uri=/, connection=PooledConnection{channel=[id: 0x87a1735e, L:/127.0.0.1:51720 - R:localhost/127.0.0.1:8081]}}, [request_prepared])
2023-03-04 00:14:09 [reactor-http-nio-3] DEBUG io.netty.util.Recycler - -Dio.netty.recycler.maxCapacityPerThread: 4096
2023-03-04 00:14:09 [reactor-http-nio-3] DEBUG io.netty.util.Recycler - -Dio.netty.recycler.ratio: 8
2023-03-04 00:14:09 [reactor-http-nio-3] DEBUG io.netty.util.Recycler - -Dio.netty.recycler.chunkSize: 32
2023-03-04 00:14:09 [reactor-http-nio-3] DEBUG io.netty.util.Recycler - -Dio.netty.recycler.blocking: false
2023-03-04 00:14:09 [reactor-http-nio-3] DEBUG io.netty.util.Recycler - -Dio.netty.recycler.batchFastThreadLocalOnly: true
2023-03-04 00:14:09 [reactor-http-nio-3] DEBUG r.n.r.DefaultPooledConnectionProvider - [87a1735e-1, L:/127.0.0.1:51720 - R:localhost/127.0.0.1:8081] onStateChange(GET{uri=/, connection=PooledConnection{channel=[id: 0x87a1735e, L:/127.0.0.1:51720 - R:localhost/127.0.0.1:8081]}}, [request_sent])
2023-03-04 00:14:09 [reactor-http-nio-3] DEBUG i.n.handler.codec.compression.Brotli - brotli4j not in the classpath; Brotli support will be unavailable.
2023-03-04 00:14:09 [reactor-http-nio-3] DEBUG r.n.http.client.HttpClientOperations - [87a1735e-1, L:/127.0.0.1:51720 - R:localhost/127.0.0.1:8081] Received response (auto-read:false) : RESPONSE(decodeResult: success, version: HTTP/1.1)
HTTP/1.1 200 OK
Date: <filtered>
Content-Type: <filtered>
Content-Length: <filtered>
Server: <filtered>
2023-03-04 00:14:09 [reactor-http-nio-3] DEBUG r.n.r.DefaultPooledConnectionProvider - [87a1735e-1, L:/127.0.0.1:51720 - R:localhost/127.0.0.1:8081] onStateChange(GET{uri=/, connection=PooledConnection{channel=[id: 0x87a1735e, L:/127.0.0.1:51720 - R:localhost/127.0.0.1:8081]}}, [response_received])
2023-03-04 00:14:09 [reactor-http-nio-3] DEBUG o.s.w.r.f.client.ExchangeFunctions - [35bfa1bb] [87a1735e-1, L:/127.0.0.1:51720 - R:localhost/127.0.0.1:8081] Response 200 OK
2023-03-04 00:14:09 [main] INFO  x.g.m.d.t.t.k.s.i.i.KafkaStreamInitializer - Topics with name twitter-topic is ready for operations.
2023-03-04 00:14:09 [main] INFO  x.g.m.d.t.t.k.s.r.i.MockKafkaStreamRunner - Start to mock twitter stream for keywords: [Java, Microservices, Spring, Kafka, Elasticsearch]
2023-03-04 00:14:09 [main] DEBUG o.s.b.a.ApplicationAvailabilityBean - Application availability state ReadinessState changed to ACCEPTING_TRAFFIC
2023-03-04 00:14:09 [reactor-http-nio-3] DEBUG r.n.http.client.HttpClientOperations - [87a1735e-1, L:/127.0.0.1:51720 - R:localhost/127.0.0.1:8081] Received last HTTP packet
2023-03-04 00:14:09 [reactor-http-nio-3] DEBUG r.n.r.DefaultPooledConnectionProvider - [87a1735e, L:/127.0.0.1:51720 - R:localhost/127.0.0.1:8081] onStateChange(GET{uri=/, connection=PooledConnection{channel=[id: 0x87a1735e, L:/127.0.0.1:51720 - R:localhost/127.0.0.1:8081]}}, [response_completed])
2023-03-04 00:14:09 [reactor-http-nio-3] DEBUG r.n.r.DefaultPooledConnectionProvider - [87a1735e, L:/127.0.0.1:51720 - R:localhost/127.0.0.1:8081] onStateChange(GET{uri=/, connection=PooledConnection{channel=[id: 0x87a1735e, L:/127.0.0.1:51720 - R:localhost/127.0.0.1:8081]}}, [disconnecting])
2023-03-04 00:14:09 [reactor-http-nio-3] DEBUG r.n.r.DefaultPooledConnectionProvider - [87a1735e, L:/127.0.0.1:51720 - R:localhost/127.0.0.1:8081] Releasing channel
2023-03-04 00:14:09 [reactor-http-nio-3] DEBUG r.n.r.PooledConnectionProvider - [87a1735e, L:/127.0.0.1:51720 - R:localhost/127.0.0.1:8081] Channel cleaned, now: 0 active connections, 1 inactive connections and 0 pending acquire requests.
2023-03-04 00:14:09 [pool-3-thread-1] DEBUG twitter4j.conf.ConfigurationBase - serialVersionUID: 6175546394599249696
2023-03-04 00:14:09 [pool-3-thread-1] DEBUG twitter4j.conf.ConfigurationBase - debug: true
2023-03-04 00:14:09 [pool-3-thread-1] DEBUG twitter4j.conf.ConfigurationBase - user: null
2023-03-04 00:14:09 [pool-3-thread-1] DEBUG twitter4j.conf.ConfigurationBase - password: null
2023-03-04 00:14:09 [pool-3-thread-1] DEBUG twitter4j.conf.ConfigurationBase - httpConf: MyHttpClientConfiguration{httpProxyHost='null', httpProxyUser='null', httpProxyPassword='null', httpProxyPort=-1, proxyType=HTTP, httpConnectionTimeout=20000, httpReadTimeout=120000, prettyDebug=false, gzipEnabled=true}
2023-03-04 00:14:09 [pool-3-thread-1] DEBUG twitter4j.conf.ConfigurationBase - httpStreamingReadTimeout: 40000
2023-03-04 00:14:09 [pool-3-thread-1] DEBUG twitter4j.conf.ConfigurationBase - httpRetryCount: 0
2023-03-04 00:14:09 [pool-3-thread-1] DEBUG twitter4j.conf.ConfigurationBase - httpRetryIntervalSeconds: 5
2023-03-04 00:14:09 [pool-3-thread-1] DEBUG twitter4j.conf.ConfigurationBase - oAuthConsumerKey: *********************
2023-03-04 00:14:09 [pool-3-thread-1] DEBUG twitter4j.conf.ConfigurationBase - oAuthConsumerSecret: ******************************************
2023-03-04 00:14:09 [pool-3-thread-1] DEBUG twitter4j.conf.ConfigurationBase - oAuthAccessToken: **************************************************
2023-03-04 00:14:09 [pool-3-thread-1] DEBUG twitter4j.conf.ConfigurationBase - oAuthAccessTokenSecret: ******************************************
2023-03-04 00:14:09 [pool-3-thread-1] DEBUG twitter4j.conf.ConfigurationBase - oAuth2TokenType: null
2023-03-04 00:14:09 [pool-3-thread-1] DEBUG twitter4j.conf.ConfigurationBase - oAuth2AccessToken: null
2023-03-04 00:14:09 [pool-3-thread-1] DEBUG twitter4j.conf.ConfigurationBase - oAuth2Scope: null
2023-03-04 00:14:09 [pool-3-thread-1] DEBUG twitter4j.conf.ConfigurationBase - oAuthRequestTokenURL: https://api.twitter.com/oauth/request_token
2023-03-04 00:14:09 [pool-3-thread-1] DEBUG twitter4j.conf.ConfigurationBase - oAuthAuthorizationURL: https://api.twitter.com/oauth/authorize
2023-03-04 00:14:09 [pool-3-thread-1] DEBUG twitter4j.conf.ConfigurationBase - oAuthAccessTokenURL: https://api.twitter.com/oauth/access_token
2023-03-04 00:14:09 [pool-3-thread-1] DEBUG twitter4j.conf.ConfigurationBase - oAuthAuthenticationURL: https://api.twitter.com/oauth/authenticate
2023-03-04 00:14:09 [pool-3-thread-1] DEBUG twitter4j.conf.ConfigurationBase - oAuth2TokenURL: https://api.twitter.com/oauth2/token
2023-03-04 00:14:09 [pool-3-thread-1] DEBUG twitter4j.conf.ConfigurationBase - oAuth2InvalidateTokenURL: https://api.twitter.com/oauth2/invalidate_token
2023-03-04 00:14:09 [pool-3-thread-1] DEBUG twitter4j.conf.ConfigurationBase - restBaseURL: https://api.twitter.com/1.1/
2023-03-04 00:14:09 [pool-3-thread-1] DEBUG twitter4j.conf.ConfigurationBase - streamBaseURL: https://stream.twitter.com/1.1/
2023-03-04 00:14:09 [pool-3-thread-1] DEBUG twitter4j.conf.ConfigurationBase - userStreamBaseURL: https://userstream.twitter.com/1.1/
2023-03-04 00:14:09 [pool-3-thread-1] DEBUG twitter4j.conf.ConfigurationBase - siteStreamBaseURL: https://sitestream.twitter.com/1.1/
2023-03-04 00:14:09 [pool-3-thread-1] DEBUG twitter4j.conf.ConfigurationBase - uploadBaseURL: https://upload.twitter.com/1.1/
2023-03-04 00:14:09 [pool-3-thread-1] DEBUG twitter4j.conf.ConfigurationBase - dispatcherImpl: twitter4j.DispatcherImpl
2023-03-04 00:14:09 [pool-3-thread-1] DEBUG twitter4j.conf.ConfigurationBase - asyncNumThreads: 1
2023-03-04 00:14:09 [pool-3-thread-1] DEBUG twitter4j.conf.ConfigurationBase - loggerFactory: null
2023-03-04 00:14:09 [pool-3-thread-1] DEBUG twitter4j.conf.ConfigurationBase - contributingTo: -1
2023-03-04 00:14:09 [pool-3-thread-1] DEBUG twitter4j.conf.ConfigurationBase - includeMyRetweetEnabled: true
2023-03-04 00:14:09 [pool-3-thread-1] DEBUG twitter4j.conf.ConfigurationBase - includeEntitiesEnabled: true
2023-03-04 00:14:09 [pool-3-thread-1] DEBUG twitter4j.conf.ConfigurationBase - trimUserEnabled: false
2023-03-04 00:14:09 [pool-3-thread-1] DEBUG twitter4j.conf.ConfigurationBase - includeExtAltTextEnabled: true
2023-03-04 00:14:09 [pool-3-thread-1] DEBUG twitter4j.conf.ConfigurationBase - tweetModeExtended: true
2023-03-04 00:14:09 [pool-3-thread-1] DEBUG twitter4j.conf.ConfigurationBase - includeEmailEnabled: false
2023-03-04 00:14:09 [pool-3-thread-1] DEBUG twitter4j.conf.ConfigurationBase - jsonStoreEnabled: false
2023-03-04 00:14:09 [pool-3-thread-1] DEBUG twitter4j.conf.ConfigurationBase - mbeanEnabled: false
2023-03-04 00:14:09 [pool-3-thread-1] DEBUG twitter4j.conf.ConfigurationBase - userStreamRepliesAllEnabled: false
2023-03-04 00:14:09 [pool-3-thread-1] DEBUG twitter4j.conf.ConfigurationBase - userStreamWithFollowingsEnabled: true
2023-03-04 00:14:09 [pool-3-thread-1] DEBUG twitter4j.conf.ConfigurationBase - stallWarningsEnabled: true
2023-03-04 00:14:09 [pool-3-thread-1] DEBUG twitter4j.conf.ConfigurationBase - applicationOnlyAuthEnabled: false
2023-03-04 00:14:09 [pool-3-thread-1] DEBUG twitter4j.conf.ConfigurationBase - mediaProvider: TWITTER
2023-03-04 00:14:09 [pool-3-thread-1] DEBUG twitter4j.conf.ConfigurationBase - mediaProviderAPIKey: null
2023-03-04 00:14:09 [pool-3-thread-1] DEBUG twitter4j.conf.ConfigurationBase - mediaProviderParameters: null
2023-03-04 00:14:09 [pool-3-thread-1] DEBUG twitter4j.conf.ConfigurationBase - daemonEnabled: true
2023-03-04 00:14:09 [pool-3-thread-1] DEBUG twitter4j.conf.ConfigurationBase - streamThreadName: 
2023-03-04 00:14:09 [pool-3-thread-1] DEBUG twitter4j.conf.ConfigurationBase - instances: [ConfigurationBase{debug=true, user='null', password='null', httpConf=MyHttpClientConfiguration{httpProxyHost='null', httpProxyUser='null', httpProxyPassword='null', httpProxyPort=-1, proxyType=HTTP, httpConnectionTimeout=20000, httpReadTimeout=120000, prettyDebug=false, gzipEnabled=true}, httpStreamingReadTimeout=40000, httpRetryCount=0, httpRetryIntervalSeconds=5, oAuthConsumerKey='*********************', oAuthConsumerSecret='******************************************', oAuthAccessToken='**************************************************', oAuthAccessTokenSecret='******************************************', oAuth2TokenType='null', oAuth2AccessToken='null', oAuth2Scope='null', oAuthRequestTokenURL='https://api.twitter.com/oauth/request_token', oAuthAuthorizationURL='https://api.twitter.com/oauth/authorize', oAuthAccessTokenURL='https://api.twitter.com/oauth/access_token', oAuthAuthenticationURL='https://api.twitter.com/oauth/authenticate', oAuth2TokenURL='https://api.twitter.com/oauth2/token', oAuth2InvalidateTokenURL='https://api.twitter.com/oauth2/invalidate_token', restBaseURL='https://api.twitter.com/1.1/', streamBaseURL='https://stream.twitter.com/1.1/', userStreamBaseURL='https://userstream.twitter.com/1.1/', siteStreamBaseURL='https://sitestream.twitter.com/1.1/', uploadBaseURL='https://upload.twitter.com/1.1/', dispatcherImpl='twitter4j.DispatcherImpl', asyncNumThreads=1, loggerFactory='null', contributingTo=-1, includeMyRetweetEnabled=true, includeEntitiesEnabled=true, trimUserEnabled=false, includeExtAltTextEnabled=true, tweetModeExtended=true, includeEmailEnabled=false, jsonStoreEnabled=false, mbeanEnabled=false, userStreamRepliesAllEnabled=false, userStreamWithFollowingsEnabled=true, stallWarningsEnabled=true, applicationOnlyAuthEnabled=false, mediaProvider='TWITTER', mediaProviderAPIKey='null', mediaProviderParameters=null, daemonEnabled=true, streamThreadName=''}]
2023-03-04 00:14:09 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text odio arcu in Elasticsearch non at sending to kafka topic twitter-topic
2023-03-04 00:14:09 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 1973790174311786209, "id": 6531461021457258466, "text": "odio arcu in Elasticsearch non at", "createdAt": 1677876249000}' to topic = 'twitter-topic'
2023-03-04 00:14:09 [pool-3-thread-1] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = -1
	batch.size = 1638400
	bootstrap.servers = [localhost:19092, localhost:29092, localhost:39092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = snappy
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.LongSerializer
	linger.ms = 5
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 60000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer

2023-03-04 00:14:09 [pool-3-thread-1] INFO  o.a.k.clients.producer.KafkaProducer - [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 0 ms.
2023-03-04 00:14:09 [pool-3-thread-1] INFO  o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2023-03-04 00:14:09 [pool-3-thread-1] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2023-03-04 00:14:09 [pool-3-thread-1] INFO  o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2023-03-04 00:14:09 [pool-3-thread-1] INFO  o.a.kafka.common.utils.AppInfoParser - App info kafka.producer for producer-1 unregistered
2023-03-04 00:14:09 [pool-3-thread-1] DEBUG o.a.k.clients.producer.KafkaProducer - [Producer clientId=producer-1] Kafka producer has been closed
2023-03-04 00:14:39 [reactor-http-nio-3] DEBUG r.n.r.DefaultPooledConnectionProvider - [87a1735e, L:/127.0.0.1:51720 ! R:localhost/127.0.0.1:8081] onStateChange(PooledConnection{channel=[id: 0x87a1735e, L:/127.0.0.1:51720 ! R:localhost/127.0.0.1:8081]}, [disconnecting])
2023-03-04 00:19:08 [kafka-admin-client-thread | adminclient-1] INFO  o.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Node -3 disconnected.
2023-03-04 00:19:08 [kafka-admin-client-thread | adminclient-1] DEBUG o.a.k.c.a.i.AdminMetadataManager - [AdminClient clientId=adminclient-1] Requesting metadata update.
2023-03-04 00:19:08 [kafka-admin-client-thread | adminclient-1] DEBUG o.a.k.clients.admin.KafkaAdminClient - [AdminClient clientId=adminclient-1] Sending MetadataRequestData(topics=[], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to localhost:39092 (id: 3 rack: null). correlationId=7, timeoutMs=30000
2023-03-04 00:19:08 [kafka-admin-client-thread | adminclient-1] DEBUG o.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Sending METADATA request with header RequestHeader(apiKey=METADATA, apiVersion=6, clientId=adminclient-1, correlationId=7) and timeout 30000 to node 3: MetadataRequestData(topics=[], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false)
2023-03-04 00:19:08 [kafka-admin-client-thread | adminclient-1] DEBUG o.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Received METADATA response from node 3 for request with header RequestHeader(apiKey=METADATA, apiVersion=6, clientId=adminclient-1, correlationId=7): MetadataResponseData(throttleTimeMs=0, brokers=[MetadataResponseBroker(nodeId=2, host='localhost', port=29092, rack=null), MetadataResponseBroker(nodeId=1, host='localhost', port=19092, rack=null), MetadataResponseBroker(nodeId=3, host='localhost', port=39092, rack=null)], clusterId='QGDYypu5SSGtA9Bc36Rjow', controllerId=3, topics=[], clusterAuthorizedOperations=-2147483648)
2023-03-04 00:19:08 [kafka-admin-client-thread | adminclient-1] DEBUG o.a.k.c.a.i.AdminMetadataManager - [AdminClient clientId=adminclient-1] Updating cluster metadata to Cluster(id = QGDYypu5SSGtA9Bc36Rjow, nodes = [localhost:19092 (id: 1 rack: null), localhost:29092 (id: 2 rack: null), localhost:39092 (id: 3 rack: null)], partitions = [], controller = localhost:39092 (id: 3 rack: null))
2023-03-04 00:21:05 [SpringApplicationShutdownHook] DEBUG o.s.b.a.ApplicationAvailabilityBean - Application availability state ReadinessState changed from ACCEPTING_TRAFFIC to REFUSING_TRAFFIC
2023-03-04 00:21:05 [SpringApplicationShutdownHook] DEBUG o.s.b.w.r.c.AnnotationConfigReactiveWebServerApplicationContext - Closing org.springframework.boot.web.reactive.context.AnnotationConfigReactiveWebServerApplicationContext@15cafec7, started on Sat Mar 04 00:14:06 IRST 2023
2023-03-04 00:21:05 [SpringApplicationShutdownHook] DEBUG o.s.c.s.DefaultLifecycleProcessor - Stopping beans in phase 2147483547
2023-03-04 00:21:05 [SpringApplicationShutdownHook] DEBUG o.s.c.s.DefaultLifecycleProcessor - Bean 'org.springframework.kafka.config.internalKafkaListenerEndpointRegistry' completed its stop procedure
2023-03-04 00:21:05 [SpringApplicationShutdownHook] DEBUG o.s.c.s.DefaultLifecycleProcessor - Stopping beans in phase 2147482623
2023-03-04 00:21:05 [SpringApplicationShutdownHook] DEBUG o.s.c.s.DefaultLifecycleProcessor - Bean 'webServerGracefulShutdown' completed its stop procedure
2023-03-04 00:21:05 [SpringApplicationShutdownHook] DEBUG o.s.c.s.DefaultLifecycleProcessor - Stopping beans in phase 2147481599
2023-03-04 00:21:05 [SpringApplicationShutdownHook] DEBUG o.s.c.s.DefaultLifecycleProcessor - Bean 'webServerStartStop' completed its stop procedure
2023-03-04 00:21:05 [SpringApplicationShutdownHook] DEBUG o.s.c.s.DefaultLifecycleProcessor - Stopping beans in phase -2147483647
2023-03-04 00:21:05 [SpringApplicationShutdownHook] DEBUG o.s.c.s.DefaultLifecycleProcessor - Bean 'springBootLoggingLifecycle' completed its stop procedure
2023-03-04 00:21:05 [SpringApplicationShutdownHook] DEBUG o.s.j.e.a.AnnotationMBeanExporter - Unregistering JMX-exposed beans on shutdown
2023-03-04 00:21:05 [SpringApplicationShutdownHook] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Closing kafka producer!
2023-03-04 00:21:05 [SpringApplicationShutdownHook] DEBUG o.a.k.clients.admin.KafkaAdminClient - [AdminClient clientId=adminclient-1] Initiating close operation.
2023-03-04 00:21:05 [SpringApplicationShutdownHook] DEBUG o.a.k.clients.admin.KafkaAdminClient - [AdminClient clientId=adminclient-1] Waiting for the I/O thread to exit. Hard shutdown in 31536000000 ms.
2023-03-04 00:21:05 [kafka-admin-client-thread | adminclient-1] INFO  o.a.kafka.common.utils.AppInfoParser - App info kafka.admin.client for adminclient-1 unregistered
2023-03-04 00:21:05 [kafka-admin-client-thread | adminclient-1] INFO  o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2023-03-04 00:21:05 [kafka-admin-client-thread | adminclient-1] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2023-03-04 00:21:05 [kafka-admin-client-thread | adminclient-1] INFO  o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2023-03-04 00:21:05 [kafka-admin-client-thread | adminclient-1] DEBUG o.a.k.clients.admin.KafkaAdminClient - [AdminClient clientId=adminclient-1] Exiting AdminClientRunnable thread.
2023-03-04 00:21:05 [SpringApplicationShutdownHook] DEBUG o.a.k.clients.admin.KafkaAdminClient - [AdminClient clientId=adminclient-1] Kafka admin client closed.
2023-03-04 00:21:07 [reactor-http-nio-3] DEBUG io.netty.buffer.PoolThreadCache - Freed 2 thread-local buffer(s) from thread: reactor-http-nio-3
2023-03-04 00:21:19 [main] INFO  x.g.m.d.t.t.k.s.TwitterToKafkaServiceApplication - Starting TwitterToKafkaServiceApplication using Java 17.0.6 with PID 40741 (/Users/admin/Documents/EventDeriventMicroservices/microservices-demo/twitter-to-kafka-service/target/classes started by admin in /Users/admin/Documents/EventDeriventMicroservices/microservices-demo)
2023-03-04 00:21:19 [main] INFO  x.g.m.d.t.t.k.s.TwitterToKafkaServiceApplication - No active profile set, falling back to 1 default profile: "default"
2023-03-04 00:21:19 [main] DEBUG o.s.boot.SpringApplication - Loading source class xyz.gouril.microservices.demo.twitter.to.kafka.service.TwitterToKafkaServiceApplication
2023-03-04 00:21:19 [main] DEBUG o.s.b.w.r.c.AnnotationConfigReactiveWebServerApplicationContext - Refreshing org.springframework.boot.web.reactive.context.AnnotationConfigReactiveWebServerApplicationContext@15cafec7
2023-03-04 00:21:19 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.context.annotation.internalConfigurationAnnotationProcessor'
2023-03-04 00:21:19 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.internalCachingMetadataReaderFactory'
2023-03-04 00:21:19 [main] DEBUG o.s.c.a.ClassPathBeanDefinitionScanner - Identified candidate component class: file [/Users/admin/Documents/EventDeriventMicroservices/microservices-demo/twitter-to-kafka-service/target/classes/xyz/gouril/microservices/demo/twitter/to/kafka/service/init/impl/KafkaStreamInitializer.class]
2023-03-04 00:21:19 [main] DEBUG o.s.c.a.ClassPathBeanDefinitionScanner - Identified candidate component class: file [/Users/admin/Documents/EventDeriventMicroservices/microservices-demo/twitter-to-kafka-service/target/classes/xyz/gouril/microservices/demo/twitter/to/kafka/service/listener/TwitterKafkaStatusListener.class]
2023-03-04 00:21:19 [main] DEBUG o.s.c.a.ClassPathBeanDefinitionScanner - Identified candidate component class: file [/Users/admin/Documents/EventDeriventMicroservices/microservices-demo/twitter-to-kafka-service/target/classes/xyz/gouril/microservices/demo/twitter/to/kafka/service/runner/impl/MockKafkaStreamRunner.class]
2023-03-04 00:21:19 [main] DEBUG o.s.c.a.ClassPathBeanDefinitionScanner - Identified candidate component class: file [/Users/admin/Documents/EventDeriventMicroservices/microservices-demo/twitter-to-kafka-service/target/classes/xyz/gouril/microservices/demo/twitter/to/kafka/service/transformer/TwitterStatusToAvroTransformer.class]
2023-03-04 00:21:19 [main] DEBUG o.s.c.a.ClassPathBeanDefinitionScanner - Identified candidate component class: file [/Users/admin/Documents/EventDeriventMicroservices/microservices-demo/app-config-data/target/classes/xyz/gouril/microservices/demo/config/KafkaConfigData.class]
2023-03-04 00:21:19 [main] DEBUG o.s.c.a.ClassPathBeanDefinitionScanner - Identified candidate component class: file [/Users/admin/Documents/EventDeriventMicroservices/microservices-demo/app-config-data/target/classes/xyz/gouril/microservices/demo/config/KafkaProducerConfigData.class]
2023-03-04 00:21:19 [main] DEBUG o.s.c.a.ClassPathBeanDefinitionScanner - Identified candidate component class: file [/Users/admin/Documents/EventDeriventMicroservices/microservices-demo/app-config-data/target/classes/xyz/gouril/microservices/demo/config/RetryConfigData.class]
2023-03-04 00:21:19 [main] DEBUG o.s.c.a.ClassPathBeanDefinitionScanner - Identified candidate component class: file [/Users/admin/Documents/EventDeriventMicroservices/microservices-demo/app-config-data/target/classes/xyz/gouril/microservices/demo/config/TwitterToKafkaServiceConfigData.class]
2023-03-04 00:21:19 [main] DEBUG o.s.c.a.ClassPathBeanDefinitionScanner - Identified candidate component class: file [/Users/admin/Documents/EventDeriventMicroservices/microservices-demo/kafka/kafka-admin/target/classes/xyz/gouril/microservices/demo/kafka/admin/client/KafkaAdminClient.class]
2023-03-04 00:21:19 [main] WARN  o.s.c.a.AnnotationTypeMapping - Support for convention-based annotation attribute overrides is deprecated and will be removed in Spring Framework 6.1. Please annotate the following attributes in @org.springframework.retry.annotation.EnableRetry with appropriate @AliasFor declarations: [proxyTargetClass]
2023-03-04 00:21:19 [main] DEBUG o.s.c.a.ClassPathBeanDefinitionScanner - Identified candidate component class: file [/Users/admin/Documents/EventDeriventMicroservices/microservices-demo/kafka/kafka-admin/target/classes/xyz/gouril/microservices/demo/kafka/admin/config/KafkaAdminConfig.class]
2023-03-04 00:21:19 [main] DEBUG o.s.c.a.ClassPathBeanDefinitionScanner - Identified candidate component class: file [/Users/admin/Documents/EventDeriventMicroservices/microservices-demo/kafka/kafka-admin/target/classes/xyz/gouril/microservices/demo/kafka/admin/config/WebClientConfig.class]
2023-03-04 00:21:19 [main] DEBUG o.s.c.a.ClassPathBeanDefinitionScanner - Identified candidate component class: file [/Users/admin/Documents/EventDeriventMicroservices/microservices-demo/common-config/target/classes/xyz/gouril/microservices/demo/common/config/RetryConfig.class]
2023-03-04 00:21:19 [main] DEBUG o.s.c.a.ClassPathBeanDefinitionScanner - Identified candidate component class: file [/Users/admin/Documents/EventDeriventMicroservices/microservices-demo/kafka/kafka-producer/target/classes/xyz/gouril/microservices/demo/kafka/producer/config/KafkaProducerConfig.class]
2023-03-04 00:21:19 [main] DEBUG o.s.c.a.ClassPathBeanDefinitionScanner - Identified candidate component class: file [/Users/admin/Documents/EventDeriventMicroservices/microservices-demo/kafka/kafka-producer/target/classes/xyz/gouril/microservices/demo/kafka/producer/service/impl/TwitterKafkaProducer.class]
2023-03-04 00:21:20 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'propertySourcesPlaceholderConfigurer'
2023-03-04 00:21:20 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.boot.sql.init.dependency.DatabaseInitializationDependencyConfigurer$DependsOnDatabaseInitializationPostProcessor'
2023-03-04 00:21:20 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.context.event.internalEventListenerProcessor'
2023-03-04 00:21:20 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.context.event.internalEventListenerFactory'
2023-03-04 00:21:20 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.context.annotation.internalAutowiredAnnotationProcessor'
2023-03-04 00:21:20 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.context.annotation.internalCommonAnnotationProcessor'
2023-03-04 00:21:20 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.boot.context.properties.ConfigurationPropertiesBindingPostProcessor'
2023-03-04 00:21:20 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.boot.context.internalConfigurationPropertiesBinder'
2023-03-04 00:21:20 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.aop.config.internalAutoProxyCreator'
2023-03-04 00:21:20 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'persistenceExceptionTranslationPostProcessor'
2023-03-04 00:21:20 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'persistenceExceptionTranslationPostProcessor' via factory method to bean named 'environment'
2023-03-04 00:21:20 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.kafka.config.internalKafkaListenerAnnotationProcessor'
2023-03-04 00:21:20 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'webServerFactoryCustomizerBeanPostProcessor'
2023-03-04 00:21:20 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'nettyReactiveWebServerFactory'
2023-03-04 00:21:20 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.retry.annotation.RetryConfiguration'
2023-03-04 00:21:20 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.web.reactive.ReactiveWebServerFactoryConfiguration$EmbeddedNetty'
2023-03-04 00:21:20 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'reactorResourceFactory'
2023-03-04 00:21:20 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.reactor.netty.ReactorNettyConfigurations$ReactorResourceFactoryConfiguration'
2023-03-04 00:21:20 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'spring.reactor.netty-org.springframework.boot.autoconfigure.reactor.netty.ReactorNettyProperties'
2023-03-04 00:21:20 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.boot.context.properties.BoundConfigurationProperties'
2023-03-04 00:21:20 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'reactorResourceFactory' via factory method to bean named 'spring.reactor.netty-org.springframework.boot.autoconfigure.reactor.netty.ReactorNettyProperties'
2023-03-04 00:21:20 [main] DEBUG reactor.util.Loggers - Using Slf4j logging framework
2023-03-04 00:21:20 [main] DEBUG i.n.u.i.l.InternalLoggerFactory - Using SLF4J as the default logging framework
2023-03-04 00:21:20 [main] DEBUG i.n.util.internal.PlatformDependent0 - -Dio.netty.noUnsafe: false
2023-03-04 00:21:20 [main] DEBUG i.n.util.internal.PlatformDependent0 - Java version: 17
2023-03-04 00:21:20 [main] DEBUG i.n.util.internal.PlatformDependent0 - sun.misc.Unsafe.theUnsafe: available
2023-03-04 00:21:20 [main] DEBUG i.n.util.internal.PlatformDependent0 - sun.misc.Unsafe.copyMemory: available
2023-03-04 00:21:20 [main] DEBUG i.n.util.internal.PlatformDependent0 - sun.misc.Unsafe.storeFence: available
2023-03-04 00:21:20 [main] DEBUG i.n.util.internal.PlatformDependent0 - java.nio.Buffer.address: available
2023-03-04 00:21:20 [main] DEBUG i.n.util.internal.PlatformDependent0 - direct buffer constructor: unavailable: Reflective setAccessible(true) disabled
2023-03-04 00:21:20 [main] DEBUG i.n.util.internal.PlatformDependent0 - java.nio.Bits.unaligned: available, true
2023-03-04 00:21:20 [main] DEBUG i.n.util.internal.PlatformDependent0 - jdk.internal.misc.Unsafe.allocateUninitializedArray(int): unavailable: class io.netty.util.internal.PlatformDependent0$7 cannot access class jdk.internal.misc.Unsafe (in module java.base) because module java.base does not export jdk.internal.misc to unnamed module @2473d930
2023-03-04 00:21:20 [main] DEBUG i.n.util.internal.PlatformDependent0 - java.nio.DirectByteBuffer.<init>(long, int): unavailable
2023-03-04 00:21:20 [main] DEBUG i.n.util.internal.PlatformDependent - sun.misc.Unsafe: available
2023-03-04 00:21:20 [main] DEBUG i.n.util.internal.PlatformDependent - maxDirectMemory: 4294967296 bytes (maybe)
2023-03-04 00:21:20 [main] DEBUG i.n.util.internal.PlatformDependent - -Dio.netty.tmpdir: /var/folders/zx/4g777wp55pg8j62jnpqrd9dh0000gn/T (java.io.tmpdir)
2023-03-04 00:21:20 [main] DEBUG i.n.util.internal.PlatformDependent - -Dio.netty.bitMode: 64 (sun.arch.data.model)
2023-03-04 00:21:20 [main] DEBUG i.n.util.internal.PlatformDependent - Platform: MacOS
2023-03-04 00:21:20 [main] DEBUG i.n.util.internal.PlatformDependent - -Dio.netty.maxDirectMemory: -1 bytes
2023-03-04 00:21:20 [main] DEBUG i.n.util.internal.PlatformDependent - -Dio.netty.uninitializedArrayAllocationThreshold: -1
2023-03-04 00:21:20 [main] DEBUG io.netty.util.internal.CleanerJava9 - java.nio.ByteBuffer.cleaner(): available
2023-03-04 00:21:20 [main] DEBUG i.n.util.internal.PlatformDependent - -Dio.netty.noPreferDirect: false
2023-03-04 00:21:20 [main] DEBUG reactor.netty.tcp.TcpResources - [http] resources will use the default LoopResources: DefaultLoopResources {prefix=reactor-http, daemon=true, selectCount=8, workerCount=8}
2023-03-04 00:21:20 [main] DEBUG reactor.netty.tcp.TcpResources - [http] resources will use the default ConnectionProvider: reactor.netty.resources.DefaultPooledConnectionProvider@ca93621
2023-03-04 00:21:20 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'nettyReactiveWebServerFactory' via factory method to bean named 'reactorResourceFactory'
2023-03-04 00:21:20 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'reactiveWebServerFactoryCustomizer'
2023-03-04 00:21:20 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.web.reactive.ReactiveWebServerFactoryAutoConfiguration'
2023-03-04 00:21:20 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'server-org.springframework.boot.autoconfigure.web.ServerProperties'
2023-03-04 00:21:20 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'reactiveWebServerFactoryCustomizer' via factory method to bean named 'server-org.springframework.boot.autoconfigure.web.ServerProperties'
2023-03-04 00:21:20 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'nettyWebServerFactoryCustomizer'
2023-03-04 00:21:20 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.web.embedded.EmbeddedWebServerFactoryCustomizerAutoConfiguration$NettyWebServerFactoryCustomizerConfiguration'
2023-03-04 00:21:20 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'nettyWebServerFactoryCustomizer' via factory method to bean named 'environment'
2023-03-04 00:21:20 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'nettyWebServerFactoryCustomizer' via factory method to bean named 'server-org.springframework.boot.autoconfigure.web.ServerProperties'
2023-03-04 00:21:20 [main] DEBUG i.n.u.i.InternalThreadLocalMap - -Dio.netty.threadLocalMap.stringBuilder.initialSize: 1024
2023-03-04 00:21:20 [main] DEBUG i.n.u.i.InternalThreadLocalMap - -Dio.netty.threadLocalMap.stringBuilder.maxSize: 4096
2023-03-04 00:21:20 [main] DEBUG io.netty.util.ResourceLeakDetector - -Dio.netty.leakDetection.level: simple
2023-03-04 00:21:20 [main] DEBUG io.netty.util.ResourceLeakDetector - -Dio.netty.leakDetection.targetRecords: 4
2023-03-04 00:21:20 [main] DEBUG i.n.u.concurrent.GlobalEventExecutor - -Dio.netty.globalEventExecutor.quietPeriodSeconds: 1
2023-03-04 00:21:20 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'twitterToKafkaServiceApplication'
2023-03-04 00:21:20 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'kafkaStreamInitializer'
2023-03-04 00:21:20 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'kafkaConfigData'
2023-03-04 00:21:20 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'kafkaAdminClient'
2023-03-04 00:21:20 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'retryConfigData'
2023-03-04 00:21:20 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'adminClient'
2023-03-04 00:21:20 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'kafkaAdminConfig'
2023-03-04 00:21:20 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'kafkaAdminConfig' via constructor to bean named 'kafkaConfigData'
2023-03-04 00:21:20 [main] INFO  o.a.k.c.admin.AdminClientConfig - AdminClientConfig values: 
	bootstrap.servers = [localhost:19092, localhost:29092, localhost:39092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2023-03-04 00:21:20 [main] DEBUG o.a.k.c.a.i.AdminMetadataManager - [AdminClient clientId=adminclient-1] Setting bootstrap cluster metadata Cluster(id = null, nodes = [localhost:39092 (id: -3 rack: null), localhost:19092 (id: -1 rack: null), localhost:29092 (id: -2 rack: null)], partitions = [], controller = null).
2023-03-04 00:21:20 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.3.2
2023-03-04 00:21:20 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: b66af662e61082cb
2023-03-04 00:21:20 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1677876680727
2023-03-04 00:21:20 [main] DEBUG o.a.k.clients.admin.KafkaAdminClient - [AdminClient clientId=adminclient-1] Kafka admin client initialized
2023-03-04 00:21:20 [kafka-admin-client-thread | adminclient-1] DEBUG o.a.k.clients.admin.KafkaAdminClient - [AdminClient clientId=adminclient-1] Thread starting
2023-03-04 00:21:20 [kafka-admin-client-thread | adminclient-1] DEBUG o.apache.kafka.clients.ClientUtils - Resolved host localhost as 127.0.0.1
2023-03-04 00:21:20 [kafka-admin-client-thread | adminclient-1] DEBUG o.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Initiating connection to node localhost:19092 (id: -1 rack: null) using address localhost/127.0.0.1
2023-03-04 00:21:20 [kafka-admin-client-thread | adminclient-1] DEBUG o.a.kafka.common.network.Selector - [AdminClient clientId=adminclient-1] Created socket with SO_RCVBUF = 342972, SO_SNDBUF = 146988, SO_TIMEOUT = 0 to node -1
2023-03-04 00:21:20 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'retryTemplate'
2023-03-04 00:21:20 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'retryConfig'
2023-03-04 00:21:20 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'retryConfig' via constructor to bean named 'retryConfigData'
2023-03-04 00:21:20 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'webClient'
2023-03-04 00:21:20 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'webClientConfig'
2023-03-04 00:21:20 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'kafkaAdminClient' via constructor to bean named 'kafkaConfigData'
2023-03-04 00:21:20 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'kafkaAdminClient' via constructor to bean named 'retryConfigData'
2023-03-04 00:21:20 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'kafkaAdminClient' via constructor to bean named 'adminClient'
2023-03-04 00:21:20 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'kafkaAdminClient' via constructor to bean named 'retryTemplate'
2023-03-04 00:21:20 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'kafkaAdminClient' via constructor to bean named 'webClient'
2023-03-04 00:21:20 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'kafkaStreamInitializer' via constructor to bean named 'kafkaConfigData'
2023-03-04 00:21:20 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'kafkaStreamInitializer' via constructor to bean named 'kafkaAdminClient'
2023-03-04 00:21:20 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'mockKafkaStreamRunner'
2023-03-04 00:21:20 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'twitterToKafkaServiceConfigData'
2023-03-04 00:21:20 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'twitterKafkaStatusListener'
2023-03-04 00:21:20 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'twitterKafkaProducer'
2023-03-04 00:21:20 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'kafkaTemplate'
2023-03-04 00:21:20 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'kafkaProducerConfig'
2023-03-04 00:21:20 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'kafkaProducerConfigData'
2023-03-04 00:21:20 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'kafkaProducerConfig' via constructor to bean named 'kafkaConfigData'
2023-03-04 00:21:20 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'kafkaProducerConfig' via constructor to bean named 'kafkaProducerConfigData'
2023-03-04 00:21:20 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'producerFactory'
2023-03-04 00:21:20 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'producerConfig'
2023-03-04 00:21:20 [kafka-admin-client-thread | adminclient-1] DEBUG o.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Completed connection to node -1. Fetching API versions.
2023-03-04 00:21:20 [kafka-admin-client-thread | adminclient-1] DEBUG o.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Initiating API versions fetch from node -1.
2023-03-04 00:21:20 [kafka-admin-client-thread | adminclient-1] DEBUG o.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Sending API_VERSIONS request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=adminclient-1, correlationId=0) and timeout 3600000 to node -1: ApiVersionsRequestData(clientSoftwareName='apache-kafka-java', clientSoftwareVersion='3.3.2')
2023-03-04 00:21:20 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'twitterKafkaProducer' via constructor to bean named 'kafkaTemplate'
2023-03-04 00:21:20 [main] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - <<<<<DEFAULT TOPIC: org.springframework.kafka.core.KafkaTemplate@6dc9da2d>>>>>>>
2023-03-04 00:21:20 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'twitterStatusToAvroTransformer'
2023-03-04 00:21:20 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'twitterKafkaStatusListener' via constructor to bean named 'kafkaConfigData'
2023-03-04 00:21:20 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'twitterKafkaStatusListener' via constructor to bean named 'twitterKafkaProducer'
2023-03-04 00:21:20 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'twitterKafkaStatusListener' via constructor to bean named 'twitterStatusToAvroTransformer'
2023-03-04 00:21:20 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'mockKafkaStreamRunner' via constructor to bean named 'twitterToKafkaServiceConfigData'
2023-03-04 00:21:20 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'mockKafkaStreamRunner' via constructor to bean named 'twitterKafkaStatusListener'
2023-03-04 00:21:20 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'twitterToKafkaServiceApplication' via constructor to bean named 'kafkaStreamInitializer'
2023-03-04 00:21:20 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'twitterToKafkaServiceApplication' via constructor to bean named 'mockKafkaStreamRunner'
2023-03-04 00:21:20 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.AutoConfigurationPackages'
2023-03-04 00:21:20 [kafka-admin-client-thread | adminclient-1] DEBUG o.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Received API_VERSIONS response from node -1 for request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=adminclient-1, correlationId=0): ApiVersionsResponseData(errorCode=35, apiKeys=[], throttleTimeMs=0, supportedFeatures=[], finalizedFeaturesEpoch=-1, finalizedFeatures=[])
2023-03-04 00:21:20 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.context.PropertyPlaceholderAutoConfiguration'
2023-03-04 00:21:20 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.boot.context.properties.EnableConfigurationPropertiesRegistrar.methodValidationExcludeFilter'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.jackson.JacksonAutoConfiguration$Jackson2ObjectMapperBuilderCustomizerConfiguration'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'standardJacksonObjectMapperBuilderCustomizer'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'spring.jackson-org.springframework.boot.autoconfigure.jackson.JacksonProperties'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'standardJacksonObjectMapperBuilderCustomizer' via factory method to bean named 'spring.jackson-org.springframework.boot.autoconfigure.jackson.JacksonProperties'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'parameterNamesModule'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.jackson.JacksonAutoConfiguration$ParameterNamesModuleConfiguration'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'jsonMixinModule'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.jackson.JacksonAutoConfiguration$JacksonMixinConfiguration'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'jsonMixinModuleEntries'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'jsonMixinModuleEntries' via factory method to bean named 'org.springframework.boot.web.reactive.context.AnnotationConfigReactiveWebServerApplicationContext@15cafec7'
2023-03-04 00:21:21 [main] DEBUG o.s.b.a.AutoConfigurationPackages - @EnableAutoConfiguration was declared on a class in the package 'xyz.gouril.microservices.demo.twitter.to.kafka.service'. Automatic @Repository and @Entity scanning is enabled.
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'jsonMixinModule' via factory method to bean named 'org.springframework.boot.web.reactive.context.AnnotationConfigReactiveWebServerApplicationContext@15cafec7'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'jsonMixinModule' via factory method to bean named 'jsonMixinModuleEntries'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'jsonComponentModule'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.jackson.JacksonAutoConfiguration'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.jackson.JacksonAutoConfiguration$JacksonObjectMapperBuilderConfiguration'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.jackson.JacksonAutoConfiguration$JacksonObjectMapperConfiguration'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'jacksonObjectMapper'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'jacksonObjectMapperBuilder' via factory method to bean named 'org.springframework.boot.web.reactive.context.AnnotationConfigReactiveWebServerApplicationContext@15cafec7'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'jacksonObjectMapperBuilder' via factory method to bean named 'standardJacksonObjectMapperBuilderCustomizer'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'jacksonObjectMapper' via factory method to bean named 'jacksonObjectMapperBuilder'
2023-03-04 00:21:21 [kafka-admin-client-thread | adminclient-1] DEBUG o.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Initiating API versions fetch from node -1.
2023-03-04 00:21:21 [kafka-admin-client-thread | adminclient-1] DEBUG o.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Sending API_VERSIONS request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=0, clientId=adminclient-1, correlationId=1) and timeout 3600000 to node -1: ApiVersionsRequestData(clientSoftwareName='apache-kafka-java', clientSoftwareVersion='3.3.2')
2023-03-04 00:21:21 [kafka-admin-client-thread | adminclient-1] DEBUG o.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Received API_VERSIONS response from node -1 for request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=0, clientId=adminclient-1, correlationId=1): ApiVersionsResponseData(errorCode=0, apiKeys=[ApiVersion(apiKey=0, minVersion=0, maxVersion=6), ApiVersion(apiKey=1, minVersion=0, maxVersion=8), ApiVersion(apiKey=2, minVersion=0, maxVersion=3), ApiVersion(apiKey=3, minVersion=0, maxVersion=6), ApiVersion(apiKey=4, minVersion=0, maxVersion=1), ApiVersion(apiKey=5, minVersion=0, maxVersion=0), ApiVersion(apiKey=6, minVersion=0, maxVersion=4), ApiVersion(apiKey=7, minVersion=0, maxVersion=1), ApiVersion(apiKey=8, minVersion=0, maxVersion=4), ApiVersion(apiKey=9, minVersion=0, maxVersion=4), ApiVersion(apiKey=10, minVersion=0, maxVersion=2), ApiVersion(apiKey=11, minVersion=0, maxVersion=3), ApiVersion(apiKey=12, minVersion=0, maxVersion=2), ApiVersion(apiKey=13, minVersion=0, maxVersion=2), ApiVersion(apiKey=14, minVersion=0, maxVersion=2), ApiVersion(apiKey=15, minVersion=0, maxVersion=2), ApiVersion(apiKey=16, minVersion=0, maxVersion=2), ApiVersion(apiKey=17, minVersion=0, maxVersion=1), ApiVersion(apiKey=18, minVersion=0, maxVersion=2), ApiVersion(apiKey=19, minVersion=0, maxVersion=3), ApiVersion(apiKey=20, minVersion=0, maxVersion=2), ApiVersion(apiKey=21, minVersion=0, maxVersion=1), ApiVersion(apiKey=22, minVersion=0, maxVersion=1), ApiVersion(apiKey=23, minVersion=0, maxVersion=1), ApiVersion(apiKey=24, minVersion=0, maxVersion=1), ApiVersion(apiKey=25, minVersion=0, maxVersion=1), ApiVersion(apiKey=26, minVersion=0, maxVersion=1), ApiVersion(apiKey=27, minVersion=0, maxVersion=0), ApiVersion(apiKey=28, minVersion=0, maxVersion=1), ApiVersion(apiKey=29, minVersion=0, maxVersion=1), ApiVersion(apiKey=30, minVersion=0, maxVersion=1), ApiVersion(apiKey=31, minVersion=0, maxVersion=1), ApiVersion(apiKey=32, minVersion=0, maxVersion=2), ApiVersion(apiKey=33, minVersion=0, maxVersion=1), ApiVersion(apiKey=34, minVersion=0, maxVersion=1), ApiVersion(apiKey=35, minVersion=0, maxVersion=1), ApiVersion(apiKey=36, minVersion=0, maxVersion=0), ApiVersion(apiKey=37, minVersion=0, maxVersion=1), ApiVersion(apiKey=38, minVersion=0, maxVersion=1), ApiVersion(apiKey=39, minVersion=0, maxVersion=1), ApiVersion(apiKey=40, minVersion=0, maxVersion=1), ApiVersion(apiKey=41, minVersion=0, maxVersion=1), ApiVersion(apiKey=42, minVersion=0, maxVersion=1)], throttleTimeMs=0, supportedFeatures=[], finalizedFeaturesEpoch=-1, finalizedFeatures=[])
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.http.codec.CodecsAutoConfiguration$DefaultCodecsConfiguration'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'defaultCodecCustomizer'
2023-03-04 00:21:21 [kafka-admin-client-thread | adminclient-1] DEBUG o.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Node -1 has finalized features epoch: -1, finalized features: [], supported features: [], API versions: (Produce(0): 0 to 6 [usable: 6], Fetch(1): 0 to 8 [usable: 8], ListOffsets(2): 0 to 3 [usable: 3], Metadata(3): 0 to 6 [usable: 6], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 4 [usable: 4], OffsetFetch(9): 0 to 4 [usable: 4], FindCoordinator(10): 0 to 2 [usable: 2], JoinGroup(11): 0 to 3 [usable: 3], Heartbeat(12): 0 to 2 [usable: 2], LeaveGroup(13): 0 to 2 [usable: 2], SyncGroup(14): 0 to 2 [usable: 2], DescribeGroups(15): 0 to 2 [usable: 2], ListGroups(16): 0 to 2 [usable: 2], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 2], CreateTopics(19): 0 to 3 [usable: 3], DeleteTopics(20): 0 to 2 [usable: 2], DeleteRecords(21): 0 to 1 [usable: 1], InitProducerId(22): 0 to 1 [usable: 1], OffsetForLeaderEpoch(23): 0 to 1 [usable: 1], AddPartitionsToTxn(24): 0 to 1 [usable: 1], AddOffsetsToTxn(25): 0 to 1 [usable: 1], EndTxn(26): 0 to 1 [usable: 1], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 1 [usable: 1], DescribeAcls(29): 0 to 1 [usable: 1], CreateAcls(30): 0 to 1 [usable: 1], DeleteAcls(31): 0 to 1 [usable: 1], DescribeConfigs(32): 0 to 2 [usable: 2], AlterConfigs(33): 0 to 1 [usable: 1], AlterReplicaLogDirs(34): 0 to 1 [usable: 1], DescribeLogDirs(35): 0 to 1 [usable: 1], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 1], CreateDelegationToken(38): 0 to 1 [usable: 1], RenewDelegationToken(39): 0 to 1 [usable: 1], ExpireDelegationToken(40): 0 to 1 [usable: 1], DescribeDelegationToken(41): 0 to 1 [usable: 1], DeleteGroups(42): 0 to 1 [usable: 1], ElectLeaders(43): UNSUPPORTED, IncrementalAlterConfigs(44): UNSUPPORTED, AlterPartitionReassignments(45): UNSUPPORTED, ListPartitionReassignments(46): UNSUPPORTED, OffsetDelete(47): UNSUPPORTED, DescribeClientQuotas(48): UNSUPPORTED, AlterClientQuotas(49): UNSUPPORTED, DescribeUserScramCredentials(50): UNSUPPORTED, AlterUserScramCredentials(51): UNSUPPORTED, AlterPartition(56): UNSUPPORTED, UpdateFeatures(57): UNSUPPORTED, DescribeCluster(60): UNSUPPORTED, DescribeProducers(61): UNSUPPORTED, DescribeTransactions(65): UNSUPPORTED, ListTransactions(66): UNSUPPORTED, AllocateProducerIds(67): UNSUPPORTED).
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'spring.codec-org.springframework.boot.autoconfigure.codec.CodecProperties'
2023-03-04 00:21:21 [kafka-admin-client-thread | adminclient-1] DEBUG o.a.k.clients.admin.KafkaAdminClient - [AdminClient clientId=adminclient-1] Sending MetadataRequestData(topics=[], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to localhost:19092 (id: -1 rack: null). correlationId=2, timeoutMs=29675
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'defaultCodecCustomizer' via factory method to bean named 'spring.codec-org.springframework.boot.autoconfigure.codec.CodecProperties'
2023-03-04 00:21:21 [kafka-admin-client-thread | adminclient-1] DEBUG o.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Sending METADATA request with header RequestHeader(apiKey=METADATA, apiVersion=6, clientId=adminclient-1, correlationId=2) and timeout 29675 to node -1: MetadataRequestData(topics=[], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false)
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.http.codec.CodecsAutoConfiguration$JacksonCodecConfiguration'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'jacksonCodecCustomizer'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'jacksonCodecCustomizer' via factory method to bean named 'jacksonObjectMapper'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.http.codec.CodecsAutoConfiguration'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.web.reactive.ReactiveMultipartAutoConfiguration'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'defaultPartHttpMessageReaderCustomizer'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'spring.webflux.multipart-org.springframework.boot.autoconfigure.web.reactive.ReactiveMultipartProperties'
2023-03-04 00:21:21 [kafka-admin-client-thread | adminclient-1] DEBUG o.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Received METADATA response from node -1 for request with header RequestHeader(apiKey=METADATA, apiVersion=6, clientId=adminclient-1, correlationId=2): MetadataResponseData(throttleTimeMs=0, brokers=[MetadataResponseBroker(nodeId=2, host='localhost', port=29092, rack=null), MetadataResponseBroker(nodeId=1, host='localhost', port=19092, rack=null), MetadataResponseBroker(nodeId=3, host='localhost', port=39092, rack=null)], clusterId='QGDYypu5SSGtA9Bc36Rjow', controllerId=3, topics=[], clusterAuthorizedOperations=-2147483648)
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'defaultPartHttpMessageReaderCustomizer' via factory method to bean named 'spring.webflux.multipart-org.springframework.boot.autoconfigure.web.reactive.ReactiveMultipartProperties'
2023-03-04 00:21:21 [kafka-admin-client-thread | adminclient-1] DEBUG o.a.k.c.a.i.AdminMetadataManager - [AdminClient clientId=adminclient-1] Updating cluster metadata to Cluster(id = QGDYypu5SSGtA9Bc36Rjow, nodes = [localhost:39092 (id: 3 rack: null), localhost:29092 (id: 2 rack: null), localhost:19092 (id: 1 rack: null)], partitions = [], controller = localhost:39092 (id: 3 rack: null))
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.web.reactive.WebSessionIdResolverAutoConfiguration'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'spring.webflux-org.springframework.boot.autoconfigure.web.reactive.WebFluxProperties'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'org.springframework.boot.autoconfigure.web.reactive.WebSessionIdResolverAutoConfiguration' via constructor to bean named 'server-org.springframework.boot.autoconfigure.web.ServerProperties'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'org.springframework.boot.autoconfigure.web.reactive.WebSessionIdResolverAutoConfiguration' via constructor to bean named 'spring.webflux-org.springframework.boot.autoconfigure.web.reactive.WebFluxProperties'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'webSessionIdResolver'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.web.reactive.error.ErrorWebFluxAutoConfiguration'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'org.springframework.boot.autoconfigure.web.reactive.error.ErrorWebFluxAutoConfiguration' via constructor to bean named 'server-org.springframework.boot.autoconfigure.web.ServerProperties'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'errorWebExceptionHandler'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'errorAttributes'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'spring.web-org.springframework.boot.autoconfigure.web.WebProperties'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'serverCodecConfigurer'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.web.reactive.WebFluxAutoConfiguration$EnableWebFluxConfiguration'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'org.springframework.boot.autoconfigure.web.reactive.WebFluxAutoConfiguration$EnableWebFluxConfiguration' via constructor to bean named 'spring.webflux-org.springframework.boot.autoconfigure.web.reactive.WebFluxProperties'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'org.springframework.boot.autoconfigure.web.reactive.WebFluxAutoConfiguration$EnableWebFluxConfiguration' via constructor to bean named 'spring.web-org.springframework.boot.autoconfigure.web.WebProperties'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'org.springframework.boot.autoconfigure.web.reactive.WebFluxAutoConfiguration$EnableWebFluxConfiguration' via constructor to bean named 'server-org.springframework.boot.autoconfigure.web.ServerProperties'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.web.reactive.WebFluxAutoConfiguration$WebFluxConfig'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'org.springframework.boot.autoconfigure.web.reactive.WebFluxAutoConfiguration$WebFluxConfig' via constructor to bean named 'spring.web-org.springframework.boot.autoconfigure.web.WebProperties'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'org.springframework.boot.autoconfigure.web.reactive.WebFluxAutoConfiguration$WebFluxConfig' via constructor to bean named 'spring.webflux-org.springframework.boot.autoconfigure.web.reactive.WebFluxProperties'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'org.springframework.boot.autoconfigure.web.reactive.WebFluxAutoConfiguration$WebFluxConfig' via constructor to bean named 'org.springframework.beans.factory.support.DefaultListableBeanFactory@8a589a2'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'errorWebExceptionHandler' via factory method to bean named 'errorAttributes'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'errorWebExceptionHandler' via factory method to bean named 'spring.web-org.springframework.boot.autoconfigure.web.WebProperties'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'errorWebExceptionHandler' via factory method to bean named 'serverCodecConfigurer'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'errorWebExceptionHandler' via factory method to bean named 'org.springframework.boot.web.reactive.context.AnnotationConfigReactiveWebServerApplicationContext@15cafec7'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'webFluxConversionService'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'webFluxValidator'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'localeContextResolver'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'webSessionManager'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'webHandler'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'requestMappingHandlerMapping'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'webFluxContentTypeResolver'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'requestMappingHandlerMapping' via factory method to bean named 'webFluxContentTypeResolver'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'routerFunctionMapping'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'routerFunctionMapping' via factory method to bean named 'serverCodecConfigurer'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'resourceHandlerMapping'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'resourceUrlProvider'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'resourceHandlerMapping' via factory method to bean named 'resourceUrlProvider'
2023-03-04 00:21:21 [main] DEBUG _.s.w.r.HandlerMapping.Mappings - 'resourceHandlerMapping' {/webjars/**=ResourceWebHandler [classpath [META-INF/resources/webjars/]], /**=ResourceWebHandler [classpath [META-INF/resources/], classpath [resources/], classpath [static/], classpath [public/]]}
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'welcomePageRouterFunctionMapping'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.web.reactive.WebFluxAutoConfiguration$WelcomePageConfiguration'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'welcomePageRouterFunctionMapping' via factory method to bean named 'org.springframework.boot.web.reactive.context.AnnotationConfigReactiveWebServerApplicationContext@15cafec7'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'welcomePageRouterFunctionMapping' via factory method to bean named 'spring.webflux-org.springframework.boot.autoconfigure.web.reactive.WebFluxProperties'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'welcomePageRouterFunctionMapping' via factory method to bean named 'spring.web-org.springframework.boot.autoconfigure.web.WebProperties'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'requestMappingHandlerAdapter'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'webFluxAdapterRegistry'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'requestMappingHandlerAdapter' via factory method to bean named 'webFluxAdapterRegistry'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'requestMappingHandlerAdapter' via factory method to bean named 'serverCodecConfigurer'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'requestMappingHandlerAdapter' via factory method to bean named 'webFluxConversionService'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'requestMappingHandlerAdapter' via factory method to bean named 'webFluxValidator'
2023-03-04 00:21:21 [main] DEBUG o.s.w.r.r.m.a.ControllerMethodResolver - ControllerAdvice beans: none
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'handlerFunctionAdapter'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'simpleHandlerAdapter'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'webFluxWebSocketHandlerAdapter'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'responseEntityResultHandler'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'responseEntityResultHandler' via factory method to bean named 'webFluxAdapterRegistry'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'responseEntityResultHandler' via factory method to bean named 'serverCodecConfigurer'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'responseEntityResultHandler' via factory method to bean named 'webFluxContentTypeResolver'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'responseBodyResultHandler'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'responseBodyResultHandler' via factory method to bean named 'webFluxAdapterRegistry'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'responseBodyResultHandler' via factory method to bean named 'serverCodecConfigurer'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'responseBodyResultHandler' via factory method to bean named 'webFluxContentTypeResolver'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'viewResolutionResultHandler'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'viewResolutionResultHandler' via factory method to bean named 'webFluxAdapterRegistry'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'viewResolutionResultHandler' via factory method to bean named 'webFluxContentTypeResolver'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'serverResponseResultHandler'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'serverResponseResultHandler' via factory method to bean named 'serverCodecConfigurer'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'responseStatusExceptionHandler'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.web.reactive.WebFluxAutoConfiguration'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.web.reactive.HttpHandlerAutoConfiguration$AnnotationConfig'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'org.springframework.boot.autoconfigure.web.reactive.HttpHandlerAutoConfiguration$AnnotationConfig' via constructor to bean named 'org.springframework.boot.web.reactive.context.AnnotationConfigReactiveWebServerApplicationContext@15cafec7'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'httpHandler'
2023-03-04 00:21:21 [main] DEBUG o.s.w.s.a.HttpWebHandlerAdapter - enableLoggingRequestDetails='false': form data and headers will be masked to prevent unsafe logging of potentially sensitive data
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.web.reactive.HttpHandlerAutoConfiguration'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.jmx.JmxAutoConfiguration'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'spring.jmx-org.springframework.boot.autoconfigure.jmx.JmxProperties'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'org.springframework.boot.autoconfigure.jmx.JmxAutoConfiguration' via constructor to bean named 'spring.jmx-org.springframework.boot.autoconfigure.jmx.JmxProperties'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'mbeanExporter'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'objectNamingStrategy'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'mbeanExporter' via factory method to bean named 'objectNamingStrategy'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'mbeanExporter' via factory method to bean named 'org.springframework.beans.factory.support.DefaultListableBeanFactory@8a589a2'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'mbeanServer'
2023-03-04 00:21:21 [main] DEBUG o.s.jmx.support.JmxUtils - Found MBeanServer: com.sun.jmx.mbeanserver.JmxMBeanServer@67f89fa3
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.admin.SpringApplicationAdminJmxAutoConfiguration'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'springApplicationAdminRegistrar'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'springApplicationAdminRegistrar' via factory method to bean named 'environment'
2023-03-04 00:21:21 [main] DEBUG o.s.b.a.SpringApplicationAdminMXBeanRegistrar$SpringApplicationAdmin - Application Admin MBean registered with name 'org.springframework.boot:type=Admin,name=SpringApplication'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.aop.AopAutoConfiguration$AspectJAutoProxyingConfiguration$CglibAutoProxyConfiguration'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.aop.AopAutoConfiguration$AspectJAutoProxyingConfiguration'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.aop.AopAutoConfiguration'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.availability.ApplicationAvailabilityAutoConfiguration'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'applicationAvailability'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.context.ConfigurationPropertiesAutoConfiguration'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.context.LifecycleAutoConfiguration'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'lifecycleProcessor'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'spring.lifecycle-org.springframework.boot.autoconfigure.context.LifecycleProperties'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'lifecycleProcessor' via factory method to bean named 'spring.lifecycle-org.springframework.boot.autoconfigure.context.LifecycleProperties'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.dao.PersistenceExceptionTranslationAutoConfiguration'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.info.ProjectInfoAutoConfiguration'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'spring.info-org.springframework.boot.autoconfigure.info.ProjectInfoProperties'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'org.springframework.boot.autoconfigure.info.ProjectInfoAutoConfiguration' via constructor to bean named 'spring.info-org.springframework.boot.autoconfigure.info.ProjectInfoProperties'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.kafka.KafkaAnnotationDrivenConfiguration$EnableKafkaConfiguration'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.kafka.config.internalKafkaListenerEndpointRegistry'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.kafka.KafkaAnnotationDrivenConfiguration'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'spring.kafka-org.springframework.boot.autoconfigure.kafka.KafkaProperties'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'org.springframework.boot.autoconfigure.kafka.KafkaAnnotationDrivenConfiguration' via constructor to bean named 'spring.kafka-org.springframework.boot.autoconfigure.kafka.KafkaProperties'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'kafkaListenerContainerFactoryConfigurer'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'kafkaListenerContainerFactory'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'kafkaListenerContainerFactory' via factory method to bean named 'kafkaListenerContainerFactoryConfigurer'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'kafkaConsumerFactory'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.kafka.KafkaAutoConfiguration'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'org.springframework.boot.autoconfigure.kafka.KafkaAutoConfiguration' via constructor to bean named 'spring.kafka-org.springframework.boot.autoconfigure.kafka.KafkaProperties'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'kafkaProducerListener'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'kafkaAdmin'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.netty.NettyAutoConfiguration'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'spring.netty-org.springframework.boot.autoconfigure.netty.NettyProperties'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'org.springframework.boot.autoconfigure.netty.NettyAutoConfiguration' via constructor to bean named 'spring.netty-org.springframework.boot.autoconfigure.netty.NettyProperties'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.sql.init.SqlInitializationAutoConfiguration'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'spring.sql.init-org.springframework.boot.autoconfigure.sql.init.SqlInitializationProperties'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.task.TaskExecutionAutoConfiguration'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'taskExecutorBuilder'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'spring.task.execution-org.springframework.boot.autoconfigure.task.TaskExecutionProperties'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'taskExecutorBuilder' via factory method to bean named 'spring.task.execution-org.springframework.boot.autoconfigure.task.TaskExecutionProperties'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.task.TaskSchedulingAutoConfiguration'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'taskSchedulerBuilder'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'spring.task.scheduling-org.springframework.boot.autoconfigure.task.TaskSchedulingProperties'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Autowiring by type from bean name 'taskSchedulerBuilder' via factory method to bean named 'spring.task.scheduling-org.springframework.boot.autoconfigure.task.TaskSchedulingProperties'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.transaction.TransactionAutoConfiguration'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'platformTransactionManagerCustomizers'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'spring.transaction-org.springframework.boot.autoconfigure.transaction.TransactionProperties'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.web.embedded.EmbeddedWebServerFactoryCustomizerAutoConfiguration'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.web.reactive.function.client.ClientHttpConnectorConfiguration$ReactorNetty'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.web.reactive.function.client.ClientHttpConnectorAutoConfiguration'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.web.reactive.function.client.WebClientAutoConfiguration$WebClientCodecsConfiguration'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'exchangeStrategiesCustomizer'
2023-03-04 00:21:21 [main] DEBUG o.s.b.f.s.DefaultListableBeanFactory - Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.web.reactive.function.client.WebClientAutoConfiguration'
2023-03-04 00:21:21 [main] DEBUG o.s.j.e.a.AnnotationMBeanExporter - Registering beans for JMX exposure on startup
2023-03-04 00:21:21 [main] DEBUG o.s.j.e.a.AnnotationMBeanExporter - Autodetecting user-defined JMX MBeans
2023-03-04 00:21:21 [main] DEBUG o.s.c.s.DefaultLifecycleProcessor - Starting beans in phase -2147483647
2023-03-04 00:21:21 [main] DEBUG o.s.c.s.DefaultLifecycleProcessor - Successfully started bean 'springBootLoggingLifecycle'
2023-03-04 00:21:21 [main] DEBUG o.s.c.s.DefaultLifecycleProcessor - Starting beans in phase 2147481599
2023-03-04 00:21:21 [main] DEBUG r.netty.resources.DefaultLoopIOUring - Default io_uring support : false
2023-03-04 00:21:21 [main] DEBUG r.netty.resources.DefaultLoopEpoll - Default Epoll support : false
2023-03-04 00:21:21 [main] DEBUG r.netty.resources.DefaultLoopKQueue - Default KQueue support : false
2023-03-04 00:21:21 [main] DEBUG i.n.c.MultithreadEventLoopGroup - -Dio.netty.eventLoopThreads: 16
2023-03-04 00:21:21 [main] DEBUG io.netty.channel.nio.NioEventLoop - -Dio.netty.noKeySetOptimization: false
2023-03-04 00:21:21 [main] DEBUG io.netty.channel.nio.NioEventLoop - -Dio.netty.selectorAutoRebuildThreshold: 512
2023-03-04 00:21:21 [main] DEBUG i.n.util.internal.PlatformDependent - org.jctools-core.MpscChunkedArrayQueue: available
2023-03-04 00:21:21 [main] DEBUG io.netty.channel.DefaultChannelId - -Dio.netty.processId: 40741 (auto-detected)
2023-03-04 00:21:21 [main] DEBUG io.netty.util.NetUtil - -Djava.net.preferIPv4Stack: false
2023-03-04 00:21:21 [main] DEBUG io.netty.util.NetUtil - -Djava.net.preferIPv6Addresses: false
2023-03-04 00:21:21 [main] DEBUG i.netty.util.NetUtilInitializations - Loopback interface: lo0 (lo0, 0:0:0:0:0:0:0:1%lo0)
2023-03-04 00:21:21 [main] DEBUG io.netty.util.NetUtil - Failed to get SOMAXCONN from sysctl and file /proc/sys/net/core/somaxconn. Default: 128
2023-03-04 00:21:21 [main] DEBUG io.netty.channel.DefaultChannelId - -Dio.netty.machineId: ac:de:48:ff:fe:00:11:22 (auto-detected)
2023-03-04 00:21:21 [main] DEBUG i.n.buffer.PooledByteBufAllocator - -Dio.netty.allocator.numHeapArenas: 16
2023-03-04 00:21:21 [main] DEBUG i.n.buffer.PooledByteBufAllocator - -Dio.netty.allocator.numDirectArenas: 16
2023-03-04 00:21:21 [main] DEBUG i.n.buffer.PooledByteBufAllocator - -Dio.netty.allocator.pageSize: 8192
2023-03-04 00:21:21 [main] DEBUG i.n.buffer.PooledByteBufAllocator - -Dio.netty.allocator.maxOrder: 9
2023-03-04 00:21:21 [main] DEBUG i.n.buffer.PooledByteBufAllocator - -Dio.netty.allocator.chunkSize: 4194304
2023-03-04 00:21:21 [main] DEBUG i.n.buffer.PooledByteBufAllocator - -Dio.netty.allocator.smallCacheSize: 256
2023-03-04 00:21:21 [main] DEBUG i.n.buffer.PooledByteBufAllocator - -Dio.netty.allocator.normalCacheSize: 64
2023-03-04 00:21:21 [main] DEBUG i.n.buffer.PooledByteBufAllocator - -Dio.netty.allocator.maxCachedBufferCapacity: 32768
2023-03-04 00:21:21 [main] DEBUG i.n.buffer.PooledByteBufAllocator - -Dio.netty.allocator.cacheTrimInterval: 8192
2023-03-04 00:21:21 [main] DEBUG i.n.buffer.PooledByteBufAllocator - -Dio.netty.allocator.cacheTrimIntervalMillis: 0
2023-03-04 00:21:21 [main] DEBUG i.n.buffer.PooledByteBufAllocator - -Dio.netty.allocator.useCacheForAllThreads: false
2023-03-04 00:21:21 [main] DEBUG i.n.buffer.PooledByteBufAllocator - -Dio.netty.allocator.maxCachedByteBuffersPerChunk: 1023
2023-03-04 00:21:21 [main] DEBUG io.netty.buffer.ByteBufUtil - -Dio.netty.allocator.type: pooled
2023-03-04 00:21:21 [main] DEBUG io.netty.buffer.ByteBufUtil - -Dio.netty.threadLocalDirectBufferSize: 0
2023-03-04 00:21:21 [main] DEBUG io.netty.buffer.ByteBufUtil - -Dio.netty.maxThreadLocalCharBufferSize: 16384
2023-03-04 00:21:21 [reactor-http-nio-1] DEBUG r.netty.transport.ServerTransport - [49994cc2, L:/[0:0:0:0:0:0:0:0]:8080] Bound new server
2023-03-04 00:21:21 [main] INFO  o.s.b.w.e.netty.NettyWebServer - Netty started on port 8080
2023-03-04 00:21:21 [main] DEBUG o.s.c.s.DefaultLifecycleProcessor - Successfully started bean 'webServerStartStop'
2023-03-04 00:21:21 [main] DEBUG o.s.c.s.DefaultLifecycleProcessor - Starting beans in phase 2147482623
2023-03-04 00:21:21 [main] DEBUG o.s.c.s.DefaultLifecycleProcessor - Successfully started bean 'webServerGracefulShutdown'
2023-03-04 00:21:21 [main] DEBUG o.s.c.s.DefaultLifecycleProcessor - Starting beans in phase 2147483547
2023-03-04 00:21:21 [main] DEBUG o.s.c.s.DefaultLifecycleProcessor - Successfully started bean 'org.springframework.kafka.config.internalKafkaListenerEndpointRegistry'
2023-03-04 00:21:21 [main] DEBUG o.s.b.a.l.ConditionEvaluationReportLogger - 


============================
CONDITIONS EVALUATION REPORT
============================


Positive matches:
-----------------

   AopAutoConfiguration matched:
      - @ConditionalOnProperty (spring.aop.auto=true) matched (OnPropertyCondition)

   AopAutoConfiguration.AspectJAutoProxyingConfiguration matched:
      - @ConditionalOnClass found required class 'org.aspectj.weaver.Advice' (OnClassCondition)

   AopAutoConfiguration.AspectJAutoProxyingConfiguration.CglibAutoProxyConfiguration matched:
      - @ConditionalOnProperty (spring.aop.proxy-target-class=true) matched (OnPropertyCondition)

   ClientHttpConnectorAutoConfiguration matched:
      - @ConditionalOnClass found required class 'org.springframework.web.reactive.function.client.WebClient' (OnClassCondition)

   ClientHttpConnectorAutoConfiguration#clientConnectorCustomizer matched:
      - @ConditionalOnBean (types: org.springframework.http.client.reactive.ClientHttpConnector; SearchStrategy: all) found bean 'reactorClientHttpConnector' (OnBeanCondition)

   ClientHttpConnectorConfiguration.ReactorNetty matched:
      - @ConditionalOnClass found required class 'reactor.netty.http.client.HttpClient' (OnClassCondition)
      - @ConditionalOnMissingBean (types: org.springframework.http.client.reactive.ClientHttpConnector; SearchStrategy: all) did not find any beans (OnBeanCondition)

   CodecsAutoConfiguration matched:
      - @ConditionalOnClass found required classes 'org.springframework.http.codec.CodecConfigurer', 'org.springframework.web.reactive.function.client.WebClient' (OnClassCondition)

   CodecsAutoConfiguration.JacksonCodecConfiguration matched:
      - @ConditionalOnClass found required class 'com.fasterxml.jackson.databind.ObjectMapper' (OnClassCondition)

   CodecsAutoConfiguration.JacksonCodecConfiguration#jacksonCodecCustomizer matched:
      - @ConditionalOnBean (types: com.fasterxml.jackson.databind.ObjectMapper; SearchStrategy: all) found bean 'jacksonObjectMapper' (OnBeanCondition)

   EmbeddedWebServerFactoryCustomizerAutoConfiguration matched:
      - @ConditionalOnWebApplication (required) found ConfigurableReactiveWebEnvironment (OnWebApplicationCondition)

   EmbeddedWebServerFactoryCustomizerAutoConfiguration.NettyWebServerFactoryCustomizerConfiguration matched:
      - @ConditionalOnClass found required class 'reactor.netty.http.server.HttpServer' (OnClassCondition)

   ErrorWebFluxAutoConfiguration matched:
      - @ConditionalOnClass found required class 'org.springframework.web.reactive.config.WebFluxConfigurer' (OnClassCondition)
      - found ConfigurableReactiveWebEnvironment (OnWebApplicationCondition)

   ErrorWebFluxAutoConfiguration#errorAttributes matched:
      - @ConditionalOnMissingBean (types: org.springframework.boot.web.reactive.error.ErrorAttributes; SearchStrategy: current) did not find any beans (OnBeanCondition)

   ErrorWebFluxAutoConfiguration#errorWebExceptionHandler matched:
      - @ConditionalOnMissingBean (types: org.springframework.boot.web.reactive.error.ErrorWebExceptionHandler; SearchStrategy: current) did not find any beans (OnBeanCondition)

   GenericCacheConfiguration matched:
      - Cache org.springframework.boot.autoconfigure.cache.GenericCacheConfiguration automatic cache type (CacheCondition)

   HttpHandlerAutoConfiguration matched:
      - @ConditionalOnClass found required classes 'org.springframework.web.reactive.DispatcherHandler', 'org.springframework.http.server.reactive.HttpHandler' (OnClassCondition)
      - found ConfigurableReactiveWebEnvironment (OnWebApplicationCondition)
      - @ConditionalOnMissingBean (types: org.springframework.http.server.reactive.HttpHandler; SearchStrategy: all) did not find any beans (OnBeanCondition)

   JacksonAutoConfiguration matched:
      - @ConditionalOnClass found required class 'com.fasterxml.jackson.databind.ObjectMapper' (OnClassCondition)

   JacksonAutoConfiguration.Jackson2ObjectMapperBuilderCustomizerConfiguration matched:
      - @ConditionalOnClass found required class 'org.springframework.http.converter.json.Jackson2ObjectMapperBuilder' (OnClassCondition)

   JacksonAutoConfiguration.JacksonObjectMapperBuilderConfiguration matched:
      - @ConditionalOnClass found required class 'org.springframework.http.converter.json.Jackson2ObjectMapperBuilder' (OnClassCondition)

   JacksonAutoConfiguration.JacksonObjectMapperBuilderConfiguration#jacksonObjectMapperBuilder matched:
      - @ConditionalOnMissingBean (types: org.springframework.http.converter.json.Jackson2ObjectMapperBuilder; SearchStrategy: all) did not find any beans (OnBeanCondition)

   JacksonAutoConfiguration.JacksonObjectMapperConfiguration matched:
      - @ConditionalOnClass found required class 'org.springframework.http.converter.json.Jackson2ObjectMapperBuilder' (OnClassCondition)

   JacksonAutoConfiguration.JacksonObjectMapperConfiguration#jacksonObjectMapper matched:
      - @ConditionalOnMissingBean (types: com.fasterxml.jackson.databind.ObjectMapper; SearchStrategy: all) did not find any beans (OnBeanCondition)

   JacksonAutoConfiguration.ParameterNamesModuleConfiguration matched:
      - @ConditionalOnClass found required class 'com.fasterxml.jackson.module.paramnames.ParameterNamesModule' (OnClassCondition)

   JacksonAutoConfiguration.ParameterNamesModuleConfiguration#parameterNamesModule matched:
      - @ConditionalOnMissingBean (types: com.fasterxml.jackson.module.paramnames.ParameterNamesModule; SearchStrategy: all) did not find any beans (OnBeanCondition)

   JmxAutoConfiguration matched:
      - @ConditionalOnClass found required class 'org.springframework.jmx.export.MBeanExporter' (OnClassCondition)
      - @ConditionalOnProperty (spring.jmx.enabled=true) matched (OnPropertyCondition)

   JmxAutoConfiguration#mbeanExporter matched:
      - @ConditionalOnMissingBean (types: org.springframework.jmx.export.MBeanExporter; SearchStrategy: current) did not find any beans (OnBeanCondition)

   JmxAutoConfiguration#mbeanServer matched:
      - @ConditionalOnMissingBean (types: javax.management.MBeanServer; SearchStrategy: all) did not find any beans (OnBeanCondition)

   JmxAutoConfiguration#objectNamingStrategy matched:
      - @ConditionalOnMissingBean (types: org.springframework.jmx.export.naming.ObjectNamingStrategy; SearchStrategy: current) did not find any beans (OnBeanCondition)

   KafkaAnnotationDrivenConfiguration matched:
      - @ConditionalOnClass found required class 'org.springframework.kafka.annotation.EnableKafka' (OnClassCondition)

   KafkaAnnotationDrivenConfiguration#kafkaListenerContainerFactory matched:
      - @ConditionalOnMissingBean (names: kafkaListenerContainerFactory; SearchStrategy: all) did not find any beans (OnBeanCondition)

   KafkaAnnotationDrivenConfiguration#kafkaListenerContainerFactoryConfigurer matched:
      - @ConditionalOnMissingBean (types: org.springframework.boot.autoconfigure.kafka.ConcurrentKafkaListenerContainerFactoryConfigurer; SearchStrategy: all) did not find any beans (OnBeanCondition)

   KafkaAnnotationDrivenConfiguration.EnableKafkaConfiguration matched:
      - @ConditionalOnMissingBean (names: org.springframework.kafka.config.internalKafkaListenerAnnotationProcessor; SearchStrategy: all) did not find any beans (OnBeanCondition)

   KafkaAutoConfiguration matched:
      - @ConditionalOnClass found required class 'org.springframework.kafka.core.KafkaTemplate' (OnClassCondition)

   KafkaAutoConfiguration#kafkaAdmin matched:
      - @ConditionalOnMissingBean (types: org.springframework.kafka.core.KafkaAdmin; SearchStrategy: all) did not find any beans (OnBeanCondition)

   KafkaAutoConfiguration#kafkaConsumerFactory matched:
      - @ConditionalOnMissingBean (types: org.springframework.kafka.core.ConsumerFactory; SearchStrategy: all) did not find any beans (OnBeanCondition)

   KafkaAutoConfiguration#kafkaProducerListener matched:
      - @ConditionalOnMissingBean (types: org.springframework.kafka.support.ProducerListener; SearchStrategy: all) did not find any beans (OnBeanCondition)

   LifecycleAutoConfiguration#defaultLifecycleProcessor matched:
      - @ConditionalOnMissingBean (names: lifecycleProcessor; SearchStrategy: current) did not find any beans (OnBeanCondition)

   MockKafkaStreamRunner matched:
      - @ConditionalOnProperty (twitter-to-kafka-service.enable-mock-tweets=true) matched (OnPropertyCondition)

   NettyAutoConfiguration matched:
      - @ConditionalOnClass found required class 'io.netty.util.NettyRuntime' (OnClassCondition)

   NoOpCacheConfiguration matched:
      - Cache org.springframework.boot.autoconfigure.cache.NoOpCacheConfiguration automatic cache type (CacheCondition)

   PersistenceExceptionTranslationAutoConfiguration matched:
      - @ConditionalOnClass found required class 'org.springframework.dao.annotation.PersistenceExceptionTranslationPostProcessor' (OnClassCondition)

   PersistenceExceptionTranslationAutoConfiguration#persistenceExceptionTranslationPostProcessor matched:
      - @ConditionalOnProperty (spring.dao.exceptiontranslation.enabled) matched (OnPropertyCondition)
      - @ConditionalOnMissingBean (types: org.springframework.dao.annotation.PersistenceExceptionTranslationPostProcessor; SearchStrategy: all) did not find any beans (OnBeanCondition)

   PropertyPlaceholderAutoConfiguration#propertySourcesPlaceholderConfigurer matched:
      - @ConditionalOnMissingBean (types: org.springframework.context.support.PropertySourcesPlaceholderConfigurer; SearchStrategy: current) did not find any beans (OnBeanCondition)

   ReactiveMultipartAutoConfiguration matched:
      - @ConditionalOnClass found required classes 'org.springframework.http.codec.multipart.DefaultPartHttpMessageReader', 'org.springframework.web.reactive.config.WebFluxConfigurer' (OnClassCondition)
      - found ConfigurableReactiveWebEnvironment (OnWebApplicationCondition)

   ReactiveWebServerFactoryAutoConfiguration matched:
      - @ConditionalOnClass found required class 'org.springframework.http.ReactiveHttpInputMessage' (OnClassCondition)
      - found ConfigurableReactiveWebEnvironment (OnWebApplicationCondition)

   ReactiveWebServerFactoryConfiguration.EmbeddedNetty matched:
      - @ConditionalOnClass found required class 'reactor.netty.http.server.HttpServer' (OnClassCondition)
      - @ConditionalOnMissingBean (types: org.springframework.boot.web.reactive.server.ReactiveWebServerFactory; SearchStrategy: all) did not find any beans (OnBeanCondition)

   ReactorNettyConfigurations.ReactorResourceFactoryConfiguration#reactorResourceFactory matched:
      - @ConditionalOnMissingBean (types: org.springframework.http.client.reactive.ReactorResourceFactory; SearchStrategy: all) did not find any beans (OnBeanCondition)

   SimpleCacheConfiguration matched:
      - Cache org.springframework.boot.autoconfigure.cache.SimpleCacheConfiguration automatic cache type (CacheCondition)

   SpringApplicationAdminJmxAutoConfiguration matched:
      - @ConditionalOnProperty (spring.application.admin.enabled=true) matched (OnPropertyCondition)

   SpringApplicationAdminJmxAutoConfiguration#springApplicationAdminRegistrar matched:
      - @ConditionalOnMissingBean (types: org.springframework.boot.admin.SpringApplicationAdminMXBeanRegistrar; SearchStrategy: all) did not find any beans (OnBeanCondition)

   SqlInitializationAutoConfiguration matched:
      - @ConditionalOnProperty (spring.sql.init.enabled) matched (OnPropertyCondition)
      - NoneNestedConditions 0 matched 1 did not; NestedCondition on SqlInitializationAutoConfiguration.SqlInitializationModeCondition.ModeIsNever @ConditionalOnProperty (spring.sql.init.mode=never) did not find property 'mode' (SqlInitializationAutoConfiguration.SqlInitializationModeCondition)

   TaskExecutionAutoConfiguration matched:
      - @ConditionalOnClass found required class 'org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor' (OnClassCondition)

   TaskExecutionAutoConfiguration#applicationTaskExecutor matched:
      - @ConditionalOnMissingBean (types: java.util.concurrent.Executor; SearchStrategy: all) did not find any beans (OnBeanCondition)

   TaskExecutionAutoConfiguration#taskExecutorBuilder matched:
      - @ConditionalOnMissingBean (types: org.springframework.boot.task.TaskExecutorBuilder; SearchStrategy: all) did not find any beans (OnBeanCondition)

   TaskSchedulingAutoConfiguration matched:
      - @ConditionalOnClass found required class 'org.springframework.scheduling.concurrent.ThreadPoolTaskScheduler' (OnClassCondition)

   TaskSchedulingAutoConfiguration#taskSchedulerBuilder matched:
      - @ConditionalOnMissingBean (types: org.springframework.boot.task.TaskSchedulerBuilder; SearchStrategy: all) did not find any beans (OnBeanCondition)

   TransactionAutoConfiguration matched:
      - @ConditionalOnClass found required class 'org.springframework.transaction.PlatformTransactionManager' (OnClassCondition)

   TransactionAutoConfiguration#platformTransactionManagerCustomizers matched:
      - @ConditionalOnMissingBean (types: org.springframework.boot.autoconfigure.transaction.TransactionManagerCustomizers; SearchStrategy: all) did not find any beans (OnBeanCondition)

   WebClientAutoConfiguration matched:
      - @ConditionalOnClass found required class 'org.springframework.web.reactive.function.client.WebClient' (OnClassCondition)

   WebClientAutoConfiguration#webClientBuilder matched:
      - @ConditionalOnMissingBean (types: org.springframework.web.reactive.function.client.WebClient$Builder; SearchStrategy: all) did not find any beans (OnBeanCondition)

   WebClientAutoConfiguration.WebClientCodecsConfiguration matched:
      - @ConditionalOnBean (types: org.springframework.boot.web.codec.CodecCustomizer; SearchStrategy: all) found beans 'jacksonCodecCustomizer', 'defaultCodecCustomizer', 'defaultPartHttpMessageReaderCustomizer' (OnBeanCondition)

   WebClientAutoConfiguration.WebClientCodecsConfiguration#exchangeStrategiesCustomizer matched:
      - @ConditionalOnMissingBean (types: org.springframework.boot.autoconfigure.web.reactive.function.client.WebClientCodecCustomizer; SearchStrategy: all) did not find any beans (OnBeanCondition)

   WebFluxAutoConfiguration matched:
      - @ConditionalOnClass found required class 'org.springframework.web.reactive.config.WebFluxConfigurer' (OnClassCondition)
      - found ConfigurableReactiveWebEnvironment (OnWebApplicationCondition)
      - @ConditionalOnMissingBean (types: org.springframework.web.reactive.config.WebFluxConfigurationSupport; SearchStrategy: all) did not find any beans (OnBeanCondition)

   WebFluxAutoConfiguration.EnableWebFluxConfiguration#localeContextResolver matched:
      - @ConditionalOnMissingBean (names: localeContextResolver; SearchStrategy: all) did not find any beans (OnBeanCondition)

   WebFluxAutoConfiguration.EnableWebFluxConfiguration#webSessionManager matched:
      - @ConditionalOnMissingBean (names: webSessionManager; SearchStrategy: all) did not find any beans (OnBeanCondition)

   WebSessionIdResolverAutoConfiguration matched:
      - @ConditionalOnClass found required classes 'org.springframework.web.server.session.WebSessionManager', 'reactor.core.publisher.Mono' (OnClassCondition)
      - found ConfigurableReactiveWebEnvironment (OnWebApplicationCondition)

   WebSessionIdResolverAutoConfiguration#webSessionIdResolver matched:
      - @ConditionalOnMissingBean (types: org.springframework.web.server.session.WebSessionIdResolver; SearchStrategy: all) did not find any beans (OnBeanCondition)


Negative matches:
-----------------

   AopAutoConfiguration.AspectJAutoProxyingConfiguration.JdkDynamicAutoProxyConfiguration:
      Did not match:
         - @ConditionalOnProperty (spring.aop.proxy-target-class=false) did not find property 'proxy-target-class' (OnPropertyCondition)

   AopAutoConfiguration.ClassProxyingConfiguration:
      Did not match:
         - @ConditionalOnMissingClass found unwanted class 'org.aspectj.weaver.Advice' (OnClassCondition)

   ArtemisAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'jakarta.jms.ConnectionFactory' (OnClassCondition)

   BatchAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.batch.core.launch.JobLauncher' (OnClassCondition)

   Cache2kCacheConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.cache2k.Cache2kBuilder' (OnClassCondition)

   CacheAutoConfiguration:
      Did not match:
         - @ConditionalOnBean (types: org.springframework.cache.interceptor.CacheAspectSupport; SearchStrategy: all) did not find any beans of type org.springframework.cache.interceptor.CacheAspectSupport (OnBeanCondition)
      Matched:
         - @ConditionalOnClass found required class 'org.springframework.cache.CacheManager' (OnClassCondition)

   CacheAutoConfiguration.CacheManagerEntityManagerFactoryDependsOnPostProcessor:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean' (OnClassCondition)
         - Ancestor org.springframework.boot.autoconfigure.cache.CacheAutoConfiguration did not match (ConditionEvaluationReport.AncestorsMatchedCondition)

   CaffeineCacheConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.github.benmanes.caffeine.cache.Caffeine' (OnClassCondition)

   CassandraAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.datastax.oss.driver.api.core.CqlSession' (OnClassCondition)

   CassandraDataAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.datastax.oss.driver.api.core.CqlSession' (OnClassCondition)

   CassandraReactiveDataAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.datastax.oss.driver.api.core.CqlSession' (OnClassCondition)

   CassandraReactiveRepositoriesAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.data.cassandra.ReactiveSession' (OnClassCondition)

   CassandraRepositoriesAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.datastax.oss.driver.api.core.CqlSession' (OnClassCondition)

   ClientHttpConnectorConfiguration.HttpClient5:
      Did not match:
         - @ConditionalOnClass did not find required classes 'org.apache.hc.client5.http.impl.async.HttpAsyncClients', 'org.apache.hc.core5.http.nio.AsyncRequestProducer' (OnClassCondition)

   ClientHttpConnectorConfiguration.JdkClient:
      Did not match:
         - @ConditionalOnMissingBean (types: org.springframework.http.client.reactive.ClientHttpConnector; SearchStrategy: all) found beans of type 'org.springframework.http.client.reactive.ClientHttpConnector' reactorClientHttpConnector (OnBeanCondition)
      Matched:
         - @ConditionalOnClass found required class 'java.net.http.HttpClient' (OnClassCondition)

   ClientHttpConnectorConfiguration.JettyClient:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.eclipse.jetty.reactive.client.ReactiveRequest' (OnClassCondition)

   CouchbaseAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.couchbase.client.java.Cluster' (OnClassCondition)

   CouchbaseCacheConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.couchbase.client.java.Cluster' (OnClassCondition)

   CouchbaseDataAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.couchbase.client.java.Bucket' (OnClassCondition)

   CouchbaseReactiveDataAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.couchbase.client.java.Cluster' (OnClassCondition)

   CouchbaseReactiveRepositoriesAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.couchbase.client.java.Cluster' (OnClassCondition)

   CouchbaseRepositoriesAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.couchbase.client.java.Bucket' (OnClassCondition)

   DataSourceAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.jdbc.datasource.embedded.EmbeddedDatabaseType' (OnClassCondition)

   DataSourceInitializationConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.jdbc.datasource.init.DatabasePopulator' (OnClassCondition)

   DataSourceTransactionManagerAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.jdbc.core.JdbcTemplate' (OnClassCondition)

   DispatcherServletAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.web.servlet.DispatcherServlet' (OnClassCondition)

   ElasticsearchClientAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'co.elastic.clients.elasticsearch.ElasticsearchClient' (OnClassCondition)

   ElasticsearchDataAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.data.elasticsearch.client.elc.ElasticsearchTemplate' (OnClassCondition)

   ElasticsearchRepositoriesAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.data.elasticsearch.repository.ElasticsearchRepository' (OnClassCondition)

   ElasticsearchRestClientAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.elasticsearch.client.RestClientBuilder' (OnClassCondition)

   EmbeddedLdapAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.unboundid.ldap.listener.InMemoryDirectoryServer' (OnClassCondition)

   EmbeddedWebServerFactoryCustomizerAutoConfiguration.JettyWebServerFactoryCustomizerConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required classes 'org.eclipse.jetty.server.Server', 'org.eclipse.jetty.util.Loader', 'org.eclipse.jetty.webapp.WebAppContext' (OnClassCondition)

   EmbeddedWebServerFactoryCustomizerAutoConfiguration.TomcatWebServerFactoryCustomizerConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required classes 'org.apache.catalina.startup.Tomcat', 'org.apache.coyote.UpgradeProtocol' (OnClassCondition)

   EmbeddedWebServerFactoryCustomizerAutoConfiguration.UndertowWebServerFactoryCustomizerConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required classes 'io.undertow.Undertow', 'org.xnio.SslClientAuthMode' (OnClassCondition)

   ErrorMvcAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'jakarta.servlet.Servlet' (OnClassCondition)

   FlywayAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.flywaydb.core.Flyway' (OnClassCondition)

   FreeMarkerAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'freemarker.template.Configuration' (OnClassCondition)

   GraphQlAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'graphql.GraphQL' (OnClassCondition)

   GraphQlQueryByExampleAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'graphql.GraphQL' (OnClassCondition)

   GraphQlQuerydslAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'graphql.GraphQL' (OnClassCondition)

   GraphQlRSocketAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'graphql.GraphQL' (OnClassCondition)

   GraphQlReactiveQueryByExampleAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'graphql.GraphQL' (OnClassCondition)

   GraphQlReactiveQuerydslAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'graphql.GraphQL' (OnClassCondition)

   GraphQlWebFluxAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'graphql.GraphQL' (OnClassCondition)

   GraphQlWebFluxSecurityAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'graphql.GraphQL' (OnClassCondition)

   GraphQlWebMvcAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'graphql.GraphQL' (OnClassCondition)

   GraphQlWebMvcSecurityAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'graphql.GraphQL' (OnClassCondition)

   GroovyTemplateAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'groovy.text.markup.MarkupTemplateEngine' (OnClassCondition)

   GsonAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.google.gson.Gson' (OnClassCondition)

   H2ConsoleAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.h2.server.web.JakartaWebServlet' (OnClassCondition)

   HazelcastAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.hazelcast.core.HazelcastInstance' (OnClassCondition)

   HazelcastCacheConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.hazelcast.core.HazelcastInstance' (OnClassCondition)

   HazelcastJpaDependencyAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.hazelcast.core.HazelcastInstance' (OnClassCondition)

   HibernateJpaAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'jakarta.persistence.EntityManager' (OnClassCondition)

   HttpEncodingAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.web.filter.CharacterEncodingFilter' (OnClassCondition)

   HttpMessageConvertersAutoConfiguration:
      Did not match:
         - NoneNestedConditions 1 matched 0 did not; NestedCondition on HttpMessageConvertersAutoConfiguration.NotReactiveWebApplicationCondition.ReactiveWebApplication found ConfigurableReactiveWebEnvironment (HttpMessageConvertersAutoConfiguration.NotReactiveWebApplicationCondition)
      Matched:
         - @ConditionalOnClass found required class 'org.springframework.http.converter.HttpMessageConverter' (OnClassCondition)

   HypermediaAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.hateoas.EntityModel' (OnClassCondition)

   InfinispanCacheConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.infinispan.spring.embedded.provider.SpringEmbeddedCacheManager' (OnClassCondition)

   InfluxDbAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.influxdb.InfluxDB' (OnClassCondition)

   IntegrationAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.integration.config.EnableIntegration' (OnClassCondition)

   JCacheCacheConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'javax.cache.Caching' (OnClassCondition)

   JdbcRepositoriesAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.data.jdbc.repository.config.AbstractJdbcConfiguration' (OnClassCondition)

   JdbcTemplateAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.jdbc.core.JdbcTemplate' (OnClassCondition)

   JerseyAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'jakarta.servlet.ServletRegistration' (OnClassCondition)

   JmsAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'jakarta.jms.Message' (OnClassCondition)

   JndiConnectionFactoryAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.jms.core.JmsTemplate' (OnClassCondition)

   JndiDataSourceAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.jdbc.datasource.embedded.EmbeddedDatabaseType' (OnClassCondition)

   JooqAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.jooq.DSLContext' (OnClassCondition)

   JpaRepositoriesAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.data.jpa.repository.JpaRepository' (OnClassCondition)

   JsonbAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'jakarta.json.bind.Jsonb' (OnClassCondition)

   JtaAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'jakarta.transaction.Transaction' (OnClassCondition)

   KafkaAutoConfiguration#kafkaJaasInitializer:
      Did not match:
         - @ConditionalOnProperty (spring.kafka.jaas.enabled) did not find property 'spring.kafka.jaas.enabled' (OnPropertyCondition)

   KafkaAutoConfiguration#kafkaProducerFactory:
      Did not match:
         - @ConditionalOnMissingBean (types: org.springframework.kafka.core.ProducerFactory; SearchStrategy: all) found beans of type 'org.springframework.kafka.core.ProducerFactory' producerFactory (OnBeanCondition)

   KafkaAutoConfiguration#kafkaRetryTopicConfiguration:
      Did not match:
         - @ConditionalOnProperty (spring.kafka.retry.topic.enabled) did not find property 'spring.kafka.retry.topic.enabled' (OnPropertyCondition)

   KafkaAutoConfiguration#kafkaTemplate:
      Did not match:
         - @ConditionalOnMissingBean (types: org.springframework.kafka.core.KafkaTemplate; SearchStrategy: all) found beans of type 'org.springframework.kafka.core.KafkaTemplate' kafkaTemplate (OnBeanCondition)

   KafkaAutoConfiguration#kafkaTransactionManager:
      Did not match:
         - @ConditionalOnProperty (spring.kafka.producer.transaction-id-prefix) did not find property 'spring.kafka.producer.transaction-id-prefix' (OnPropertyCondition)

   KafkaStreamsAnnotationDrivenConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.apache.kafka.streams.StreamsBuilder' (OnClassCondition)

   LdapAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.ldap.core.ContextSource' (OnClassCondition)

   LdapRepositoriesAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.data.ldap.repository.LdapRepository' (OnClassCondition)

   LiquibaseAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'liquibase.change.DatabaseChange' (OnClassCondition)

   MailSenderAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'jakarta.activation.MimeType' (OnClassCondition)

   MailSenderValidatorAutoConfiguration:
      Did not match:
         - @ConditionalOnSingleCandidate did not find required type 'org.springframework.mail.javamail.JavaMailSenderImpl' (OnBeanCondition)

   MessageSourceAutoConfiguration:
      Did not match:
         - ResourceBundle did not find bundle with basename messages (MessageSourceAutoConfiguration.ResourceBundleCondition)

   MongoAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.mongodb.client.MongoClient' (OnClassCondition)

   MongoDataAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.mongodb.client.MongoClient' (OnClassCondition)

   MongoReactiveAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.mongodb.reactivestreams.client.MongoClient' (OnClassCondition)

   MongoReactiveDataAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.mongodb.reactivestreams.client.MongoClient' (OnClassCondition)

   MongoReactiveRepositoriesAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.mongodb.reactivestreams.client.MongoClient' (OnClassCondition)

   MongoRepositoriesAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.mongodb.client.MongoClient' (OnClassCondition)

   MultipartAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'jakarta.servlet.MultipartConfigElement' (OnClassCondition)

   MustacheAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.samskivert.mustache.Mustache' (OnClassCondition)

   Neo4jAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.neo4j.driver.Driver' (OnClassCondition)

   Neo4jDataAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.neo4j.driver.Driver' (OnClassCondition)

   Neo4jReactiveDataAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.neo4j.driver.Driver' (OnClassCondition)

   Neo4jReactiveRepositoriesAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.neo4j.driver.Driver' (OnClassCondition)

   Neo4jRepositoriesAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.neo4j.driver.Driver' (OnClassCondition)

   OAuth2ClientAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.security.config.annotation.web.configuration.EnableWebSecurity' (OnClassCondition)

   OAuth2ResourceServerAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.security.oauth2.server.resource.authentication.BearerTokenAuthenticationToken' (OnClassCondition)

   ProjectInfoAutoConfiguration#buildProperties:
      Did not match:
         - @ConditionalOnResource did not find resource '${spring.info.build.location:classpath:META-INF/build-info.properties}' (OnResourceCondition)

   ProjectInfoAutoConfiguration#gitProperties:
      Did not match:
         - GitResource did not find git info at classpath:git.properties (ProjectInfoAutoConfiguration.GitResourceAvailableCondition)

   QuartzAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.quartz.Scheduler' (OnClassCondition)

   R2dbcAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'io.r2dbc.spi.ConnectionFactory' (OnClassCondition)

   R2dbcDataAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.data.r2dbc.core.R2dbcEntityTemplate' (OnClassCondition)

   R2dbcInitializationConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required classes 'io.r2dbc.spi.ConnectionFactory', 'org.springframework.r2dbc.connection.init.DatabasePopulator' (OnClassCondition)

   R2dbcRepositoriesAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'io.r2dbc.spi.ConnectionFactory' (OnClassCondition)

   R2dbcTransactionManagerAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.r2dbc.connection.R2dbcTransactionManager' (OnClassCondition)

   RSocketGraphQlClientAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'graphql.GraphQL' (OnClassCondition)

   RSocketMessagingAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'io.rsocket.RSocket' (OnClassCondition)

   RSocketRequesterAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'io.rsocket.RSocket' (OnClassCondition)

   RSocketSecurityAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.security.rsocket.core.SecuritySocketAcceptorInterceptor' (OnClassCondition)

   RSocketServerAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'io.rsocket.core.RSocketServer' (OnClassCondition)

   RSocketStrategiesAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'io.rsocket.RSocket' (OnClassCondition)

   RabbitAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.rabbitmq.client.Channel' (OnClassCondition)

   ReactiveElasticsearchClientAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'co.elastic.clients.transport.ElasticsearchTransport' (OnClassCondition)

   ReactiveElasticsearchRepositoriesAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.data.elasticsearch.client.elc.ReactiveElasticsearchClient' (OnClassCondition)

   ReactiveOAuth2ClientAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.security.config.annotation.web.reactive.EnableWebFluxSecurity' (OnClassCondition)

   ReactiveOAuth2ResourceServerAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.security.config.annotation.web.reactive.EnableWebFluxSecurity' (OnClassCondition)

   ReactiveSecurityAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.security.config.annotation.web.reactive.EnableWebFluxSecurity' (OnClassCondition)

   ReactiveUserDetailsServiceAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.security.authentication.ReactiveAuthenticationManager' (OnClassCondition)

   ReactiveWebServerFactoryAutoConfiguration#forwardedHeaderTransformer:
      Did not match:
         - @ConditionalOnProperty (server.forward-headers-strategy=framework) did not find property 'server.forward-headers-strategy' (OnPropertyCondition)

   ReactiveWebServerFactoryAutoConfiguration#tomcatReactiveWebServerFactoryCustomizer:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.apache.catalina.startup.Tomcat' (OnClassCondition)

   ReactiveWebServerFactoryConfiguration.EmbeddedJetty:
      Did not match:
         - @ConditionalOnClass did not find required classes 'org.eclipse.jetty.server.Server', 'org.eclipse.jetty.servlet.ServletHolder' (OnClassCondition)

   ReactiveWebServerFactoryConfiguration.EmbeddedTomcat:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.apache.catalina.startup.Tomcat' (OnClassCondition)

   ReactiveWebServerFactoryConfiguration.EmbeddedUndertow:
      Did not match:
         - @ConditionalOnClass did not find required class 'io.undertow.Undertow' (OnClassCondition)

   RedisAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.data.redis.core.RedisOperations' (OnClassCondition)

   RedisCacheConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.data.redis.connection.RedisConnectionFactory' (OnClassCondition)

   RedisReactiveAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.data.redis.connection.ReactiveRedisConnectionFactory' (OnClassCondition)

   RedisRepositoriesAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.data.redis.repository.configuration.EnableRedisRepositories' (OnClassCondition)

   RepositoryRestMvcAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.data.rest.webmvc.config.RepositoryRestMvcConfiguration' (OnClassCondition)

   RestTemplateAutoConfiguration:
      Did not match:
         - NoneNestedConditions 1 matched 0 did not; NestedCondition on RestTemplateAutoConfiguration.NotReactiveWebApplicationCondition.ReactiveWebApplication found ConfigurableReactiveWebEnvironment (RestTemplateAutoConfiguration.NotReactiveWebApplicationCondition)
      Matched:
         - @ConditionalOnClass found required class 'org.springframework.web.client.RestTemplate' (OnClassCondition)

   Saml2RelyingPartyAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.security.saml2.provider.service.registration.RelyingPartyRegistrationRepository' (OnClassCondition)

   SecurityAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.security.authentication.DefaultAuthenticationEventPublisher' (OnClassCondition)

   SecurityFilterAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.security.config.http.SessionCreationPolicy' (OnClassCondition)

   SendGridAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.sendgrid.SendGrid' (OnClassCondition)

   ServletWebServerFactoryAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'jakarta.servlet.ServletRequest' (OnClassCondition)

   SessionAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.session.Session' (OnClassCondition)

   SpringDataWebAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.data.web.PageableHandlerMethodArgumentResolver' (OnClassCondition)

   TaskSchedulingAutoConfiguration#scheduledBeanLazyInitializationExcludeFilter:
      Did not match:
         - @ConditionalOnBean (names: org.springframework.context.annotation.internalScheduledAnnotationProcessor; SearchStrategy: all) did not find any beans named org.springframework.context.annotation.internalScheduledAnnotationProcessor (OnBeanCondition)

   TaskSchedulingAutoConfiguration#taskScheduler:
      Did not match:
         - @ConditionalOnBean (names: org.springframework.context.annotation.internalScheduledAnnotationProcessor; SearchStrategy: all) did not find any beans named org.springframework.context.annotation.internalScheduledAnnotationProcessor (OnBeanCondition)

   ThymeleafAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.thymeleaf.spring6.SpringTemplateEngine' (OnClassCondition)

   TransactionAutoConfiguration#transactionalOperator:
      Did not match:
         - @ConditionalOnSingleCandidate (types: org.springframework.transaction.ReactiveTransactionManager; SearchStrategy: all) did not find any beans (OnBeanCondition)

   TransactionAutoConfiguration.EnableTransactionManagementConfiguration:
      Did not match:
         - @ConditionalOnBean (types: org.springframework.transaction.TransactionManager; SearchStrategy: all) did not find any beans of type org.springframework.transaction.TransactionManager (OnBeanCondition)

   TransactionAutoConfiguration.EnableTransactionManagementConfiguration.CglibAutoProxyConfiguration:
      Did not match:
         - Ancestor org.springframework.boot.autoconfigure.transaction.TransactionAutoConfiguration$EnableTransactionManagementConfiguration did not match (ConditionEvaluationReport.AncestorsMatchedCondition)
      Matched:
         - @ConditionalOnProperty (spring.aop.proxy-target-class=true) matched (OnPropertyCondition)

   TransactionAutoConfiguration.EnableTransactionManagementConfiguration.JdkDynamicAutoProxyConfiguration:
      Did not match:
         - @ConditionalOnProperty (spring.aop.proxy-target-class=false) did not find property 'proxy-target-class' (OnPropertyCondition)
         - Ancestor org.springframework.boot.autoconfigure.transaction.TransactionAutoConfiguration$EnableTransactionManagementConfiguration did not match (ConditionEvaluationReport.AncestorsMatchedCondition)

   TransactionAutoConfiguration.TransactionTemplateConfiguration:
      Did not match:
         - @ConditionalOnSingleCandidate (types: org.springframework.transaction.PlatformTransactionManager; SearchStrategy: all) did not find any beans (OnBeanCondition)

   TwitterKafkaStreamRunner:
      Did not match:
         - @ConditionalOnProperty (twitter-to-kafka-service.enable-mock-tweets=false) found different value in property 'twitter-to-kafka-service.enable-mock-tweets' (OnPropertyCondition)

   UserDetailsServiceAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.security.authentication.AuthenticationManager' (OnClassCondition)

   ValidationAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'jakarta.validation.executable.ExecutableValidator' (OnClassCondition)

   WebFluxAutoConfiguration#hiddenHttpMethodFilter:
      Did not match:
         - @ConditionalOnProperty (spring.webflux.hiddenmethod.filter.enabled) did not find property 'enabled' (OnPropertyCondition)

   WebFluxAutoConfiguration.ProblemDetailsErrorHandlingConfiguration:
      Did not match:
         - @ConditionalOnProperty (spring.webflux.problemdetails.enabled=true) did not find property 'enabled' (OnPropertyCondition)

   WebFluxAutoConfiguration.ResourceChainCustomizerConfiguration:
      Did not match:
         - @ConditionalOnEnabledResourceChain did not find class org.webjars.WebJarAssetLocator (OnEnabledResourceChainCondition)

   WebMvcAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'jakarta.servlet.Servlet' (OnClassCondition)

   WebServiceTemplateAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.oxm.Marshaller' (OnClassCondition)

   WebServicesAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.ws.transport.http.MessageDispatcherServlet' (OnClassCondition)

   WebSocketMessagingAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.web.socket.config.annotation.WebSocketMessageBrokerConfigurer' (OnClassCondition)

   WebSocketReactiveAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'jakarta.servlet.Servlet' (OnClassCondition)

   WebSocketServletAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'jakarta.servlet.Servlet' (OnClassCondition)

   XADataSourceAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'jakarta.transaction.TransactionManager' (OnClassCondition)


Exclusions:
-----------

    None


Unconditional classes:
----------------------

    org.springframework.boot.autoconfigure.context.ConfigurationPropertiesAutoConfiguration

    org.springframework.boot.autoconfigure.context.LifecycleAutoConfiguration

    org.springframework.boot.autoconfigure.context.PropertyPlaceholderAutoConfiguration

    org.springframework.boot.autoconfigure.availability.ApplicationAvailabilityAutoConfiguration

    org.springframework.boot.autoconfigure.info.ProjectInfoAutoConfiguration



2023-03-04 00:21:21 [main] INFO  x.g.m.d.t.t.k.s.TwitterToKafkaServiceApplication - Started TwitterToKafkaServiceApplication in 2.492 seconds (process running for 3.391)
2023-03-04 00:21:21 [main] DEBUG o.s.b.a.ApplicationAvailabilityBean - Application availability state LivenessState changed to CORRECT
2023-03-04 00:21:21 [main] INFO  x.g.m.d.t.t.k.s.TwitterToKafkaServiceApplication - Application started!
2023-03-04 00:21:21 [main] DEBUG o.s.retry.support.RetryTemplate - Retry: count=0
2023-03-04 00:21:21 [main] INFO  x.g.m.d.k.a.client.KafkaAdminClient - Creating 1 topic(s), attempt 0
2023-03-04 00:21:21 [main] DEBUG o.a.k.clients.admin.KafkaAdminClient - [AdminClient clientId=adminclient-1] Queueing Call(callName=createTopics, deadlineMs=1677876741545, tries=0, nextAllowedTryMs=0) with a timeout 30000 ms from now.
2023-03-04 00:21:21 [main] DEBUG o.s.retry.support.RetryTemplate - Retry: count=0
2023-03-04 00:21:21 [kafka-admin-client-thread | adminclient-1] DEBUG o.apache.kafka.clients.ClientUtils - Resolved host localhost as 127.0.0.1
2023-03-04 00:21:21 [kafka-admin-client-thread | adminclient-1] DEBUG o.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Initiating connection to node localhost:39092 (id: 3 rack: null) using address localhost/127.0.0.1
2023-03-04 00:21:21 [main] INFO  x.g.m.d.k.a.client.KafkaAdminClient - Reading kafka topic [twitter-topic], attempt 0
2023-03-04 00:21:21 [main] DEBUG o.a.k.clients.admin.KafkaAdminClient - [AdminClient clientId=adminclient-1] Queueing Call(callName=listTopics, deadlineMs=1677876741546, tries=0, nextAllowedTryMs=0) with a timeout 30000 ms from now.
2023-03-04 00:21:21 [kafka-admin-client-thread | adminclient-1] DEBUG o.a.kafka.common.network.Selector - [AdminClient clientId=adminclient-1] Created socket with SO_RCVBUF = 342972, SO_SNDBUF = 146988, SO_TIMEOUT = 0 to node 3
2023-03-04 00:21:21 [kafka-admin-client-thread | adminclient-1] DEBUG o.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Completed connection to node 3. Fetching API versions.
2023-03-04 00:21:21 [kafka-admin-client-thread | adminclient-1] DEBUG o.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Initiating API versions fetch from node 3.
2023-03-04 00:21:21 [kafka-admin-client-thread | adminclient-1] DEBUG o.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Sending API_VERSIONS request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=adminclient-1, correlationId=3) and timeout 3600000 to node 3: ApiVersionsRequestData(clientSoftwareName='apache-kafka-java', clientSoftwareVersion='3.3.2')
2023-03-04 00:21:21 [kafka-admin-client-thread | adminclient-1] DEBUG o.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Received API_VERSIONS response from node 3 for request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=adminclient-1, correlationId=3): ApiVersionsResponseData(errorCode=35, apiKeys=[], throttleTimeMs=0, supportedFeatures=[], finalizedFeaturesEpoch=-1, finalizedFeatures=[])
2023-03-04 00:21:21 [kafka-admin-client-thread | adminclient-1] DEBUG o.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Initiating API versions fetch from node 3.
2023-03-04 00:21:21 [kafka-admin-client-thread | adminclient-1] DEBUG o.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Sending API_VERSIONS request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=0, clientId=adminclient-1, correlationId=4) and timeout 3600000 to node 3: ApiVersionsRequestData(clientSoftwareName='apache-kafka-java', clientSoftwareVersion='3.3.2')
2023-03-04 00:21:21 [kafka-admin-client-thread | adminclient-1] DEBUG o.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Received API_VERSIONS response from node 3 for request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=0, clientId=adminclient-1, correlationId=4): ApiVersionsResponseData(errorCode=0, apiKeys=[ApiVersion(apiKey=0, minVersion=0, maxVersion=6), ApiVersion(apiKey=1, minVersion=0, maxVersion=8), ApiVersion(apiKey=2, minVersion=0, maxVersion=3), ApiVersion(apiKey=3, minVersion=0, maxVersion=6), ApiVersion(apiKey=4, minVersion=0, maxVersion=1), ApiVersion(apiKey=5, minVersion=0, maxVersion=0), ApiVersion(apiKey=6, minVersion=0, maxVersion=4), ApiVersion(apiKey=7, minVersion=0, maxVersion=1), ApiVersion(apiKey=8, minVersion=0, maxVersion=4), ApiVersion(apiKey=9, minVersion=0, maxVersion=4), ApiVersion(apiKey=10, minVersion=0, maxVersion=2), ApiVersion(apiKey=11, minVersion=0, maxVersion=3), ApiVersion(apiKey=12, minVersion=0, maxVersion=2), ApiVersion(apiKey=13, minVersion=0, maxVersion=2), ApiVersion(apiKey=14, minVersion=0, maxVersion=2), ApiVersion(apiKey=15, minVersion=0, maxVersion=2), ApiVersion(apiKey=16, minVersion=0, maxVersion=2), ApiVersion(apiKey=17, minVersion=0, maxVersion=1), ApiVersion(apiKey=18, minVersion=0, maxVersion=2), ApiVersion(apiKey=19, minVersion=0, maxVersion=3), ApiVersion(apiKey=20, minVersion=0, maxVersion=2), ApiVersion(apiKey=21, minVersion=0, maxVersion=1), ApiVersion(apiKey=22, minVersion=0, maxVersion=1), ApiVersion(apiKey=23, minVersion=0, maxVersion=1), ApiVersion(apiKey=24, minVersion=0, maxVersion=1), ApiVersion(apiKey=25, minVersion=0, maxVersion=1), ApiVersion(apiKey=26, minVersion=0, maxVersion=1), ApiVersion(apiKey=27, minVersion=0, maxVersion=0), ApiVersion(apiKey=28, minVersion=0, maxVersion=1), ApiVersion(apiKey=29, minVersion=0, maxVersion=1), ApiVersion(apiKey=30, minVersion=0, maxVersion=1), ApiVersion(apiKey=31, minVersion=0, maxVersion=1), ApiVersion(apiKey=32, minVersion=0, maxVersion=2), ApiVersion(apiKey=33, minVersion=0, maxVersion=1), ApiVersion(apiKey=34, minVersion=0, maxVersion=1), ApiVersion(apiKey=35, minVersion=0, maxVersion=1), ApiVersion(apiKey=36, minVersion=0, maxVersion=0), ApiVersion(apiKey=37, minVersion=0, maxVersion=1), ApiVersion(apiKey=38, minVersion=0, maxVersion=1), ApiVersion(apiKey=39, minVersion=0, maxVersion=1), ApiVersion(apiKey=40, minVersion=0, maxVersion=1), ApiVersion(apiKey=41, minVersion=0, maxVersion=1), ApiVersion(apiKey=42, minVersion=0, maxVersion=1)], throttleTimeMs=0, supportedFeatures=[], finalizedFeaturesEpoch=-1, finalizedFeatures=[])
2023-03-04 00:21:21 [kafka-admin-client-thread | adminclient-1] DEBUG o.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Node 3 has finalized features epoch: -1, finalized features: [], supported features: [], API versions: (Produce(0): 0 to 6 [usable: 6], Fetch(1): 0 to 8 [usable: 8], ListOffsets(2): 0 to 3 [usable: 3], Metadata(3): 0 to 6 [usable: 6], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 4 [usable: 4], OffsetFetch(9): 0 to 4 [usable: 4], FindCoordinator(10): 0 to 2 [usable: 2], JoinGroup(11): 0 to 3 [usable: 3], Heartbeat(12): 0 to 2 [usable: 2], LeaveGroup(13): 0 to 2 [usable: 2], SyncGroup(14): 0 to 2 [usable: 2], DescribeGroups(15): 0 to 2 [usable: 2], ListGroups(16): 0 to 2 [usable: 2], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 2], CreateTopics(19): 0 to 3 [usable: 3], DeleteTopics(20): 0 to 2 [usable: 2], DeleteRecords(21): 0 to 1 [usable: 1], InitProducerId(22): 0 to 1 [usable: 1], OffsetForLeaderEpoch(23): 0 to 1 [usable: 1], AddPartitionsToTxn(24): 0 to 1 [usable: 1], AddOffsetsToTxn(25): 0 to 1 [usable: 1], EndTxn(26): 0 to 1 [usable: 1], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 1 [usable: 1], DescribeAcls(29): 0 to 1 [usable: 1], CreateAcls(30): 0 to 1 [usable: 1], DeleteAcls(31): 0 to 1 [usable: 1], DescribeConfigs(32): 0 to 2 [usable: 2], AlterConfigs(33): 0 to 1 [usable: 1], AlterReplicaLogDirs(34): 0 to 1 [usable: 1], DescribeLogDirs(35): 0 to 1 [usable: 1], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 1], CreateDelegationToken(38): 0 to 1 [usable: 1], RenewDelegationToken(39): 0 to 1 [usable: 1], ExpireDelegationToken(40): 0 to 1 [usable: 1], DescribeDelegationToken(41): 0 to 1 [usable: 1], DeleteGroups(42): 0 to 1 [usable: 1], ElectLeaders(43): UNSUPPORTED, IncrementalAlterConfigs(44): UNSUPPORTED, AlterPartitionReassignments(45): UNSUPPORTED, ListPartitionReassignments(46): UNSUPPORTED, OffsetDelete(47): UNSUPPORTED, DescribeClientQuotas(48): UNSUPPORTED, AlterClientQuotas(49): UNSUPPORTED, DescribeUserScramCredentials(50): UNSUPPORTED, AlterUserScramCredentials(51): UNSUPPORTED, AlterPartition(56): UNSUPPORTED, UpdateFeatures(57): UNSUPPORTED, DescribeCluster(60): UNSUPPORTED, DescribeProducers(61): UNSUPPORTED, DescribeTransactions(65): UNSUPPORTED, ListTransactions(66): UNSUPPORTED, AllocateProducerIds(67): UNSUPPORTED).
2023-03-04 00:21:21 [kafka-admin-client-thread | adminclient-1] DEBUG o.a.k.clients.admin.KafkaAdminClient - [AdminClient clientId=adminclient-1] Sending CreateTopicsRequestData(topics=[CreatableTopic(name='twitter-topic', numPartitions=3, replicationFactor=3, assignments=[], configs=[])], timeoutMs=29989, validateOnly=false) to localhost:39092 (id: 3 rack: null). correlationId=5, timeoutMs=29989
2023-03-04 00:21:21 [kafka-admin-client-thread | adminclient-1] DEBUG o.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Sending CREATE_TOPICS request with header RequestHeader(apiKey=CREATE_TOPICS, apiVersion=3, clientId=adminclient-1, correlationId=5) and timeout 29989 to node 3: CreateTopicsRequestData(topics=[CreatableTopic(name='twitter-topic', numPartitions=3, replicationFactor=3, assignments=[], configs=[])], timeoutMs=29989, validateOnly=false)
2023-03-04 00:21:21 [kafka-admin-client-thread | adminclient-1] DEBUG o.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Received CREATE_TOPICS response from node 3 for request with header RequestHeader(apiKey=CREATE_TOPICS, apiVersion=3, clientId=adminclient-1, correlationId=5): CreateTopicsResponseData(throttleTimeMs=0, topics=[CreatableTopicResult(name='twitter-topic', topicId=AAAAAAAAAAAAAAAAAAAAAA, errorCode=36, errorMessage='Topic 'twitter-topic' already exists.', topicConfigErrorCode=0, numPartitions=-1, replicationFactor=-1, configs=[])])
2023-03-04 00:21:21 [kafka-admin-client-thread | adminclient-1] DEBUG o.a.k.clients.admin.KafkaAdminClient - [AdminClient clientId=adminclient-1] Sending MetadataRequestData(topics=null, allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to localhost:39092 (id: 3 rack: null). correlationId=6, timeoutMs=30000
2023-03-04 00:21:21 [kafka-admin-client-thread | adminclient-1] DEBUG o.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Sending METADATA request with header RequestHeader(apiKey=METADATA, apiVersion=6, clientId=adminclient-1, correlationId=6) and timeout 30000 to node 3: MetadataRequestData(topics=null, allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false)
2023-03-04 00:21:21 [kafka-admin-client-thread | adminclient-1] DEBUG o.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Received METADATA response from node 3 for request with header RequestHeader(apiKey=METADATA, apiVersion=6, clientId=adminclient-1, correlationId=6): MetadataResponseData(throttleTimeMs=0, brokers=[MetadataResponseBroker(nodeId=2, host='localhost', port=29092, rack=null), MetadataResponseBroker(nodeId=1, host='localhost', port=19092, rack=null), MetadataResponseBroker(nodeId=3, host='localhost', port=39092, rack=null)], clusterId='QGDYypu5SSGtA9Bc36Rjow', controllerId=3, topics=[MetadataResponseTopic(errorCode=0, name='__confluent.support.metrics', topicId=AAAAAAAAAAAAAAAAAAAAAA, isInternal=false, partitions=[MetadataResponsePartition(errorCode=0, partitionIndex=0, leaderId=2, leaderEpoch=-1, replicaNodes=[2, 3], isrNodes=[2, 3], offlineReplicas=[])], topicAuthorizedOperations=-2147483648), MetadataResponseTopic(errorCode=0, name='_schemas', topicId=AAAAAAAAAAAAAAAAAAAAAA, isInternal=false, partitions=[MetadataResponsePartition(errorCode=0, partitionIndex=0, leaderId=3, leaderEpoch=-1, replicaNodes=[3, 1, 2], isrNodes=[3, 2, 1], offlineReplicas=[])], topicAuthorizedOperations=-2147483648), MetadataResponseTopic(errorCode=0, name='twitter-topic', topicId=AAAAAAAAAAAAAAAAAAAAAA, isInternal=false, partitions=[MetadataResponsePartition(errorCode=0, partitionIndex=2, leaderId=3, leaderEpoch=-1, replicaNodes=[3, 2, 1], isrNodes=[3, 2, 1], offlineReplicas=[]), MetadataResponsePartition(errorCode=0, partitionIndex=1, leaderId=1, leaderEpoch=-1, replicaNodes=[1, 3, 2], isrNodes=[1, 3, 2], offlineReplicas=[]), MetadataResponsePartition(errorCode=0, partitionIndex=0, leaderId=2, leaderEpoch=-1, replicaNodes=[2, 1, 3], isrNodes=[2, 1, 3], offlineReplicas=[])], topicAuthorizedOperations=-2147483648)], clusterAuthorizedOperations=-2147483648)
2023-03-04 00:21:21 [main] DEBUG o.s.w.r.f.client.ExchangeFunctions - [6367a688] HTTP GET http://localhost:8081
2023-03-04 00:21:21 [main] DEBUG i.n.r.DefaultHostsFileEntriesResolver - -Dio.netty.hostsFileRefreshInterval: 0
2023-03-04 00:21:21 [main] DEBUG i.n.u.internal.NativeLibraryLoader - -Dio.netty.native.workdir: /var/folders/zx/4g777wp55pg8j62jnpqrd9dh0000gn/T (io.netty.tmpdir)
2023-03-04 00:21:21 [main] DEBUG i.n.u.internal.NativeLibraryLoader - -Dio.netty.native.deleteLibAfterLoading: true
2023-03-04 00:21:21 [main] DEBUG i.n.u.internal.NativeLibraryLoader - -Dio.netty.native.tryPatchShadedId: true
2023-03-04 00:21:21 [main] DEBUG i.n.u.internal.NativeLibraryLoader - -Dio.netty.native.detectNativeLibraryDuplicates: true
2023-03-04 00:21:22 [main] DEBUG i.n.u.internal.NativeLibraryLoader - Successfully loaded the library /var/folders/zx/4g777wp55pg8j62jnpqrd9dh0000gn/T/libnetty_resolver_dns_native_macos_x86_646919949470158440955.dylib
2023-03-04 00:21:22 [main] DEBUG i.n.r.d.DnsServerAddressStreamProviders - io.netty.resolver.dns.macos.MacOSDnsServerAddressStreamProvider: available
2023-03-04 00:21:22 [main] DEBUG r.n.r.PooledConnectionProvider - Creating a new [http] client pool [PoolFactory{evictionInterval=PT0S, leasingStrategy=fifo, maxConnections=500, maxIdleTime=-1, maxLifeTime=-1, metricsEnabled=false, pendingAcquireMaxCount=1000, pendingAcquireTimeout=45000}] for [localhost/<unresolved>:8081]
2023-03-04 00:21:22 [reactor-http-nio-3] DEBUG r.n.r.PooledConnectionProvider - [db39a7e0] Created a new pooled channel, now: 0 active connections, 0 inactive connections and 0 pending acquire requests.
2023-03-04 00:21:22 [reactor-http-nio-3] DEBUG io.netty.buffer.AbstractByteBuf - -Dio.netty.buffer.checkAccessible: true
2023-03-04 00:21:22 [reactor-http-nio-3] DEBUG io.netty.buffer.AbstractByteBuf - -Dio.netty.buffer.checkBounds: true
2023-03-04 00:21:22 [reactor-http-nio-3] DEBUG i.n.util.ResourceLeakDetectorFactory - Loaded default ResourceLeakDetector: io.netty.util.ResourceLeakDetector@71f738aa
2023-03-04 00:21:22 [reactor-http-nio-3] DEBUG r.netty.transport.TransportConfig - [db39a7e0] Initialized pipeline DefaultChannelPipeline{(reactor.left.httpCodec = io.netty.handler.codec.http.HttpClientCodec), (reactor.left.httpDecompressor = io.netty.handler.codec.http.HttpContentDecompressor), (reactor.right.reactiveBridge = reactor.netty.channel.ChannelOperationsHandler)}
2023-03-04 00:21:22 [reactor-http-nio-3] DEBUG r.netty.transport.TransportConnector - [db39a7e0] Connecting to [localhost/127.0.0.1:8081].
2023-03-04 00:21:22 [reactor-http-nio-3] DEBUG r.n.r.DefaultPooledConnectionProvider - [db39a7e0, L:/127.0.0.1:51757 - R:localhost/127.0.0.1:8081] Registering pool release on close event for channel
2023-03-04 00:21:22 [reactor-http-nio-3] DEBUG r.n.r.PooledConnectionProvider - [db39a7e0, L:/127.0.0.1:51757 - R:localhost/127.0.0.1:8081] Channel connected, now: 1 active connections, 0 inactive connections and 0 pending acquire requests.
2023-03-04 00:21:22 [reactor-http-nio-3] DEBUG r.n.r.DefaultPooledConnectionProvider - [db39a7e0, L:/127.0.0.1:51757 - R:localhost/127.0.0.1:8081] onStateChange(PooledConnection{channel=[id: 0xdb39a7e0, L:/127.0.0.1:51757 - R:localhost/127.0.0.1:8081]}, [connected])
2023-03-04 00:21:22 [reactor-http-nio-3] DEBUG r.n.r.DefaultPooledConnectionProvider - [db39a7e0-1, L:/127.0.0.1:51757 - R:localhost/127.0.0.1:8081] onStateChange(GET{uri=null, connection=PooledConnection{channel=[id: 0xdb39a7e0, L:/127.0.0.1:51757 - R:localhost/127.0.0.1:8081]}}, [configured])
2023-03-04 00:21:22 [reactor-http-nio-3] DEBUG r.n.http.client.HttpClientConnect - [db39a7e0-1, L:/127.0.0.1:51757 - R:localhost/127.0.0.1:8081] Handler is being applied: {uri=http://localhost:8081/, method=GET}
2023-03-04 00:21:22 [reactor-http-nio-3] DEBUG r.n.r.DefaultPooledConnectionProvider - [db39a7e0-1, L:/127.0.0.1:51757 - R:localhost/127.0.0.1:8081] onStateChange(GET{uri=/, connection=PooledConnection{channel=[id: 0xdb39a7e0, L:/127.0.0.1:51757 - R:localhost/127.0.0.1:8081]}}, [request_prepared])
2023-03-04 00:21:22 [reactor-http-nio-3] DEBUG io.netty.util.Recycler - -Dio.netty.recycler.maxCapacityPerThread: 4096
2023-03-04 00:21:22 [reactor-http-nio-3] DEBUG io.netty.util.Recycler - -Dio.netty.recycler.ratio: 8
2023-03-04 00:21:22 [reactor-http-nio-3] DEBUG io.netty.util.Recycler - -Dio.netty.recycler.chunkSize: 32
2023-03-04 00:21:22 [reactor-http-nio-3] DEBUG io.netty.util.Recycler - -Dio.netty.recycler.blocking: false
2023-03-04 00:21:22 [reactor-http-nio-3] DEBUG io.netty.util.Recycler - -Dio.netty.recycler.batchFastThreadLocalOnly: true
2023-03-04 00:21:22 [reactor-http-nio-3] DEBUG r.n.r.DefaultPooledConnectionProvider - [db39a7e0-1, L:/127.0.0.1:51757 - R:localhost/127.0.0.1:8081] onStateChange(GET{uri=/, connection=PooledConnection{channel=[id: 0xdb39a7e0, L:/127.0.0.1:51757 - R:localhost/127.0.0.1:8081]}}, [request_sent])
2023-03-04 00:21:22 [reactor-http-nio-3] DEBUG i.n.handler.codec.compression.Brotli - brotli4j not in the classpath; Brotli support will be unavailable.
2023-03-04 00:21:22 [reactor-http-nio-3] DEBUG r.n.http.client.HttpClientOperations - [db39a7e0-1, L:/127.0.0.1:51757 - R:localhost/127.0.0.1:8081] Received response (auto-read:false) : RESPONSE(decodeResult: success, version: HTTP/1.1)
HTTP/1.1 200 OK
Date: <filtered>
Content-Type: <filtered>
Content-Length: <filtered>
Server: <filtered>
2023-03-04 00:21:22 [reactor-http-nio-3] DEBUG r.n.r.DefaultPooledConnectionProvider - [db39a7e0-1, L:/127.0.0.1:51757 - R:localhost/127.0.0.1:8081] onStateChange(GET{uri=/, connection=PooledConnection{channel=[id: 0xdb39a7e0, L:/127.0.0.1:51757 - R:localhost/127.0.0.1:8081]}}, [response_received])
2023-03-04 00:21:22 [reactor-http-nio-3] DEBUG o.s.w.r.f.client.ExchangeFunctions - [6367a688] [db39a7e0-1, L:/127.0.0.1:51757 - R:localhost/127.0.0.1:8081] Response 200 OK
2023-03-04 00:21:22 [main] INFO  x.g.m.d.t.t.k.s.i.i.KafkaStreamInitializer - Topics with name twitter-topic is ready for operations.
2023-03-04 00:21:22 [main] INFO  x.g.m.d.t.t.k.s.r.i.MockKafkaStreamRunner - Start to mock twitter stream for keywords: [Java, Microservices, Spring, Kafka, Elasticsearch]
2023-03-04 00:21:22 [main] DEBUG o.s.b.a.ApplicationAvailabilityBean - Application availability state ReadinessState changed to ACCEPTING_TRAFFIC
2023-03-04 00:21:22 [reactor-http-nio-3] DEBUG r.n.http.client.HttpClientOperations - [db39a7e0-1, L:/127.0.0.1:51757 - R:localhost/127.0.0.1:8081] Received last HTTP packet
2023-03-04 00:21:22 [reactor-http-nio-3] DEBUG r.n.r.DefaultPooledConnectionProvider - [db39a7e0, L:/127.0.0.1:51757 - R:localhost/127.0.0.1:8081] onStateChange(GET{uri=/, connection=PooledConnection{channel=[id: 0xdb39a7e0, L:/127.0.0.1:51757 - R:localhost/127.0.0.1:8081]}}, [response_completed])
2023-03-04 00:21:22 [reactor-http-nio-3] DEBUG r.n.r.DefaultPooledConnectionProvider - [db39a7e0, L:/127.0.0.1:51757 - R:localhost/127.0.0.1:8081] onStateChange(GET{uri=/, connection=PooledConnection{channel=[id: 0xdb39a7e0, L:/127.0.0.1:51757 - R:localhost/127.0.0.1:8081]}}, [disconnecting])
2023-03-04 00:21:22 [reactor-http-nio-3] DEBUG r.n.r.DefaultPooledConnectionProvider - [db39a7e0, L:/127.0.0.1:51757 - R:localhost/127.0.0.1:8081] Releasing channel
2023-03-04 00:21:22 [reactor-http-nio-3] DEBUG r.n.r.PooledConnectionProvider - [db39a7e0, L:/127.0.0.1:51757 - R:localhost/127.0.0.1:8081] Channel cleaned, now: 0 active connections, 1 inactive connections and 0 pending acquire requests.
2023-03-04 00:21:22 [pool-3-thread-1] DEBUG twitter4j.conf.ConfigurationBase - serialVersionUID: 6175546394599249696
2023-03-04 00:21:22 [pool-3-thread-1] DEBUG twitter4j.conf.ConfigurationBase - debug: true
2023-03-04 00:21:22 [pool-3-thread-1] DEBUG twitter4j.conf.ConfigurationBase - user: null
2023-03-04 00:21:22 [pool-3-thread-1] DEBUG twitter4j.conf.ConfigurationBase - password: null
2023-03-04 00:21:22 [pool-3-thread-1] DEBUG twitter4j.conf.ConfigurationBase - httpConf: MyHttpClientConfiguration{httpProxyHost='null', httpProxyUser='null', httpProxyPassword='null', httpProxyPort=-1, proxyType=HTTP, httpConnectionTimeout=20000, httpReadTimeout=120000, prettyDebug=false, gzipEnabled=true}
2023-03-04 00:21:22 [pool-3-thread-1] DEBUG twitter4j.conf.ConfigurationBase - httpStreamingReadTimeout: 40000
2023-03-04 00:21:22 [pool-3-thread-1] DEBUG twitter4j.conf.ConfigurationBase - httpRetryCount: 0
2023-03-04 00:21:22 [pool-3-thread-1] DEBUG twitter4j.conf.ConfigurationBase - httpRetryIntervalSeconds: 5
2023-03-04 00:21:22 [pool-3-thread-1] DEBUG twitter4j.conf.ConfigurationBase - oAuthConsumerKey: *********************
2023-03-04 00:21:22 [pool-3-thread-1] DEBUG twitter4j.conf.ConfigurationBase - oAuthConsumerSecret: ******************************************
2023-03-04 00:21:22 [pool-3-thread-1] DEBUG twitter4j.conf.ConfigurationBase - oAuthAccessToken: **************************************************
2023-03-04 00:21:22 [pool-3-thread-1] DEBUG twitter4j.conf.ConfigurationBase - oAuthAccessTokenSecret: ******************************************
2023-03-04 00:21:22 [pool-3-thread-1] DEBUG twitter4j.conf.ConfigurationBase - oAuth2TokenType: null
2023-03-04 00:21:22 [pool-3-thread-1] DEBUG twitter4j.conf.ConfigurationBase - oAuth2AccessToken: null
2023-03-04 00:21:22 [pool-3-thread-1] DEBUG twitter4j.conf.ConfigurationBase - oAuth2Scope: null
2023-03-04 00:21:22 [pool-3-thread-1] DEBUG twitter4j.conf.ConfigurationBase - oAuthRequestTokenURL: https://api.twitter.com/oauth/request_token
2023-03-04 00:21:22 [pool-3-thread-1] DEBUG twitter4j.conf.ConfigurationBase - oAuthAuthorizationURL: https://api.twitter.com/oauth/authorize
2023-03-04 00:21:22 [pool-3-thread-1] DEBUG twitter4j.conf.ConfigurationBase - oAuthAccessTokenURL: https://api.twitter.com/oauth/access_token
2023-03-04 00:21:22 [pool-3-thread-1] DEBUG twitter4j.conf.ConfigurationBase - oAuthAuthenticationURL: https://api.twitter.com/oauth/authenticate
2023-03-04 00:21:22 [pool-3-thread-1] DEBUG twitter4j.conf.ConfigurationBase - oAuth2TokenURL: https://api.twitter.com/oauth2/token
2023-03-04 00:21:22 [pool-3-thread-1] DEBUG twitter4j.conf.ConfigurationBase - oAuth2InvalidateTokenURL: https://api.twitter.com/oauth2/invalidate_token
2023-03-04 00:21:22 [pool-3-thread-1] DEBUG twitter4j.conf.ConfigurationBase - restBaseURL: https://api.twitter.com/1.1/
2023-03-04 00:21:22 [pool-3-thread-1] DEBUG twitter4j.conf.ConfigurationBase - streamBaseURL: https://stream.twitter.com/1.1/
2023-03-04 00:21:22 [pool-3-thread-1] DEBUG twitter4j.conf.ConfigurationBase - userStreamBaseURL: https://userstream.twitter.com/1.1/
2023-03-04 00:21:22 [pool-3-thread-1] DEBUG twitter4j.conf.ConfigurationBase - siteStreamBaseURL: https://sitestream.twitter.com/1.1/
2023-03-04 00:21:22 [pool-3-thread-1] DEBUG twitter4j.conf.ConfigurationBase - uploadBaseURL: https://upload.twitter.com/1.1/
2023-03-04 00:21:22 [pool-3-thread-1] DEBUG twitter4j.conf.ConfigurationBase - dispatcherImpl: twitter4j.DispatcherImpl
2023-03-04 00:21:22 [pool-3-thread-1] DEBUG twitter4j.conf.ConfigurationBase - asyncNumThreads: 1
2023-03-04 00:21:22 [pool-3-thread-1] DEBUG twitter4j.conf.ConfigurationBase - loggerFactory: null
2023-03-04 00:21:22 [pool-3-thread-1] DEBUG twitter4j.conf.ConfigurationBase - contributingTo: -1
2023-03-04 00:21:22 [pool-3-thread-1] DEBUG twitter4j.conf.ConfigurationBase - includeMyRetweetEnabled: true
2023-03-04 00:21:22 [pool-3-thread-1] DEBUG twitter4j.conf.ConfigurationBase - includeEntitiesEnabled: true
2023-03-04 00:21:22 [pool-3-thread-1] DEBUG twitter4j.conf.ConfigurationBase - trimUserEnabled: false
2023-03-04 00:21:22 [pool-3-thread-1] DEBUG twitter4j.conf.ConfigurationBase - includeExtAltTextEnabled: true
2023-03-04 00:21:22 [pool-3-thread-1] DEBUG twitter4j.conf.ConfigurationBase - tweetModeExtended: true
2023-03-04 00:21:22 [pool-3-thread-1] DEBUG twitter4j.conf.ConfigurationBase - includeEmailEnabled: false
2023-03-04 00:21:22 [pool-3-thread-1] DEBUG twitter4j.conf.ConfigurationBase - jsonStoreEnabled: false
2023-03-04 00:21:22 [pool-3-thread-1] DEBUG twitter4j.conf.ConfigurationBase - mbeanEnabled: false
2023-03-04 00:21:22 [pool-3-thread-1] DEBUG twitter4j.conf.ConfigurationBase - userStreamRepliesAllEnabled: false
2023-03-04 00:21:22 [pool-3-thread-1] DEBUG twitter4j.conf.ConfigurationBase - userStreamWithFollowingsEnabled: true
2023-03-04 00:21:22 [pool-3-thread-1] DEBUG twitter4j.conf.ConfigurationBase - stallWarningsEnabled: true
2023-03-04 00:21:22 [pool-3-thread-1] DEBUG twitter4j.conf.ConfigurationBase - applicationOnlyAuthEnabled: false
2023-03-04 00:21:22 [pool-3-thread-1] DEBUG twitter4j.conf.ConfigurationBase - mediaProvider: TWITTER
2023-03-04 00:21:22 [pool-3-thread-1] DEBUG twitter4j.conf.ConfigurationBase - mediaProviderAPIKey: null
2023-03-04 00:21:22 [pool-3-thread-1] DEBUG twitter4j.conf.ConfigurationBase - mediaProviderParameters: null
2023-03-04 00:21:22 [pool-3-thread-1] DEBUG twitter4j.conf.ConfigurationBase - daemonEnabled: true
2023-03-04 00:21:22 [pool-3-thread-1] DEBUG twitter4j.conf.ConfigurationBase - streamThreadName: 
2023-03-04 00:21:22 [pool-3-thread-1] DEBUG twitter4j.conf.ConfigurationBase - instances: [ConfigurationBase{debug=true, user='null', password='null', httpConf=MyHttpClientConfiguration{httpProxyHost='null', httpProxyUser='null', httpProxyPassword='null', httpProxyPort=-1, proxyType=HTTP, httpConnectionTimeout=20000, httpReadTimeout=120000, prettyDebug=false, gzipEnabled=true}, httpStreamingReadTimeout=40000, httpRetryCount=0, httpRetryIntervalSeconds=5, oAuthConsumerKey='*********************', oAuthConsumerSecret='******************************************', oAuthAccessToken='**************************************************', oAuthAccessTokenSecret='******************************************', oAuth2TokenType='null', oAuth2AccessToken='null', oAuth2Scope='null', oAuthRequestTokenURL='https://api.twitter.com/oauth/request_token', oAuthAuthorizationURL='https://api.twitter.com/oauth/authorize', oAuthAccessTokenURL='https://api.twitter.com/oauth/access_token', oAuthAuthenticationURL='https://api.twitter.com/oauth/authenticate', oAuth2TokenURL='https://api.twitter.com/oauth2/token', oAuth2InvalidateTokenURL='https://api.twitter.com/oauth2/invalidate_token', restBaseURL='https://api.twitter.com/1.1/', streamBaseURL='https://stream.twitter.com/1.1/', userStreamBaseURL='https://userstream.twitter.com/1.1/', siteStreamBaseURL='https://sitestream.twitter.com/1.1/', uploadBaseURL='https://upload.twitter.com/1.1/', dispatcherImpl='twitter4j.DispatcherImpl', asyncNumThreads=1, loggerFactory='null', contributingTo=-1, includeMyRetweetEnabled=true, includeEntitiesEnabled=true, trimUserEnabled=false, includeExtAltTextEnabled=true, tweetModeExtended=true, includeEmailEnabled=false, jsonStoreEnabled=false, mbeanEnabled=false, userStreamRepliesAllEnabled=false, userStreamWithFollowingsEnabled=true, stallWarningsEnabled=true, applicationOnlyAuthEnabled=false, mediaProvider='TWITTER', mediaProviderAPIKey='null', mediaProviderParameters=null, daemonEnabled=true, streamThreadName=''}]
2023-03-04 00:21:22 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text vestibulum at sed non lacus arcu quis metus Spring at euismod sed metus at lacus tempor sending to kafka topic twitter-topic
2023-03-04 00:21:22 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 4022408386427756938, "id": 615957039765214863, "text": "vestibulum at sed non lacus arcu quis metus Spring at euismod sed metus at lacus tempor", "createdAt": 1677876682000}' to topic = 'twitter-topic'
2023-03-04 00:21:22 [pool-3-thread-1] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = -1
	batch.size = 1638400
	bootstrap.servers = [localhost:19092, localhost:29092, localhost:39092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = snappy
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.LongSerializer
	linger.ms = 5
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 60000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer

2023-03-04 00:21:22 [pool-3-thread-1] INFO  i.c.k.s.KafkaAvroSerializerConfig - KafkaAvroSerializerConfig values: 
	auto.register.schemas = true
	avro.reflection.allow.null = false
	avro.remove.java.properties = false
	avro.use.logical.type.converters = false
	basic.auth.credentials.source = URL
	basic.auth.user.info = [hidden]
	bearer.auth.cache.expiry.buffer.seconds = 300
	bearer.auth.client.id = null
	bearer.auth.client.secret = null
	bearer.auth.credentials.source = STATIC_TOKEN
	bearer.auth.identity.pool.id = null
	bearer.auth.issuer.endpoint.url = null
	bearer.auth.logical.cluster = null
	bearer.auth.scope = null
	bearer.auth.scope.claim.name = scope
	bearer.auth.sub.claim.name = sub
	bearer.auth.token = [hidden]
	context.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy
	id.compatibility.strict = true
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	latest.compatibility.strict = true
	max.schemas.per.subject = 1000
	normalize.schemas = false
	proxy.host = 
	proxy.port = -1
	schema.format = null
	schema.reflection = false
	schema.registry.basic.auth.user.info = [hidden]
	schema.registry.ssl.cipher.suites = null
	schema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	schema.registry.ssl.endpoint.identification.algorithm = https
	schema.registry.ssl.engine.factory.class = null
	schema.registry.ssl.key.password = null
	schema.registry.ssl.keymanager.algorithm = SunX509
	schema.registry.ssl.keystore.certificate.chain = null
	schema.registry.ssl.keystore.key = null
	schema.registry.ssl.keystore.location = null
	schema.registry.ssl.keystore.password = null
	schema.registry.ssl.keystore.type = JKS
	schema.registry.ssl.protocol = TLSv1.3
	schema.registry.ssl.provider = null
	schema.registry.ssl.secure.random.implementation = null
	schema.registry.ssl.trustmanager.algorithm = PKIX
	schema.registry.ssl.truststore.certificates = null
	schema.registry.ssl.truststore.location = null
	schema.registry.ssl.truststore.password = null
	schema.registry.ssl.truststore.type = JKS
	schema.registry.url = [http://localhost:8081]
	use.latest.version = false
	use.schema.id = -1
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy

2023-03-04 00:21:22 [pool-3-thread-1] DEBUG i.c.k.s.client.security.SslFactory - Created SSL context with keystore null, truststore null, provider SunJSSE.
2023-03-04 00:21:22 [pool-3-thread-1] INFO  o.a.k.clients.producer.KafkaProducer - [Producer clientId=producer-1] Instantiated an idempotent producer.
2023-03-04 00:21:22 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Starting Kafka producer I/O thread.
2023-03-04 00:21:22 [pool-3-thread-1] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.3.2
2023-03-04 00:21:22 [pool-3-thread-1] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: b66af662e61082cb
2023-03-04 00:21:22 [pool-3-thread-1] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1677876682600
2023-03-04 00:21:22 [pool-3-thread-1] DEBUG o.a.k.clients.producer.KafkaProducer - [Producer clientId=producer-1] Kafka producer started
2023-03-04 00:21:22 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] Transition from state UNINITIALIZED to INITIALIZING
2023-03-04 00:21:22 [pool-3-thread-1] DEBUG o.s.k.c.DefaultKafkaProducerFactory - Created new Producer: CloseSafeProducer [delegate=org.apache.kafka.clients.producer.KafkaProducer@16fbe0b]
2023-03-04 00:21:22 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] Enqueuing transactional request InitProducerIdRequestData(transactionalId=null, transactionTimeoutMs=2147483647, producerId=-1, producerEpoch=-1)
2023-03-04 00:21:22 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Initialize connection to node localhost:19092 (id: -1 rack: null) for sending metadata request
2023-03-04 00:21:22 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.ClientUtils - Resolved host localhost as 127.0.0.1
2023-03-04 00:21:22 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Initiating connection to node localhost:19092 (id: -1 rack: null) using address localhost/127.0.0.1
2023-03-04 00:21:22 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.ClientUtils - Resolved host localhost as 127.0.0.1
2023-03-04 00:21:22 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Initiating connection to node localhost:39092 (id: -3 rack: null) using address localhost/127.0.0.1
2023-03-04 00:21:22 [kafka-producer-network-thread | producer-1] DEBUG o.a.kafka.common.network.Selector - [Producer clientId=producer-1] Created socket with SO_RCVBUF = 326640, SO_SNDBUF = 146988, SO_TIMEOUT = 0 to node -1
2023-03-04 00:21:22 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Completed connection to node -1. Fetching API versions.
2023-03-04 00:21:22 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Initiating API versions fetch from node -1.
2023-03-04 00:21:22 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending API_VERSIONS request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=producer-1, correlationId=0) and timeout 60000 to node -1: ApiVersionsRequestData(clientSoftwareName='apache-kafka-java', clientSoftwareVersion='3.3.2')
2023-03-04 00:21:22 [kafka-producer-network-thread | producer-1] DEBUG o.a.kafka.common.network.Selector - [Producer clientId=producer-1] Created socket with SO_RCVBUF = 326640, SO_SNDBUF = 146988, SO_TIMEOUT = 0 to node -3
2023-03-04 00:21:22 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Completed connection to node -3. Fetching API versions.
2023-03-04 00:21:22 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Initiating API versions fetch from node -3.
2023-03-04 00:21:22 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending API_VERSIONS request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=producer-1, correlationId=1) and timeout 60000 to node -3: ApiVersionsRequestData(clientSoftwareName='apache-kafka-java', clientSoftwareVersion='3.3.2')
2023-03-04 00:21:22 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received API_VERSIONS response from node -1 for request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=producer-1, correlationId=0): ApiVersionsResponseData(errorCode=35, apiKeys=[], throttleTimeMs=0, supportedFeatures=[], finalizedFeaturesEpoch=-1, finalizedFeatures=[])
2023-03-04 00:21:22 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Initiating API versions fetch from node -1.
2023-03-04 00:21:22 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending API_VERSIONS request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=0, clientId=producer-1, correlationId=2) and timeout 60000 to node -1: ApiVersionsRequestData(clientSoftwareName='apache-kafka-java', clientSoftwareVersion='3.3.2')
2023-03-04 00:21:22 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received API_VERSIONS response from node -3 for request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=producer-1, correlationId=1): ApiVersionsResponseData(errorCode=35, apiKeys=[], throttleTimeMs=0, supportedFeatures=[], finalizedFeaturesEpoch=-1, finalizedFeatures=[])
2023-03-04 00:21:22 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Initiating API versions fetch from node -3.
2023-03-04 00:21:22 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending API_VERSIONS request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=0, clientId=producer-1, correlationId=3) and timeout 60000 to node -3: ApiVersionsRequestData(clientSoftwareName='apache-kafka-java', clientSoftwareVersion='3.3.2')
2023-03-04 00:21:22 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received API_VERSIONS response from node -1 for request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=0, clientId=producer-1, correlationId=2): ApiVersionsResponseData(errorCode=0, apiKeys=[ApiVersion(apiKey=0, minVersion=0, maxVersion=6), ApiVersion(apiKey=1, minVersion=0, maxVersion=8), ApiVersion(apiKey=2, minVersion=0, maxVersion=3), ApiVersion(apiKey=3, minVersion=0, maxVersion=6), ApiVersion(apiKey=4, minVersion=0, maxVersion=1), ApiVersion(apiKey=5, minVersion=0, maxVersion=0), ApiVersion(apiKey=6, minVersion=0, maxVersion=4), ApiVersion(apiKey=7, minVersion=0, maxVersion=1), ApiVersion(apiKey=8, minVersion=0, maxVersion=4), ApiVersion(apiKey=9, minVersion=0, maxVersion=4), ApiVersion(apiKey=10, minVersion=0, maxVersion=2), ApiVersion(apiKey=11, minVersion=0, maxVersion=3), ApiVersion(apiKey=12, minVersion=0, maxVersion=2), ApiVersion(apiKey=13, minVersion=0, maxVersion=2), ApiVersion(apiKey=14, minVersion=0, maxVersion=2), ApiVersion(apiKey=15, minVersion=0, maxVersion=2), ApiVersion(apiKey=16, minVersion=0, maxVersion=2), ApiVersion(apiKey=17, minVersion=0, maxVersion=1), ApiVersion(apiKey=18, minVersion=0, maxVersion=2), ApiVersion(apiKey=19, minVersion=0, maxVersion=3), ApiVersion(apiKey=20, minVersion=0, maxVersion=2), ApiVersion(apiKey=21, minVersion=0, maxVersion=1), ApiVersion(apiKey=22, minVersion=0, maxVersion=1), ApiVersion(apiKey=23, minVersion=0, maxVersion=1), ApiVersion(apiKey=24, minVersion=0, maxVersion=1), ApiVersion(apiKey=25, minVersion=0, maxVersion=1), ApiVersion(apiKey=26, minVersion=0, maxVersion=1), ApiVersion(apiKey=27, minVersion=0, maxVersion=0), ApiVersion(apiKey=28, minVersion=0, maxVersion=1), ApiVersion(apiKey=29, minVersion=0, maxVersion=1), ApiVersion(apiKey=30, minVersion=0, maxVersion=1), ApiVersion(apiKey=31, minVersion=0, maxVersion=1), ApiVersion(apiKey=32, minVersion=0, maxVersion=2), ApiVersion(apiKey=33, minVersion=0, maxVersion=1), ApiVersion(apiKey=34, minVersion=0, maxVersion=1), ApiVersion(apiKey=35, minVersion=0, maxVersion=1), ApiVersion(apiKey=36, minVersion=0, maxVersion=0), ApiVersion(apiKey=37, minVersion=0, maxVersion=1), ApiVersion(apiKey=38, minVersion=0, maxVersion=1), ApiVersion(apiKey=39, minVersion=0, maxVersion=1), ApiVersion(apiKey=40, minVersion=0, maxVersion=1), ApiVersion(apiKey=41, minVersion=0, maxVersion=1), ApiVersion(apiKey=42, minVersion=0, maxVersion=1)], throttleTimeMs=0, supportedFeatures=[], finalizedFeaturesEpoch=-1, finalizedFeatures=[])
2023-03-04 00:21:22 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Node -1 has finalized features epoch: -1, finalized features: [], supported features: [], API versions: (Produce(0): 0 to 6 [usable: 6], Fetch(1): 0 to 8 [usable: 8], ListOffsets(2): 0 to 3 [usable: 3], Metadata(3): 0 to 6 [usable: 6], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 4 [usable: 4], OffsetFetch(9): 0 to 4 [usable: 4], FindCoordinator(10): 0 to 2 [usable: 2], JoinGroup(11): 0 to 3 [usable: 3], Heartbeat(12): 0 to 2 [usable: 2], LeaveGroup(13): 0 to 2 [usable: 2], SyncGroup(14): 0 to 2 [usable: 2], DescribeGroups(15): 0 to 2 [usable: 2], ListGroups(16): 0 to 2 [usable: 2], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 2], CreateTopics(19): 0 to 3 [usable: 3], DeleteTopics(20): 0 to 2 [usable: 2], DeleteRecords(21): 0 to 1 [usable: 1], InitProducerId(22): 0 to 1 [usable: 1], OffsetForLeaderEpoch(23): 0 to 1 [usable: 1], AddPartitionsToTxn(24): 0 to 1 [usable: 1], AddOffsetsToTxn(25): 0 to 1 [usable: 1], EndTxn(26): 0 to 1 [usable: 1], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 1 [usable: 1], DescribeAcls(29): 0 to 1 [usable: 1], CreateAcls(30): 0 to 1 [usable: 1], DeleteAcls(31): 0 to 1 [usable: 1], DescribeConfigs(32): 0 to 2 [usable: 2], AlterConfigs(33): 0 to 1 [usable: 1], AlterReplicaLogDirs(34): 0 to 1 [usable: 1], DescribeLogDirs(35): 0 to 1 [usable: 1], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 1], CreateDelegationToken(38): 0 to 1 [usable: 1], RenewDelegationToken(39): 0 to 1 [usable: 1], ExpireDelegationToken(40): 0 to 1 [usable: 1], DescribeDelegationToken(41): 0 to 1 [usable: 1], DeleteGroups(42): 0 to 1 [usable: 1], ElectLeaders(43): UNSUPPORTED, IncrementalAlterConfigs(44): UNSUPPORTED, AlterPartitionReassignments(45): UNSUPPORTED, ListPartitionReassignments(46): UNSUPPORTED, OffsetDelete(47): UNSUPPORTED, DescribeClientQuotas(48): UNSUPPORTED, AlterClientQuotas(49): UNSUPPORTED, DescribeUserScramCredentials(50): UNSUPPORTED, AlterUserScramCredentials(51): UNSUPPORTED, AlterPartition(56): UNSUPPORTED, UpdateFeatures(57): UNSUPPORTED, DescribeCluster(60): UNSUPPORTED, DescribeProducers(61): UNSUPPORTED, DescribeTransactions(65): UNSUPPORTED, ListTransactions(66): UNSUPPORTED, AllocateProducerIds(67): UNSUPPORTED).
2023-03-04 00:21:22 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending metadata request MetadataRequestData(topics=[MetadataRequestTopic(topicId=AAAAAAAAAAAAAAAAAAAAAA, name='twitter-topic')], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to node localhost:19092 (id: -1 rack: null)
2023-03-04 00:21:22 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending METADATA request with header RequestHeader(apiKey=METADATA, apiVersion=6, clientId=producer-1, correlationId=4) and timeout 60000 to node -1: MetadataRequestData(topics=[MetadataRequestTopic(topicId=AAAAAAAAAAAAAAAAAAAAAA, name='twitter-topic')], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false)
2023-03-04 00:21:22 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received API_VERSIONS response from node -3 for request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=0, clientId=producer-1, correlationId=3): ApiVersionsResponseData(errorCode=0, apiKeys=[ApiVersion(apiKey=0, minVersion=0, maxVersion=6), ApiVersion(apiKey=1, minVersion=0, maxVersion=8), ApiVersion(apiKey=2, minVersion=0, maxVersion=3), ApiVersion(apiKey=3, minVersion=0, maxVersion=6), ApiVersion(apiKey=4, minVersion=0, maxVersion=1), ApiVersion(apiKey=5, minVersion=0, maxVersion=0), ApiVersion(apiKey=6, minVersion=0, maxVersion=4), ApiVersion(apiKey=7, minVersion=0, maxVersion=1), ApiVersion(apiKey=8, minVersion=0, maxVersion=4), ApiVersion(apiKey=9, minVersion=0, maxVersion=4), ApiVersion(apiKey=10, minVersion=0, maxVersion=2), ApiVersion(apiKey=11, minVersion=0, maxVersion=3), ApiVersion(apiKey=12, minVersion=0, maxVersion=2), ApiVersion(apiKey=13, minVersion=0, maxVersion=2), ApiVersion(apiKey=14, minVersion=0, maxVersion=2), ApiVersion(apiKey=15, minVersion=0, maxVersion=2), ApiVersion(apiKey=16, minVersion=0, maxVersion=2), ApiVersion(apiKey=17, minVersion=0, maxVersion=1), ApiVersion(apiKey=18, minVersion=0, maxVersion=2), ApiVersion(apiKey=19, minVersion=0, maxVersion=3), ApiVersion(apiKey=20, minVersion=0, maxVersion=2), ApiVersion(apiKey=21, minVersion=0, maxVersion=1), ApiVersion(apiKey=22, minVersion=0, maxVersion=1), ApiVersion(apiKey=23, minVersion=0, maxVersion=1), ApiVersion(apiKey=24, minVersion=0, maxVersion=1), ApiVersion(apiKey=25, minVersion=0, maxVersion=1), ApiVersion(apiKey=26, minVersion=0, maxVersion=1), ApiVersion(apiKey=27, minVersion=0, maxVersion=0), ApiVersion(apiKey=28, minVersion=0, maxVersion=1), ApiVersion(apiKey=29, minVersion=0, maxVersion=1), ApiVersion(apiKey=30, minVersion=0, maxVersion=1), ApiVersion(apiKey=31, minVersion=0, maxVersion=1), ApiVersion(apiKey=32, minVersion=0, maxVersion=2), ApiVersion(apiKey=33, minVersion=0, maxVersion=1), ApiVersion(apiKey=34, minVersion=0, maxVersion=1), ApiVersion(apiKey=35, minVersion=0, maxVersion=1), ApiVersion(apiKey=36, minVersion=0, maxVersion=0), ApiVersion(apiKey=37, minVersion=0, maxVersion=1), ApiVersion(apiKey=38, minVersion=0, maxVersion=1), ApiVersion(apiKey=39, minVersion=0, maxVersion=1), ApiVersion(apiKey=40, minVersion=0, maxVersion=1), ApiVersion(apiKey=41, minVersion=0, maxVersion=1), ApiVersion(apiKey=42, minVersion=0, maxVersion=1)], throttleTimeMs=0, supportedFeatures=[], finalizedFeaturesEpoch=-1, finalizedFeatures=[])
2023-03-04 00:21:22 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Node -3 has finalized features epoch: -1, finalized features: [], supported features: [], API versions: (Produce(0): 0 to 6 [usable: 6], Fetch(1): 0 to 8 [usable: 8], ListOffsets(2): 0 to 3 [usable: 3], Metadata(3): 0 to 6 [usable: 6], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 4 [usable: 4], OffsetFetch(9): 0 to 4 [usable: 4], FindCoordinator(10): 0 to 2 [usable: 2], JoinGroup(11): 0 to 3 [usable: 3], Heartbeat(12): 0 to 2 [usable: 2], LeaveGroup(13): 0 to 2 [usable: 2], SyncGroup(14): 0 to 2 [usable: 2], DescribeGroups(15): 0 to 2 [usable: 2], ListGroups(16): 0 to 2 [usable: 2], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 2], CreateTopics(19): 0 to 3 [usable: 3], DeleteTopics(20): 0 to 2 [usable: 2], DeleteRecords(21): 0 to 1 [usable: 1], InitProducerId(22): 0 to 1 [usable: 1], OffsetForLeaderEpoch(23): 0 to 1 [usable: 1], AddPartitionsToTxn(24): 0 to 1 [usable: 1], AddOffsetsToTxn(25): 0 to 1 [usable: 1], EndTxn(26): 0 to 1 [usable: 1], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 1 [usable: 1], DescribeAcls(29): 0 to 1 [usable: 1], CreateAcls(30): 0 to 1 [usable: 1], DeleteAcls(31): 0 to 1 [usable: 1], DescribeConfigs(32): 0 to 2 [usable: 2], AlterConfigs(33): 0 to 1 [usable: 1], AlterReplicaLogDirs(34): 0 to 1 [usable: 1], DescribeLogDirs(35): 0 to 1 [usable: 1], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 1], CreateDelegationToken(38): 0 to 1 [usable: 1], RenewDelegationToken(39): 0 to 1 [usable: 1], ExpireDelegationToken(40): 0 to 1 [usable: 1], DescribeDelegationToken(41): 0 to 1 [usable: 1], DeleteGroups(42): 0 to 1 [usable: 1], ElectLeaders(43): UNSUPPORTED, IncrementalAlterConfigs(44): UNSUPPORTED, AlterPartitionReassignments(45): UNSUPPORTED, ListPartitionReassignments(46): UNSUPPORTED, OffsetDelete(47): UNSUPPORTED, DescribeClientQuotas(48): UNSUPPORTED, AlterClientQuotas(49): UNSUPPORTED, DescribeUserScramCredentials(50): UNSUPPORTED, AlterUserScramCredentials(51): UNSUPPORTED, AlterPartition(56): UNSUPPORTED, UpdateFeatures(57): UNSUPPORTED, DescribeCluster(60): UNSUPPORTED, DescribeProducers(61): UNSUPPORTED, DescribeTransactions(65): UNSUPPORTED, ListTransactions(66): UNSUPPORTED, AllocateProducerIds(67): UNSUPPORTED).
2023-03-04 00:21:22 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Sending transactional request InitProducerIdRequestData(transactionalId=null, transactionTimeoutMs=2147483647, producerId=-1, producerEpoch=-1) to node localhost:39092 (id: -3 rack: null) with correlation ID 5
2023-03-04 00:21:22 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending INIT_PRODUCER_ID request with header RequestHeader(apiKey=INIT_PRODUCER_ID, apiVersion=1, clientId=producer-1, correlationId=5) and timeout 60000 to node -3: InitProducerIdRequestData(transactionalId=null, transactionTimeoutMs=2147483647, producerId=-1, producerEpoch=-1)
2023-03-04 00:21:22 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received METADATA response from node -1 for request with header RequestHeader(apiKey=METADATA, apiVersion=6, clientId=producer-1, correlationId=4): MetadataResponseData(throttleTimeMs=0, brokers=[MetadataResponseBroker(nodeId=2, host='localhost', port=29092, rack=null), MetadataResponseBroker(nodeId=1, host='localhost', port=19092, rack=null), MetadataResponseBroker(nodeId=3, host='localhost', port=39092, rack=null)], clusterId='QGDYypu5SSGtA9Bc36Rjow', controllerId=3, topics=[MetadataResponseTopic(errorCode=0, name='twitter-topic', topicId=AAAAAAAAAAAAAAAAAAAAAA, isInternal=false, partitions=[MetadataResponsePartition(errorCode=0, partitionIndex=2, leaderId=3, leaderEpoch=-1, replicaNodes=[3, 2, 1], isrNodes=[3, 2, 1], offlineReplicas=[]), MetadataResponsePartition(errorCode=0, partitionIndex=1, leaderId=1, leaderEpoch=-1, replicaNodes=[1, 3, 2], isrNodes=[1, 3, 2], offlineReplicas=[]), MetadataResponsePartition(errorCode=0, partitionIndex=0, leaderId=2, leaderEpoch=-1, replicaNodes=[2, 1, 3], isrNodes=[2, 1, 3], offlineReplicas=[])], topicAuthorizedOperations=-2147483648)], clusterAuthorizedOperations=-2147483648)
2023-03-04 00:21:22 [kafka-producer-network-thread | producer-1] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Cluster ID: QGDYypu5SSGtA9Bc36Rjow
2023-03-04 00:21:22 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Updated cluster metadata updateVersion 2 to MetadataCache{clusterId='QGDYypu5SSGtA9Bc36Rjow', nodes={1=localhost:19092 (id: 1 rack: null), 2=localhost:29092 (id: 2 rack: null), 3=localhost:39092 (id: 3 rack: null)}, partitions=[PartitionMetadata(error=NONE, partition=twitter-topic-0, leader=Optional[2], leaderEpoch=Optional.empty, replicas=2,1,3, isr=2,1,3, offlineReplicas=), PartitionMetadata(error=NONE, partition=twitter-topic-1, leader=Optional[1], leaderEpoch=Optional.empty, replicas=1,3,2, isr=1,3,2, offlineReplicas=), PartitionMetadata(error=NONE, partition=twitter-topic-2, leader=Optional[3], leaderEpoch=Optional.empty, replicas=3,2,1, isr=3,2,1, offlineReplicas=)], controller=localhost:39092 (id: 3 rack: null)}
2023-03-04 00:21:22 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received INIT_PRODUCER_ID response from node -3 for request with header RequestHeader(apiKey=INIT_PRODUCER_ID, apiVersion=1, clientId=producer-1, correlationId=5): InitProducerIdResponseData(throttleTimeMs=0, errorCode=0, producerId=3000, producerEpoch=0)
2023-03-04 00:21:22 [kafka-producer-network-thread | producer-1] INFO  o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId set to 3000 with epoch 0
2023-03-04 00:21:22 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] Transition from state INITIALIZING to READY
2023-03-04 00:21:22 [pool-3-thread-1] DEBUG i.c.k.s.client.rest.RestService - Sending POST with input {"schema":"{\"type\":\"record\",\"name\":\"TwitterAvroModel\",\"namespace\":\"xyz.gouril.microservices.demo.kafka.avro.model\",\"fields\":[{\"name\":\"userId\",\"type\":\"long\"},{\"name\":\"id\",\"type\":\"long\"},{\"name\":\"text\",\"type\":[\"null\",{\"type\":\"string\",\"avro.java.string\":\"String\"}]},{\"name\":\"createdAt\",\"type\":[\"null\",\"long\"],\"logicalType\":[\"null\",\"date\"]}]}"} to http://localhost:8081/subjects/twitter-topic-value/versions?normalize=false
2023-03-04 00:21:24 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:21:24 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.ClientUtils - Resolved host localhost as 127.0.0.1
2023-03-04 00:21:24 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Initiating connection to node localhost:39092 (id: 3 rack: null) using address localhost/127.0.0.1
2023-03-04 00:21:24 [kafka-producer-network-thread | producer-1] DEBUG o.a.kafka.common.network.Selector - [Producer clientId=producer-1] Created socket with SO_RCVBUF = 326640, SO_SNDBUF = 146988, SO_TIMEOUT = 0 to node 3
2023-03-04 00:21:24 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Completed connection to node 3. Fetching API versions.
2023-03-04 00:21:24 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Initiating API versions fetch from node 3.
2023-03-04 00:21:24 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending API_VERSIONS request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=producer-1, correlationId=6) and timeout 60000 to node 3: ApiVersionsRequestData(clientSoftwareName='apache-kafka-java', clientSoftwareVersion='3.3.2')
2023-03-04 00:21:24 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received API_VERSIONS response from node 3 for request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=producer-1, correlationId=6): ApiVersionsResponseData(errorCode=35, apiKeys=[], throttleTimeMs=0, supportedFeatures=[], finalizedFeaturesEpoch=-1, finalizedFeatures=[])
2023-03-04 00:21:24 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Initiating API versions fetch from node 3.
2023-03-04 00:21:24 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending API_VERSIONS request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=0, clientId=producer-1, correlationId=7) and timeout 60000 to node 3: ApiVersionsRequestData(clientSoftwareName='apache-kafka-java', clientSoftwareVersion='3.3.2')
2023-03-04 00:21:24 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received API_VERSIONS response from node 3 for request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=0, clientId=producer-1, correlationId=7): ApiVersionsResponseData(errorCode=0, apiKeys=[ApiVersion(apiKey=0, minVersion=0, maxVersion=6), ApiVersion(apiKey=1, minVersion=0, maxVersion=8), ApiVersion(apiKey=2, minVersion=0, maxVersion=3), ApiVersion(apiKey=3, minVersion=0, maxVersion=6), ApiVersion(apiKey=4, minVersion=0, maxVersion=1), ApiVersion(apiKey=5, minVersion=0, maxVersion=0), ApiVersion(apiKey=6, minVersion=0, maxVersion=4), ApiVersion(apiKey=7, minVersion=0, maxVersion=1), ApiVersion(apiKey=8, minVersion=0, maxVersion=4), ApiVersion(apiKey=9, minVersion=0, maxVersion=4), ApiVersion(apiKey=10, minVersion=0, maxVersion=2), ApiVersion(apiKey=11, minVersion=0, maxVersion=3), ApiVersion(apiKey=12, minVersion=0, maxVersion=2), ApiVersion(apiKey=13, minVersion=0, maxVersion=2), ApiVersion(apiKey=14, minVersion=0, maxVersion=2), ApiVersion(apiKey=15, minVersion=0, maxVersion=2), ApiVersion(apiKey=16, minVersion=0, maxVersion=2), ApiVersion(apiKey=17, minVersion=0, maxVersion=1), ApiVersion(apiKey=18, minVersion=0, maxVersion=2), ApiVersion(apiKey=19, minVersion=0, maxVersion=3), ApiVersion(apiKey=20, minVersion=0, maxVersion=2), ApiVersion(apiKey=21, minVersion=0, maxVersion=1), ApiVersion(apiKey=22, minVersion=0, maxVersion=1), ApiVersion(apiKey=23, minVersion=0, maxVersion=1), ApiVersion(apiKey=24, minVersion=0, maxVersion=1), ApiVersion(apiKey=25, minVersion=0, maxVersion=1), ApiVersion(apiKey=26, minVersion=0, maxVersion=1), ApiVersion(apiKey=27, minVersion=0, maxVersion=0), ApiVersion(apiKey=28, minVersion=0, maxVersion=1), ApiVersion(apiKey=29, minVersion=0, maxVersion=1), ApiVersion(apiKey=30, minVersion=0, maxVersion=1), ApiVersion(apiKey=31, minVersion=0, maxVersion=1), ApiVersion(apiKey=32, minVersion=0, maxVersion=2), ApiVersion(apiKey=33, minVersion=0, maxVersion=1), ApiVersion(apiKey=34, minVersion=0, maxVersion=1), ApiVersion(apiKey=35, minVersion=0, maxVersion=1), ApiVersion(apiKey=36, minVersion=0, maxVersion=0), ApiVersion(apiKey=37, minVersion=0, maxVersion=1), ApiVersion(apiKey=38, minVersion=0, maxVersion=1), ApiVersion(apiKey=39, minVersion=0, maxVersion=1), ApiVersion(apiKey=40, minVersion=0, maxVersion=1), ApiVersion(apiKey=41, minVersion=0, maxVersion=1), ApiVersion(apiKey=42, minVersion=0, maxVersion=1)], throttleTimeMs=0, supportedFeatures=[], finalizedFeaturesEpoch=-1, finalizedFeatures=[])
2023-03-04 00:21:24 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Node 3 has finalized features epoch: -1, finalized features: [], supported features: [], API versions: (Produce(0): 0 to 6 [usable: 6], Fetch(1): 0 to 8 [usable: 8], ListOffsets(2): 0 to 3 [usable: 3], Metadata(3): 0 to 6 [usable: 6], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 4 [usable: 4], OffsetFetch(9): 0 to 4 [usable: 4], FindCoordinator(10): 0 to 2 [usable: 2], JoinGroup(11): 0 to 3 [usable: 3], Heartbeat(12): 0 to 2 [usable: 2], LeaveGroup(13): 0 to 2 [usable: 2], SyncGroup(14): 0 to 2 [usable: 2], DescribeGroups(15): 0 to 2 [usable: 2], ListGroups(16): 0 to 2 [usable: 2], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 2], CreateTopics(19): 0 to 3 [usable: 3], DeleteTopics(20): 0 to 2 [usable: 2], DeleteRecords(21): 0 to 1 [usable: 1], InitProducerId(22): 0 to 1 [usable: 1], OffsetForLeaderEpoch(23): 0 to 1 [usable: 1], AddPartitionsToTxn(24): 0 to 1 [usable: 1], AddOffsetsToTxn(25): 0 to 1 [usable: 1], EndTxn(26): 0 to 1 [usable: 1], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 1 [usable: 1], DescribeAcls(29): 0 to 1 [usable: 1], CreateAcls(30): 0 to 1 [usable: 1], DeleteAcls(31): 0 to 1 [usable: 1], DescribeConfigs(32): 0 to 2 [usable: 2], AlterConfigs(33): 0 to 1 [usable: 1], AlterReplicaLogDirs(34): 0 to 1 [usable: 1], DescribeLogDirs(35): 0 to 1 [usable: 1], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 1], CreateDelegationToken(38): 0 to 1 [usable: 1], RenewDelegationToken(39): 0 to 1 [usable: 1], ExpireDelegationToken(40): 0 to 1 [usable: 1], DescribeDelegationToken(41): 0 to 1 [usable: 1], DeleteGroups(42): 0 to 1 [usable: 1], ElectLeaders(43): UNSUPPORTED, IncrementalAlterConfigs(44): UNSUPPORTED, AlterPartitionReassignments(45): UNSUPPORTED, ListPartitionReassignments(46): UNSUPPORTED, OffsetDelete(47): UNSUPPORTED, DescribeClientQuotas(48): UNSUPPORTED, AlterClientQuotas(49): UNSUPPORTED, DescribeUserScramCredentials(50): UNSUPPORTED, AlterUserScramCredentials(51): UNSUPPORTED, AlterPartition(56): UNSUPPORTED, UpdateFeatures(57): UNSUPPORTED, DescribeCluster(60): UNSUPPORTED, DescribeProducers(61): UNSUPPORTED, DescribeTransactions(65): UNSUPPORTED, ListTransactions(66): UNSUPPORTED, AllocateProducerIds(67): UNSUPPORTED).
2023-03-04 00:21:24 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId of partition twitter-topic-2 set to 3000 with epoch 0. Reinitialize sequence at beginning.
2023-03-04 00:21:24 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 0 being sent to partition twitter-topic-2
2023-03-04 00:21:24 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=8) and timeout 60000 to node 3: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-2=220]}
2023-03-04 00:21:24 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 3 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=8): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=2, errorCode=0, baseOffset=0, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:21:24 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-2 to 0
2023-03-04 00:21:24 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:21:34 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text odio euismod dictum ante Elasticsearch lacus at sending to kafka topic twitter-topic
2023-03-04 00:21:34 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 1346288600977209767, "id": 1654553047165660954, "text": "odio euismod dictum ante Elasticsearch lacus at", "createdAt": 1677876694000}' to topic = 'twitter-topic'
2023-03-04 00:21:34 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:21:34 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 1 being sent to partition twitter-topic-2
2023-03-04 00:21:34 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=9) and timeout 60000 to node 3: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-2=179]}
2023-03-04 00:21:34 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 3 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=9): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=2, errorCode=0, baseOffset=1, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:21:34 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-2 to 1
2023-03-04 00:21:34 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:21:44 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text ullamcorper sed tempor lacus euismod Elasticsearch lacinia arcu lacus ullamcorper sending to kafka topic twitter-topic
2023-03-04 00:21:44 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 1740690957156087834, "id": 5115692138941202807, "text": "ullamcorper sed tempor lacus euismod Elasticsearch lacinia arcu lacus ullamcorper", "createdAt": 1677876704000}' to topic = 'twitter-topic'
2023-03-04 00:21:44 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:21:44 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.ClientUtils - Resolved host localhost as 127.0.0.1
2023-03-04 00:21:44 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Initiating connection to node localhost:19092 (id: 1 rack: null) using address localhost/127.0.0.1
2023-03-04 00:21:44 [kafka-producer-network-thread | producer-1] DEBUG o.a.kafka.common.network.Selector - [Producer clientId=producer-1] Created socket with SO_RCVBUF = 326640, SO_SNDBUF = 146988, SO_TIMEOUT = 0 to node 1
2023-03-04 00:21:44 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Completed connection to node 1. Fetching API versions.
2023-03-04 00:21:44 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Initiating API versions fetch from node 1.
2023-03-04 00:21:44 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending API_VERSIONS request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=producer-1, correlationId=10) and timeout 60000 to node 1: ApiVersionsRequestData(clientSoftwareName='apache-kafka-java', clientSoftwareVersion='3.3.2')
2023-03-04 00:21:44 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received API_VERSIONS response from node 1 for request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=producer-1, correlationId=10): ApiVersionsResponseData(errorCode=35, apiKeys=[], throttleTimeMs=0, supportedFeatures=[], finalizedFeaturesEpoch=-1, finalizedFeatures=[])
2023-03-04 00:21:44 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Initiating API versions fetch from node 1.
2023-03-04 00:21:44 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending API_VERSIONS request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=0, clientId=producer-1, correlationId=11) and timeout 60000 to node 1: ApiVersionsRequestData(clientSoftwareName='apache-kafka-java', clientSoftwareVersion='3.3.2')
2023-03-04 00:21:44 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received API_VERSIONS response from node 1 for request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=0, clientId=producer-1, correlationId=11): ApiVersionsResponseData(errorCode=0, apiKeys=[ApiVersion(apiKey=0, minVersion=0, maxVersion=6), ApiVersion(apiKey=1, minVersion=0, maxVersion=8), ApiVersion(apiKey=2, minVersion=0, maxVersion=3), ApiVersion(apiKey=3, minVersion=0, maxVersion=6), ApiVersion(apiKey=4, minVersion=0, maxVersion=1), ApiVersion(apiKey=5, minVersion=0, maxVersion=0), ApiVersion(apiKey=6, minVersion=0, maxVersion=4), ApiVersion(apiKey=7, minVersion=0, maxVersion=1), ApiVersion(apiKey=8, minVersion=0, maxVersion=4), ApiVersion(apiKey=9, minVersion=0, maxVersion=4), ApiVersion(apiKey=10, minVersion=0, maxVersion=2), ApiVersion(apiKey=11, minVersion=0, maxVersion=3), ApiVersion(apiKey=12, minVersion=0, maxVersion=2), ApiVersion(apiKey=13, minVersion=0, maxVersion=2), ApiVersion(apiKey=14, minVersion=0, maxVersion=2), ApiVersion(apiKey=15, minVersion=0, maxVersion=2), ApiVersion(apiKey=16, minVersion=0, maxVersion=2), ApiVersion(apiKey=17, minVersion=0, maxVersion=1), ApiVersion(apiKey=18, minVersion=0, maxVersion=2), ApiVersion(apiKey=19, minVersion=0, maxVersion=3), ApiVersion(apiKey=20, minVersion=0, maxVersion=2), ApiVersion(apiKey=21, minVersion=0, maxVersion=1), ApiVersion(apiKey=22, minVersion=0, maxVersion=1), ApiVersion(apiKey=23, minVersion=0, maxVersion=1), ApiVersion(apiKey=24, minVersion=0, maxVersion=1), ApiVersion(apiKey=25, minVersion=0, maxVersion=1), ApiVersion(apiKey=26, minVersion=0, maxVersion=1), ApiVersion(apiKey=27, minVersion=0, maxVersion=0), ApiVersion(apiKey=28, minVersion=0, maxVersion=1), ApiVersion(apiKey=29, minVersion=0, maxVersion=1), ApiVersion(apiKey=30, minVersion=0, maxVersion=1), ApiVersion(apiKey=31, minVersion=0, maxVersion=1), ApiVersion(apiKey=32, minVersion=0, maxVersion=2), ApiVersion(apiKey=33, minVersion=0, maxVersion=1), ApiVersion(apiKey=34, minVersion=0, maxVersion=1), ApiVersion(apiKey=35, minVersion=0, maxVersion=1), ApiVersion(apiKey=36, minVersion=0, maxVersion=0), ApiVersion(apiKey=37, minVersion=0, maxVersion=1), ApiVersion(apiKey=38, minVersion=0, maxVersion=1), ApiVersion(apiKey=39, minVersion=0, maxVersion=1), ApiVersion(apiKey=40, minVersion=0, maxVersion=1), ApiVersion(apiKey=41, minVersion=0, maxVersion=1), ApiVersion(apiKey=42, minVersion=0, maxVersion=1)], throttleTimeMs=0, supportedFeatures=[], finalizedFeaturesEpoch=-1, finalizedFeatures=[])
2023-03-04 00:21:44 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Node 1 has finalized features epoch: -1, finalized features: [], supported features: [], API versions: (Produce(0): 0 to 6 [usable: 6], Fetch(1): 0 to 8 [usable: 8], ListOffsets(2): 0 to 3 [usable: 3], Metadata(3): 0 to 6 [usable: 6], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 4 [usable: 4], OffsetFetch(9): 0 to 4 [usable: 4], FindCoordinator(10): 0 to 2 [usable: 2], JoinGroup(11): 0 to 3 [usable: 3], Heartbeat(12): 0 to 2 [usable: 2], LeaveGroup(13): 0 to 2 [usable: 2], SyncGroup(14): 0 to 2 [usable: 2], DescribeGroups(15): 0 to 2 [usable: 2], ListGroups(16): 0 to 2 [usable: 2], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 2], CreateTopics(19): 0 to 3 [usable: 3], DeleteTopics(20): 0 to 2 [usable: 2], DeleteRecords(21): 0 to 1 [usable: 1], InitProducerId(22): 0 to 1 [usable: 1], OffsetForLeaderEpoch(23): 0 to 1 [usable: 1], AddPartitionsToTxn(24): 0 to 1 [usable: 1], AddOffsetsToTxn(25): 0 to 1 [usable: 1], EndTxn(26): 0 to 1 [usable: 1], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 1 [usable: 1], DescribeAcls(29): 0 to 1 [usable: 1], CreateAcls(30): 0 to 1 [usable: 1], DeleteAcls(31): 0 to 1 [usable: 1], DescribeConfigs(32): 0 to 2 [usable: 2], AlterConfigs(33): 0 to 1 [usable: 1], AlterReplicaLogDirs(34): 0 to 1 [usable: 1], DescribeLogDirs(35): 0 to 1 [usable: 1], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 1], CreateDelegationToken(38): 0 to 1 [usable: 1], RenewDelegationToken(39): 0 to 1 [usable: 1], ExpireDelegationToken(40): 0 to 1 [usable: 1], DescribeDelegationToken(41): 0 to 1 [usable: 1], DeleteGroups(42): 0 to 1 [usable: 1], ElectLeaders(43): UNSUPPORTED, IncrementalAlterConfigs(44): UNSUPPORTED, AlterPartitionReassignments(45): UNSUPPORTED, ListPartitionReassignments(46): UNSUPPORTED, OffsetDelete(47): UNSUPPORTED, DescribeClientQuotas(48): UNSUPPORTED, AlterClientQuotas(49): UNSUPPORTED, DescribeUserScramCredentials(50): UNSUPPORTED, AlterUserScramCredentials(51): UNSUPPORTED, AlterPartition(56): UNSUPPORTED, UpdateFeatures(57): UNSUPPORTED, DescribeCluster(60): UNSUPPORTED, DescribeProducers(61): UNSUPPORTED, DescribeTransactions(65): UNSUPPORTED, ListTransactions(66): UNSUPPORTED, AllocateProducerIds(67): UNSUPPORTED).
2023-03-04 00:21:44 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId of partition twitter-topic-1 set to 3000 with epoch 0. Reinitialize sequence at beginning.
2023-03-04 00:21:44 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 0 being sent to partition twitter-topic-1
2023-03-04 00:21:44 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=12) and timeout 60000 to node 1: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-1=204]}
2023-03-04 00:21:44 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 1 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=12): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=1, errorCode=0, baseOffset=0, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:21:44 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-1 to 0
2023-03-04 00:21:44 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:21:52 [reactor-http-nio-3] DEBUG r.n.r.DefaultPooledConnectionProvider - [db39a7e0, L:/127.0.0.1:51757 ! R:localhost/127.0.0.1:8081] onStateChange(PooledConnection{channel=[id: 0xdb39a7e0, L:/127.0.0.1:51757 ! R:localhost/127.0.0.1:8081]}, [disconnecting])
2023-03-04 00:21:54 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text arcu sed metus in a vestibulum feugiat Elasticsearch at non non at euismod sending to kafka topic twitter-topic
2023-03-04 00:21:54 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 8823032836980936192, "id": 8952852316732541409, "text": "arcu sed metus in a vestibulum feugiat Elasticsearch at non non at euismod", "createdAt": 1677876714000}' to topic = 'twitter-topic'
2023-03-04 00:21:54 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:21:54 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.ClientUtils - Resolved host localhost as 127.0.0.1
2023-03-04 00:21:54 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Initiating connection to node localhost:29092 (id: 2 rack: null) using address localhost/127.0.0.1
2023-03-04 00:21:54 [kafka-producer-network-thread | producer-1] DEBUG o.a.kafka.common.network.Selector - [Producer clientId=producer-1] Created socket with SO_RCVBUF = 326640, SO_SNDBUF = 146988, SO_TIMEOUT = 0 to node 2
2023-03-04 00:21:54 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Completed connection to node 2. Fetching API versions.
2023-03-04 00:21:54 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Initiating API versions fetch from node 2.
2023-03-04 00:21:54 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending API_VERSIONS request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=producer-1, correlationId=13) and timeout 60000 to node 2: ApiVersionsRequestData(clientSoftwareName='apache-kafka-java', clientSoftwareVersion='3.3.2')
2023-03-04 00:21:54 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received API_VERSIONS response from node 2 for request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=producer-1, correlationId=13): ApiVersionsResponseData(errorCode=35, apiKeys=[], throttleTimeMs=0, supportedFeatures=[], finalizedFeaturesEpoch=-1, finalizedFeatures=[])
2023-03-04 00:21:54 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Initiating API versions fetch from node 2.
2023-03-04 00:21:54 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending API_VERSIONS request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=0, clientId=producer-1, correlationId=14) and timeout 60000 to node 2: ApiVersionsRequestData(clientSoftwareName='apache-kafka-java', clientSoftwareVersion='3.3.2')
2023-03-04 00:21:54 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received API_VERSIONS response from node 2 for request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=0, clientId=producer-1, correlationId=14): ApiVersionsResponseData(errorCode=0, apiKeys=[ApiVersion(apiKey=0, minVersion=0, maxVersion=6), ApiVersion(apiKey=1, minVersion=0, maxVersion=8), ApiVersion(apiKey=2, minVersion=0, maxVersion=3), ApiVersion(apiKey=3, minVersion=0, maxVersion=6), ApiVersion(apiKey=4, minVersion=0, maxVersion=1), ApiVersion(apiKey=5, minVersion=0, maxVersion=0), ApiVersion(apiKey=6, minVersion=0, maxVersion=4), ApiVersion(apiKey=7, minVersion=0, maxVersion=1), ApiVersion(apiKey=8, minVersion=0, maxVersion=4), ApiVersion(apiKey=9, minVersion=0, maxVersion=4), ApiVersion(apiKey=10, minVersion=0, maxVersion=2), ApiVersion(apiKey=11, minVersion=0, maxVersion=3), ApiVersion(apiKey=12, minVersion=0, maxVersion=2), ApiVersion(apiKey=13, minVersion=0, maxVersion=2), ApiVersion(apiKey=14, minVersion=0, maxVersion=2), ApiVersion(apiKey=15, minVersion=0, maxVersion=2), ApiVersion(apiKey=16, minVersion=0, maxVersion=2), ApiVersion(apiKey=17, minVersion=0, maxVersion=1), ApiVersion(apiKey=18, minVersion=0, maxVersion=2), ApiVersion(apiKey=19, minVersion=0, maxVersion=3), ApiVersion(apiKey=20, minVersion=0, maxVersion=2), ApiVersion(apiKey=21, minVersion=0, maxVersion=1), ApiVersion(apiKey=22, minVersion=0, maxVersion=1), ApiVersion(apiKey=23, minVersion=0, maxVersion=1), ApiVersion(apiKey=24, minVersion=0, maxVersion=1), ApiVersion(apiKey=25, minVersion=0, maxVersion=1), ApiVersion(apiKey=26, minVersion=0, maxVersion=1), ApiVersion(apiKey=27, minVersion=0, maxVersion=0), ApiVersion(apiKey=28, minVersion=0, maxVersion=1), ApiVersion(apiKey=29, minVersion=0, maxVersion=1), ApiVersion(apiKey=30, minVersion=0, maxVersion=1), ApiVersion(apiKey=31, minVersion=0, maxVersion=1), ApiVersion(apiKey=32, minVersion=0, maxVersion=2), ApiVersion(apiKey=33, minVersion=0, maxVersion=1), ApiVersion(apiKey=34, minVersion=0, maxVersion=1), ApiVersion(apiKey=35, minVersion=0, maxVersion=1), ApiVersion(apiKey=36, minVersion=0, maxVersion=0), ApiVersion(apiKey=37, minVersion=0, maxVersion=1), ApiVersion(apiKey=38, minVersion=0, maxVersion=1), ApiVersion(apiKey=39, minVersion=0, maxVersion=1), ApiVersion(apiKey=40, minVersion=0, maxVersion=1), ApiVersion(apiKey=41, minVersion=0, maxVersion=1), ApiVersion(apiKey=42, minVersion=0, maxVersion=1)], throttleTimeMs=0, supportedFeatures=[], finalizedFeaturesEpoch=-1, finalizedFeatures=[])
2023-03-04 00:21:54 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Node 2 has finalized features epoch: -1, finalized features: [], supported features: [], API versions: (Produce(0): 0 to 6 [usable: 6], Fetch(1): 0 to 8 [usable: 8], ListOffsets(2): 0 to 3 [usable: 3], Metadata(3): 0 to 6 [usable: 6], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 4 [usable: 4], OffsetFetch(9): 0 to 4 [usable: 4], FindCoordinator(10): 0 to 2 [usable: 2], JoinGroup(11): 0 to 3 [usable: 3], Heartbeat(12): 0 to 2 [usable: 2], LeaveGroup(13): 0 to 2 [usable: 2], SyncGroup(14): 0 to 2 [usable: 2], DescribeGroups(15): 0 to 2 [usable: 2], ListGroups(16): 0 to 2 [usable: 2], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 2], CreateTopics(19): 0 to 3 [usable: 3], DeleteTopics(20): 0 to 2 [usable: 2], DeleteRecords(21): 0 to 1 [usable: 1], InitProducerId(22): 0 to 1 [usable: 1], OffsetForLeaderEpoch(23): 0 to 1 [usable: 1], AddPartitionsToTxn(24): 0 to 1 [usable: 1], AddOffsetsToTxn(25): 0 to 1 [usable: 1], EndTxn(26): 0 to 1 [usable: 1], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 1 [usable: 1], DescribeAcls(29): 0 to 1 [usable: 1], CreateAcls(30): 0 to 1 [usable: 1], DeleteAcls(31): 0 to 1 [usable: 1], DescribeConfigs(32): 0 to 2 [usable: 2], AlterConfigs(33): 0 to 1 [usable: 1], AlterReplicaLogDirs(34): 0 to 1 [usable: 1], DescribeLogDirs(35): 0 to 1 [usable: 1], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 1], CreateDelegationToken(38): 0 to 1 [usable: 1], RenewDelegationToken(39): 0 to 1 [usable: 1], ExpireDelegationToken(40): 0 to 1 [usable: 1], DescribeDelegationToken(41): 0 to 1 [usable: 1], DeleteGroups(42): 0 to 1 [usable: 1], ElectLeaders(43): UNSUPPORTED, IncrementalAlterConfigs(44): UNSUPPORTED, AlterPartitionReassignments(45): UNSUPPORTED, ListPartitionReassignments(46): UNSUPPORTED, OffsetDelete(47): UNSUPPORTED, DescribeClientQuotas(48): UNSUPPORTED, AlterClientQuotas(49): UNSUPPORTED, DescribeUserScramCredentials(50): UNSUPPORTED, AlterUserScramCredentials(51): UNSUPPORTED, AlterPartition(56): UNSUPPORTED, UpdateFeatures(57): UNSUPPORTED, DescribeCluster(60): UNSUPPORTED, DescribeProducers(61): UNSUPPORTED, DescribeTransactions(65): UNSUPPORTED, ListTransactions(66): UNSUPPORTED, AllocateProducerIds(67): UNSUPPORTED).
2023-03-04 00:21:54 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId of partition twitter-topic-0 set to 3000 with epoch 0. Reinitialize sequence at beginning.
2023-03-04 00:21:54 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 0 being sent to partition twitter-topic-0
2023-03-04 00:21:54 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=15) and timeout 60000 to node 2: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-0=209]}
2023-03-04 00:21:54 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 2 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=15): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=0, errorCode=0, baseOffset=0, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:21:54 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-0 to 0
2023-03-04 00:21:54 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:22:04 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text sed lacinia commodo non lacus commodo Java tempor ante sed quis ullamcorper sending to kafka topic twitter-topic
2023-03-04 00:22:04 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 7665418376677704227, "id": 665923695911281646, "text": "sed lacinia commodo non lacus commodo Java tempor ante sed quis ullamcorper", "createdAt": 1677876724000}' to topic = 'twitter-topic'
2023-03-04 00:22:04 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:22:04 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 1 being sent to partition twitter-topic-0
2023-03-04 00:22:04 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=16) and timeout 60000 to node 2: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-0=200]}
2023-03-04 00:22:04 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 2 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=16): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=0, errorCode=0, baseOffset=1, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:22:04 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-0 to 1
2023-03-04 00:22:04 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:22:14 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text ullamcorper metus odio commodo in Elasticsearch metus odio arcu at sending to kafka topic twitter-topic
2023-03-04 00:22:14 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 3707207631998430076, "id": 5823234560698301444, "text": "ullamcorper metus odio commodo in Elasticsearch metus odio arcu at", "createdAt": 1677876734000}' to topic = 'twitter-topic'
2023-03-04 00:22:14 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:22:14 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 2 being sent to partition twitter-topic-2
2023-03-04 00:22:14 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=17) and timeout 60000 to node 3: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-2=192]}
2023-03-04 00:22:14 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 3 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=17): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=2, errorCode=0, baseOffset=2, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:22:14 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-2 to 2
2023-03-04 00:22:14 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:22:24 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text arcu sed non at Spring tempor ante at sending to kafka topic twitter-topic
2023-03-04 00:22:24 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 2737093771538541554, "id": 1180446420081605701, "text": "arcu sed non at Spring tempor ante at", "createdAt": 1677876744000}' to topic = 'twitter-topic'
2023-03-04 00:22:24 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:22:24 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 2 being sent to partition twitter-topic-0
2023-03-04 00:22:24 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=18) and timeout 60000 to node 2: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-0=169]}
2023-03-04 00:22:24 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 2 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=18): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=0, errorCode=0, baseOffset=2, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:22:24 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-0 to 2
2023-03-04 00:22:24 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:22:34 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text sed tempor vestibulum ullamcorper Microservices non at sending to kafka topic twitter-topic
2023-03-04 00:22:34 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 9108803484896562220, "id": 3044254892164403522, "text": "sed tempor vestibulum ullamcorper Microservices non at", "createdAt": 1677876754000}' to topic = 'twitter-topic'
2023-03-04 00:22:34 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:22:34 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 3 being sent to partition twitter-topic-2
2023-03-04 00:22:34 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=19) and timeout 60000 to node 3: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-2=187]}
2023-03-04 00:22:34 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 3 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=19): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=2, errorCode=0, baseOffset=3, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:22:34 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-2 to 3
2023-03-04 00:22:34 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:22:44 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text feugiat euismod ullamcorper non Spring tempor at sending to kafka topic twitter-topic
2023-03-04 00:22:44 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 4217836526228539709, "id": 1461837970493350581, "text": "feugiat euismod ullamcorper non Spring tempor at", "createdAt": 1677876764000}' to topic = 'twitter-topic'
2023-03-04 00:22:44 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:22:44 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 4 being sent to partition twitter-topic-2
2023-03-04 00:22:44 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=20) and timeout 60000 to node 3: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-2=181]}
2023-03-04 00:22:44 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 3 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=20): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=2, errorCode=0, baseOffset=4, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:22:44 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-2 to 4
2023-03-04 00:22:44 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:22:54 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text lacus in lacus ullamcorper sed Elasticsearch tempor at tempor sending to kafka topic twitter-topic
2023-03-04 00:22:54 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 6970773393288008823, "id": 6659011624162560255, "text": "lacus in lacus ullamcorper sed Elasticsearch tempor at tempor", "createdAt": 1677876774000}' to topic = 'twitter-topic'
2023-03-04 00:22:54 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:22:54 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 1 being sent to partition twitter-topic-1
2023-03-04 00:22:54 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=21) and timeout 60000 to node 1: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-1=191]}
2023-03-04 00:22:54 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 1 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=21): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=1, errorCode=0, baseOffset=1, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:22:54 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-1 to 1
2023-03-04 00:22:54 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:23:04 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text tempor lacinia tempor commodo Kafka commodo ante in sending to kafka topic twitter-topic
2023-03-04 00:23:04 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 7536530982815053286, "id": 1775701592626657018, "text": "tempor lacinia tempor commodo Kafka commodo ante in", "createdAt": 1677876784000}' to topic = 'twitter-topic'
2023-03-04 00:23:04 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:23:04 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 2 being sent to partition twitter-topic-1
2023-03-04 00:23:04 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=22) and timeout 60000 to node 1: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-1=174]}
2023-03-04 00:23:04 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 1 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=22): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=1, errorCode=0, baseOffset=2, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:23:04 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-1 to 2
2023-03-04 00:23:04 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:23:14 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text ullamcorper lacus metus feugiat Spring feugiat a at sending to kafka topic twitter-topic
2023-03-04 00:23:14 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 7924461542236746300, "id": 5433187876360429178, "text": "ullamcorper lacus metus feugiat Spring feugiat a at", "createdAt": 1677876794000}' to topic = 'twitter-topic'
2023-03-04 00:23:14 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:23:14 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 3 being sent to partition twitter-topic-0
2023-03-04 00:23:14 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=23) and timeout 60000 to node 2: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-0=185]}
2023-03-04 00:23:14 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 2 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=23): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=0, errorCode=0, baseOffset=3, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:23:14 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-0 to 3
2023-03-04 00:23:14 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:23:24 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text in non metus sed sed quis lacinia ullamcorper Elasticsearch at ante feugiat arcu ante sed arcu sending to kafka topic twitter-topic
2023-03-04 00:23:24 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 1852748772268989110, "id": 1342262858816097008, "text": "in non metus sed sed quis lacinia ullamcorper Elasticsearch at ante feugiat arcu ante sed arcu", "createdAt": 1677876804000}' to topic = 'twitter-topic'
2023-03-04 00:23:24 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:23:24 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 3 being sent to partition twitter-topic-1
2023-03-04 00:23:24 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=24) and timeout 60000 to node 1: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-1=222]}
2023-03-04 00:23:24 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 1 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=24): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=1, errorCode=0, baseOffset=3, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:23:24 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-1 to 3
2023-03-04 00:23:24 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:23:34 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text metus at lacinia lacinia odio metus non Kafka feugiat a odio quis ante sending to kafka topic twitter-topic
2023-03-04 00:23:34 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 3070644399996042416, "id": 6334033643208786576, "text": "metus at lacinia lacinia odio metus non Kafka feugiat a odio quis ante", "createdAt": 1677876814000}' to topic = 'twitter-topic'
2023-03-04 00:23:34 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:23:34 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 4 being sent to partition twitter-topic-1
2023-03-04 00:23:34 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=25) and timeout 60000 to node 1: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-1=192]}
2023-03-04 00:23:34 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 1 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=25): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=1, errorCode=0, baseOffset=4, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:23:34 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-1 to 4
2023-03-04 00:23:34 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:23:44 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text ante at tempor at ante ante tempor arcu Microservices tempor dictum feugiat commodo arcu dictum vestibulum sending to kafka topic twitter-topic
2023-03-04 00:23:44 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 6095559483366593004, "id": 3367998065750249631, "text": "ante at tempor at ante ante tempor arcu Microservices tempor dictum feugiat commodo arcu dictum vestibulum", "createdAt": 1677876824000}' to topic = 'twitter-topic'
2023-03-04 00:23:44 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:23:44 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 5 being sent to partition twitter-topic-1
2023-03-04 00:23:44 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=26) and timeout 60000 to node 1: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-1=221]}
2023-03-04 00:23:44 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 1 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=26): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=1, errorCode=0, baseOffset=5, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:23:44 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-1 to 5
2023-03-04 00:23:44 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:23:54 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text dictum at ullamcorper in odio ullamcorper Microservices metus odio feugiat at sending to kafka topic twitter-topic
2023-03-04 00:23:54 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 7975385479382252025, "id": 8188736650937481847, "text": "dictum at ullamcorper in odio ullamcorper Microservices metus odio feugiat at", "createdAt": 1677876834000}' to topic = 'twitter-topic'
2023-03-04 00:23:54 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:23:54 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 5 being sent to partition twitter-topic-2
2023-03-04 00:23:54 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=27) and timeout 60000 to node 3: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-2=205]}
2023-03-04 00:23:54 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 3 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=27): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=2, errorCode=0, baseOffset=5, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:23:54 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-2 to 5
2023-03-04 00:23:54 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:24:04 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text non ullamcorper non commodo Java quis commodo in sending to kafka topic twitter-topic
2023-03-04 00:24:04 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 7661157231311963755, "id": 8863485318491263859, "text": "non ullamcorper non commodo Java quis commodo in", "createdAt": 1677876844000}' to topic = 'twitter-topic'
2023-03-04 00:24:04 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:24:04 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 6 being sent to partition twitter-topic-1
2023-03-04 00:24:04 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=28) and timeout 60000 to node 1: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-1=176]}
2023-03-04 00:24:04 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 1 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=28): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=1, errorCode=0, baseOffset=6, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:24:04 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-1 to 6
2023-03-04 00:24:04 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:24:14 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text ante tempor vestibulum at odio at odio quis Java ullamcorper dictum metus arcu euismod tempor sending to kafka topic twitter-topic
2023-03-04 00:24:14 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 8639207782221790015, "id": 5941370296663238382, "text": "ante tempor vestibulum at odio at odio quis Java ullamcorper dictum metus arcu euismod tempor", "createdAt": 1677876854000}' to topic = 'twitter-topic'
2023-03-04 00:24:14 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:24:14 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 4 being sent to partition twitter-topic-0
2023-03-04 00:24:14 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=29) and timeout 60000 to node 2: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-0=223]}
2023-03-04 00:24:14 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 2 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=29): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=0, errorCode=0, baseOffset=4, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:24:14 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-0 to 4
2023-03-04 00:24:14 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:24:24 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text dictum lacinia lacus Spring ullamcorper arcu sending to kafka topic twitter-topic
2023-03-04 00:24:24 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 60456249050382677, "id": 3394869358869450349, "text": "dictum lacinia lacus Spring ullamcorper arcu", "createdAt": 1677876864000}' to topic = 'twitter-topic'
2023-03-04 00:24:24 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:24:24 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 7 being sent to partition twitter-topic-1
2023-03-04 00:24:24 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=30) and timeout 60000 to node 1: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-1=176]}
2023-03-04 00:24:24 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 1 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=30): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=1, errorCode=0, baseOffset=7, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:24:24 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-1 to 7
2023-03-04 00:24:24 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:24:34 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text commodo in metus euismod sed Kafka a tempor metus sending to kafka topic twitter-topic
2023-03-04 00:24:34 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 4612534923348200221, "id": 8102319806875089724, "text": "commodo in metus euismod sed Kafka a tempor metus", "createdAt": 1677876874000}' to topic = 'twitter-topic'
2023-03-04 00:24:34 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:24:34 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 8 being sent to partition twitter-topic-1
2023-03-04 00:24:34 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=31) and timeout 60000 to node 1: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-1=183]}
2023-03-04 00:24:34 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 1 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=31): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=1, errorCode=0, baseOffset=8, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:24:34 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-1 to 8
2023-03-04 00:24:34 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:24:44 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text odio in lacus ullamcorper ante vestibulum a ullamcorper Kafka vestibulum lacinia ullamcorper odio non euismod sending to kafka topic twitter-topic
2023-03-04 00:24:44 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 2324721284039831600, "id": 4636217014249953335, "text": "odio in lacus ullamcorper ante vestibulum a ullamcorper Kafka vestibulum lacinia ullamcorper odio non euismod", "createdAt": 1677876884000}' to topic = 'twitter-topic'
2023-03-04 00:24:44 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:24:44 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 9 being sent to partition twitter-topic-1
2023-03-04 00:24:44 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=32) and timeout 60000 to node 1: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-1=218]}
2023-03-04 00:24:44 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 1 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=32): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=1, errorCode=0, baseOffset=9, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:24:44 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-1 to 9
2023-03-04 00:24:44 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:24:54 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text lacus quis metus odio feugiat Java dictum ante commodo sending to kafka topic twitter-topic
2023-03-04 00:24:54 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 5823384837323382537, "id": 6735463529172745866, "text": "lacus quis metus odio feugiat Java dictum ante commodo", "createdAt": 1677876894000}' to topic = 'twitter-topic'
2023-03-04 00:24:54 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:24:54 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 6 being sent to partition twitter-topic-2
2023-03-04 00:24:54 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=33) and timeout 60000 to node 3: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-2=188]}
2023-03-04 00:24:54 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 3 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=33): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=2, errorCode=0, baseOffset=6, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:24:54 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-2 to 6
2023-03-04 00:24:54 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:25:04 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text arcu at ante euismod Kafka euismod sed sending to kafka topic twitter-topic
2023-03-04 00:25:04 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 958049673911371348, "id": 1330618615348982855, "text": "arcu at ante euismod Kafka euismod sed", "createdAt": 1677876904000}' to topic = 'twitter-topic'
2023-03-04 00:25:04 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:25:04 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 7 being sent to partition twitter-topic-2
2023-03-04 00:25:04 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=34) and timeout 60000 to node 3: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-2=164]}
2023-03-04 00:25:04 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 3 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=34): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=2, errorCode=0, baseOffset=7, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:25:04 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-2 to 7
2023-03-04 00:25:04 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:25:14 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text ante quis a arcu Elasticsearch at in sending to kafka topic twitter-topic
2023-03-04 00:25:14 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 993058593381299129, "id": 94570198245550241, "text": "ante quis a arcu Elasticsearch at in", "createdAt": 1677876914000}' to topic = 'twitter-topic'
2023-03-04 00:25:14 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:25:14 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 8 being sent to partition twitter-topic-2
2023-03-04 00:25:14 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=35) and timeout 60000 to node 3: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-2=168]}
2023-03-04 00:25:14 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 3 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=35): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=2, errorCode=0, baseOffset=8, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:25:14 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-2 to 8
2023-03-04 00:25:14 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:25:24 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text commodo tempor lacus vestibulum dictum Spring in commodo non tempor sending to kafka topic twitter-topic
2023-03-04 00:25:24 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 5981647017159625997, "id": 7843446333903161658, "text": "commodo tempor lacus vestibulum dictum Spring in commodo non tempor", "createdAt": 1677876924000}' to topic = 'twitter-topic'
2023-03-04 00:25:24 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:25:24 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 9 being sent to partition twitter-topic-2
2023-03-04 00:25:24 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=36) and timeout 60000 to node 3: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-2=197]}
2023-03-04 00:25:24 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 3 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=36): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=2, errorCode=0, baseOffset=9, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:25:24 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-2 to 9
2023-03-04 00:25:24 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:25:34 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text commodo quis quis vestibulum tempor sed dictum Kafka ante dictum metus ante lacinia in sending to kafka topic twitter-topic
2023-03-04 00:25:34 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 5889323672229440755, "id": 2785779863107029289, "text": "commodo quis quis vestibulum tempor sed dictum Kafka ante dictum metus ante lacinia in", "createdAt": 1677876934000}' to topic = 'twitter-topic'
2023-03-04 00:25:34 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:25:34 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 5 being sent to partition twitter-topic-0
2023-03-04 00:25:34 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=37) and timeout 60000 to node 2: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-0=222]}
2023-03-04 00:25:34 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 2 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=37): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=0, errorCode=0, baseOffset=5, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:25:34 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-0 to 5
2023-03-04 00:25:34 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:25:44 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text odio metus non vestibulum at tempor sed lacus Kafka lacus tempor a lacus in non at sending to kafka topic twitter-topic
2023-03-04 00:25:44 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 7472274041312186242, "id": 4286964572272602306, "text": "odio metus non vestibulum at tempor sed lacus Kafka lacus tempor a lacus in non at", "createdAt": 1677876944000}' to topic = 'twitter-topic'
2023-03-04 00:25:44 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:25:44 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 10 being sent to partition twitter-topic-2
2023-03-04 00:25:44 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=38) and timeout 60000 to node 3: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-2=210]}
2023-03-04 00:25:44 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 3 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=38): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=2, errorCode=0, baseOffset=10, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:25:44 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-2 to 10
2023-03-04 00:25:44 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:25:54 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text quis non at tempor feugiat Kafka vestibulum at quis commodo sending to kafka topic twitter-topic
2023-03-04 00:25:54 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 6483304901246320184, "id": 1129221421821786973, "text": "quis non at tempor feugiat Kafka vestibulum at quis commodo", "createdAt": 1677876954000}' to topic = 'twitter-topic'
2023-03-04 00:25:54 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:25:54 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 6 being sent to partition twitter-topic-0
2023-03-04 00:25:54 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=39) and timeout 60000 to node 2: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-0=191]}
2023-03-04 00:25:54 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 2 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=39): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=0, errorCode=0, baseOffset=6, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:25:54 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-0 to 6
2023-03-04 00:25:54 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:26:04 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text sed commodo non ullamcorper euismod non Elasticsearch ullamcorper euismod arcu tempor sending to kafka topic twitter-topic
2023-03-04 00:26:04 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 8010791077931024482, "id": 2430894208432239566, "text": "sed commodo non ullamcorper euismod non Elasticsearch ullamcorper euismod arcu tempor", "createdAt": 1677876964000}' to topic = 'twitter-topic'
2023-03-04 00:26:04 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:26:04 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 11 being sent to partition twitter-topic-2
2023-03-04 00:26:04 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=40) and timeout 60000 to node 3: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-2=213]}
2023-03-04 00:26:04 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 3 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=40): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=2, errorCode=0, baseOffset=11, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:26:04 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-2 to 11
2023-03-04 00:26:04 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:26:14 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text ullamcorper ante quis a non in lacus tempor Java tempor feugiat non dictum arcu dictum sending to kafka topic twitter-topic
2023-03-04 00:26:14 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 5068378996961400765, "id": 1442701682968204469, "text": "ullamcorper ante quis a non in lacus tempor Java tempor feugiat non dictum arcu dictum", "createdAt": 1677876974000}' to topic = 'twitter-topic'
2023-03-04 00:26:14 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:26:14 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 7 being sent to partition twitter-topic-0
2023-03-04 00:26:14 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=41) and timeout 60000 to node 2: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-0=218]}
2023-03-04 00:26:14 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 2 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=41): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=0, errorCode=0, baseOffset=7, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:26:14 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-0 to 7
2023-03-04 00:26:14 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:26:21 [kafka-admin-client-thread | adminclient-1] INFO  o.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Node -1 disconnected.
2023-03-04 00:26:21 [kafka-admin-client-thread | adminclient-1] DEBUG o.a.k.c.a.i.AdminMetadataManager - [AdminClient clientId=adminclient-1] Requesting metadata update.
2023-03-04 00:26:21 [kafka-admin-client-thread | adminclient-1] DEBUG o.a.k.clients.admin.KafkaAdminClient - [AdminClient clientId=adminclient-1] Sending MetadataRequestData(topics=[], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to localhost:39092 (id: 3 rack: null). correlationId=7, timeoutMs=30000
2023-03-04 00:26:21 [kafka-admin-client-thread | adminclient-1] DEBUG o.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Sending METADATA request with header RequestHeader(apiKey=METADATA, apiVersion=6, clientId=adminclient-1, correlationId=7) and timeout 30000 to node 3: MetadataRequestData(topics=[], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false)
2023-03-04 00:26:21 [kafka-admin-client-thread | adminclient-1] DEBUG o.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Received METADATA response from node 3 for request with header RequestHeader(apiKey=METADATA, apiVersion=6, clientId=adminclient-1, correlationId=7): MetadataResponseData(throttleTimeMs=0, brokers=[MetadataResponseBroker(nodeId=2, host='localhost', port=29092, rack=null), MetadataResponseBroker(nodeId=1, host='localhost', port=19092, rack=null), MetadataResponseBroker(nodeId=3, host='localhost', port=39092, rack=null)], clusterId='QGDYypu5SSGtA9Bc36Rjow', controllerId=3, topics=[], clusterAuthorizedOperations=-2147483648)
2023-03-04 00:26:21 [kafka-admin-client-thread | adminclient-1] DEBUG o.a.k.c.a.i.AdminMetadataManager - [AdminClient clientId=adminclient-1] Updating cluster metadata to Cluster(id = QGDYypu5SSGtA9Bc36Rjow, nodes = [localhost:39092 (id: 3 rack: null), localhost:19092 (id: 1 rack: null), localhost:29092 (id: 2 rack: null)], partitions = [], controller = localhost:39092 (id: 3 rack: null))
2023-03-04 00:26:22 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending metadata request MetadataRequestData(topics=[MetadataRequestTopic(topicId=AAAAAAAAAAAAAAAAAAAAAA, name='twitter-topic')], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to node localhost:39092 (id: 3 rack: null)
2023-03-04 00:26:22 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending METADATA request with header RequestHeader(apiKey=METADATA, apiVersion=6, clientId=producer-1, correlationId=42) and timeout 60000 to node 3: MetadataRequestData(topics=[MetadataRequestTopic(topicId=AAAAAAAAAAAAAAAAAAAAAA, name='twitter-topic')], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false)
2023-03-04 00:26:22 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received METADATA response from node 3 for request with header RequestHeader(apiKey=METADATA, apiVersion=6, clientId=producer-1, correlationId=42): MetadataResponseData(throttleTimeMs=0, brokers=[MetadataResponseBroker(nodeId=2, host='localhost', port=29092, rack=null), MetadataResponseBroker(nodeId=1, host='localhost', port=19092, rack=null), MetadataResponseBroker(nodeId=3, host='localhost', port=39092, rack=null)], clusterId='QGDYypu5SSGtA9Bc36Rjow', controllerId=3, topics=[MetadataResponseTopic(errorCode=0, name='twitter-topic', topicId=AAAAAAAAAAAAAAAAAAAAAA, isInternal=false, partitions=[MetadataResponsePartition(errorCode=0, partitionIndex=2, leaderId=3, leaderEpoch=-1, replicaNodes=[3, 2, 1], isrNodes=[3, 2, 1], offlineReplicas=[]), MetadataResponsePartition(errorCode=0, partitionIndex=1, leaderId=1, leaderEpoch=-1, replicaNodes=[1, 3, 2], isrNodes=[1, 3, 2], offlineReplicas=[]), MetadataResponsePartition(errorCode=0, partitionIndex=0, leaderId=2, leaderEpoch=-1, replicaNodes=[2, 1, 3], isrNodes=[2, 1, 3], offlineReplicas=[])], topicAuthorizedOperations=-2147483648)], clusterAuthorizedOperations=-2147483648)
2023-03-04 00:26:22 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Updated cluster metadata updateVersion 3 to MetadataCache{clusterId='QGDYypu5SSGtA9Bc36Rjow', nodes={1=localhost:19092 (id: 1 rack: null), 2=localhost:29092 (id: 2 rack: null), 3=localhost:39092 (id: 3 rack: null)}, partitions=[PartitionMetadata(error=NONE, partition=twitter-topic-0, leader=Optional[2], leaderEpoch=Optional.empty, replicas=2,1,3, isr=2,1,3, offlineReplicas=), PartitionMetadata(error=NONE, partition=twitter-topic-1, leader=Optional[1], leaderEpoch=Optional.empty, replicas=1,3,2, isr=1,3,2, offlineReplicas=), PartitionMetadata(error=NONE, partition=twitter-topic-2, leader=Optional[3], leaderEpoch=Optional.empty, replicas=3,2,1, isr=3,2,1, offlineReplicas=)], controller=localhost:39092 (id: 3 rack: null)}
2023-03-04 00:26:24 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text metus feugiat non ullamcorper lacus tempor odio quis Microservices lacinia quis quis euismod non metus ante sending to kafka topic twitter-topic
2023-03-04 00:26:24 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 1517009836084571148, "id": 8336876777332630385, "text": "metus feugiat non ullamcorper lacus tempor odio quis Microservices lacinia quis quis euismod non metus ante", "createdAt": 1677876984000}' to topic = 'twitter-topic'
2023-03-04 00:26:24 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:26:24 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 10 being sent to partition twitter-topic-1
2023-03-04 00:26:24 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=43) and timeout 60000 to node 1: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-1=233]}
2023-03-04 00:26:24 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 1 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=43): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=1, errorCode=0, baseOffset=10, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:26:24 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-1 to 10
2023-03-04 00:26:24 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:26:34 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text in a sed Spring quis metus sending to kafka topic twitter-topic
2023-03-04 00:26:34 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 8255292865325962301, "id": 6113451468221456404, "text": "in a sed Spring quis metus", "createdAt": 1677876994000}' to topic = 'twitter-topic'
2023-03-04 00:26:34 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:26:34 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 8 being sent to partition twitter-topic-0
2023-03-04 00:26:34 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=44) and timeout 60000 to node 2: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-0=160]}
2023-03-04 00:26:34 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 2 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=44): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=0, errorCode=0, baseOffset=8, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:26:34 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-0 to 8
2023-03-04 00:26:34 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:26:44 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text tempor feugiat arcu metus non Microservices ullamcorper tempor dictum sending to kafka topic twitter-topic
2023-03-04 00:26:44 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 2909317377154901219, "id": 534567609602632171, "text": "tempor feugiat arcu metus non Microservices ullamcorper tempor dictum", "createdAt": 1677877004000}' to topic = 'twitter-topic'
2023-03-04 00:26:44 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:26:44 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 9 being sent to partition twitter-topic-0
2023-03-04 00:26:44 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=45) and timeout 60000 to node 2: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-0=199]}
2023-03-04 00:26:44 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 2 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=45): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=0, errorCode=0, baseOffset=9, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:26:44 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-0 to 9
2023-03-04 00:26:44 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:26:54 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text a non in in at ullamcorper Java ante commodo dictum a sending to kafka topic twitter-topic
2023-03-04 00:26:54 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 452524240895669866, "id": 640939326247019541, "text": "a non in in at ullamcorper Java ante commodo dictum a", "createdAt": 1677877014000}' to topic = 'twitter-topic'
2023-03-04 00:26:54 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:26:54 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 12 being sent to partition twitter-topic-2
2023-03-04 00:26:54 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=46) and timeout 60000 to node 3: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-2=182]}
2023-03-04 00:26:54 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 3 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=46): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=2, errorCode=0, baseOffset=12, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:26:54 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-2 to 12
2023-03-04 00:26:54 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:27:04 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text odio in in a lacus non ullamcorper Spring dictum arcu non sed at at sending to kafka topic twitter-topic
2023-03-04 00:27:04 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 3903433350582071236, "id": 7865948839346083748, "text": "odio in in a lacus non ullamcorper Spring dictum arcu non sed at at", "createdAt": 1677877024000}' to topic = 'twitter-topic'
2023-03-04 00:27:04 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:27:04 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 11 being sent to partition twitter-topic-1
2023-03-04 00:27:04 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=47) and timeout 60000 to node 1: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-1=200]}
2023-03-04 00:27:04 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 1 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=47): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=1, errorCode=0, baseOffset=11, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:27:04 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-1 to 11
2023-03-04 00:27:04 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:27:14 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text lacus ante metus tempor a feugiat at sed Elasticsearch metus at lacinia commodo ullamcorper commodo sending to kafka topic twitter-topic
2023-03-04 00:27:14 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 6651579040097512602, "id": 7025585831032278117, "text": "lacus ante metus tempor a feugiat at sed Elasticsearch metus at lacinia commodo ullamcorper commodo", "createdAt": 1677877034000}' to topic = 'twitter-topic'
2023-03-04 00:27:14 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:27:14 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 12 being sent to partition twitter-topic-1
2023-03-04 00:27:14 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=48) and timeout 60000 to node 1: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-1=229]}
2023-03-04 00:27:14 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 1 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=48): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=1, errorCode=0, baseOffset=12, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:27:14 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-1 to 12
2023-03-04 00:27:14 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:27:24 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text tempor vestibulum ullamcorper ullamcorper vestibulum Kafka odio vestibulum quis sending to kafka topic twitter-topic
2023-03-04 00:27:24 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 321266408365333234, "id": 8735180795971549882, "text": "tempor vestibulum ullamcorper ullamcorper vestibulum Kafka odio vestibulum quis", "createdAt": 1677877044000}' to topic = 'twitter-topic'
2023-03-04 00:27:24 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:27:24 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 10 being sent to partition twitter-topic-0
2023-03-04 00:27:24 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=49) and timeout 60000 to node 2: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-0=195]}
2023-03-04 00:27:24 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 2 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=49): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=0, errorCode=0, baseOffset=10, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:27:24 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-0 to 10
2023-03-04 00:27:24 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:27:34 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text arcu ante odio at ante Elasticsearch in non feugiat at sending to kafka topic twitter-topic
2023-03-04 00:27:34 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 6822738806494816172, "id": 8239812454796462087, "text": "arcu ante odio at ante Elasticsearch in non feugiat at", "createdAt": 1677877054000}' to topic = 'twitter-topic'
2023-03-04 00:27:34 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:27:34 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 11 being sent to partition twitter-topic-0
2023-03-04 00:27:34 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=50) and timeout 60000 to node 2: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-0=184]}
2023-03-04 00:27:34 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 2 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=50): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=0, errorCode=0, baseOffset=11, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:27:34 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-0 to 11
2023-03-04 00:27:34 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:27:44 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text commodo lacinia feugiat euismod odio lacus in Elasticsearch vestibulum feugiat sed quis vestibulum dictum sending to kafka topic twitter-topic
2023-03-04 00:27:44 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 6409031806044600299, "id": 2184519584742948301, "text": "commodo lacinia feugiat euismod odio lacus in Elasticsearch vestibulum feugiat sed quis vestibulum dictum", "createdAt": 1677877064000}' to topic = 'twitter-topic'
2023-03-04 00:27:44 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:27:44 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 12 being sent to partition twitter-topic-0
2023-03-04 00:27:44 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=51) and timeout 60000 to node 2: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-0=223]}
2023-03-04 00:27:44 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 2 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=51): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=0, errorCode=0, baseOffset=12, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:27:44 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-0 to 12
2023-03-04 00:27:44 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:27:54 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text metus at vestibulum lacinia dictum lacus in ullamcorper Kafka feugiat feugiat euismod euismod odio arcu ullamcorper sending to kafka topic twitter-topic
2023-03-04 00:27:54 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 1968829909042522109, "id": 3764390152941379716, "text": "metus at vestibulum lacinia dictum lacus in ullamcorper Kafka feugiat feugiat euismod euismod odio arcu ullamcorper", "createdAt": 1677877074000}' to topic = 'twitter-topic'
2023-03-04 00:27:54 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:27:54 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 13 being sent to partition twitter-topic-2
2023-03-04 00:27:54 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=52) and timeout 60000 to node 3: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-2=238]}
2023-03-04 00:27:54 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 3 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=52): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=2, errorCode=0, baseOffset=13, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:27:54 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-2 to 13
2023-03-04 00:27:54 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:28:04 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text metus at ullamcorper feugiat at commodo Elasticsearch dictum odio vestibulum arcu ullamcorper sending to kafka topic twitter-topic
2023-03-04 00:28:04 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 1473211472722130969, "id": 3536493169137554036, "text": "metus at ullamcorper feugiat at commodo Elasticsearch dictum odio vestibulum arcu ullamcorper", "createdAt": 1677877084000}' to topic = 'twitter-topic'
2023-03-04 00:28:04 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:28:04 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 13 being sent to partition twitter-topic-1
2023-03-04 00:28:04 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=53) and timeout 60000 to node 1: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-1=228]}
2023-03-04 00:28:04 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 1 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=53): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=1, errorCode=0, baseOffset=13, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:28:04 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-1 to 13
2023-03-04 00:28:04 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:28:14 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text dictum at euismod at vestibulum arcu Spring a in metus lacinia sending to kafka topic twitter-topic
2023-03-04 00:28:14 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 1683724701844122800, "id": 2853729560950319101, "text": "dictum at euismod at vestibulum arcu Spring a in metus lacinia", "createdAt": 1677877094000}' to topic = 'twitter-topic'
2023-03-04 00:28:14 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:28:14 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 14 being sent to partition twitter-topic-2
2023-03-04 00:28:14 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=54) and timeout 60000 to node 3: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-2=191]}
2023-03-04 00:28:14 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 3 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=54): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=2, errorCode=0, baseOffset=14, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:28:14 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-2 to 14
2023-03-04 00:28:14 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:28:24 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text arcu dictum arcu at Kafka euismod non sending to kafka topic twitter-topic
2023-03-04 00:28:24 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 7535185619392506644, "id": 2083202031481333706, "text": "arcu dictum arcu at Kafka euismod non", "createdAt": 1677877104000}' to topic = 'twitter-topic'
2023-03-04 00:28:24 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:28:24 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 14 being sent to partition twitter-topic-1
2023-03-04 00:28:24 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=55) and timeout 60000 to node 1: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-1=167]}
2023-03-04 00:28:24 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 1 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=55): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=1, errorCode=0, baseOffset=14, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:28:24 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-1 to 14
2023-03-04 00:28:24 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:28:34 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text a lacinia dictum commodo non metus Microservices sed euismod ullamcorper odio sending to kafka topic twitter-topic
2023-03-04 00:28:34 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 6021924274397806786, "id": 8332193671467555576, "text": "a lacinia dictum commodo non metus Microservices sed euismod ullamcorper odio", "createdAt": 1677877114000}' to topic = 'twitter-topic'
2023-03-04 00:28:34 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:28:34 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 13 being sent to partition twitter-topic-0
2023-03-04 00:28:34 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=56) and timeout 60000 to node 2: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-0=213]}
2023-03-04 00:28:34 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 2 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=56): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=0, errorCode=0, baseOffset=13, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:28:34 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-0 to 13
2023-03-04 00:28:34 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:28:44 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text a commodo euismod tempor Microservices odio tempor lacinia sending to kafka topic twitter-topic
2023-03-04 00:28:44 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 5983274453753337601, "id": 5329911946701913564, "text": "a commodo euismod tempor Microservices odio tempor lacinia", "createdAt": 1677877124000}' to topic = 'twitter-topic'
2023-03-04 00:28:44 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:28:44 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 15 being sent to partition twitter-topic-1
2023-03-04 00:28:44 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=57) and timeout 60000 to node 1: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-1=191]}
2023-03-04 00:28:44 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 1 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=57): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=1, errorCode=0, baseOffset=15, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:28:44 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-1 to 15
2023-03-04 00:28:44 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:28:54 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text lacus arcu metus vestibulum quis at tempor lacus Microservices non ante ullamcorper tempor at vestibulum lacus sending to kafka topic twitter-topic
2023-03-04 00:28:54 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 5301541212603178171, "id": 7347767463762424480, "text": "lacus arcu metus vestibulum quis at tempor lacus Microservices non ante ullamcorper tempor at vestibulum lacus", "createdAt": 1677877134000}' to topic = 'twitter-topic'
2023-03-04 00:28:54 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:28:54 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 16 being sent to partition twitter-topic-1
2023-03-04 00:28:54 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=58) and timeout 60000 to node 1: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-1=231]}
2023-03-04 00:28:54 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 1 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=58): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=1, errorCode=0, baseOffset=16, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:28:54 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-1 to 16
2023-03-04 00:28:54 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:29:04 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text commodo non metus euismod odio Spring non lacinia lacinia sending to kafka topic twitter-topic
2023-03-04 00:29:04 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 6304397994702740627, "id": 7619106187956364791, "text": "commodo non metus euismod odio Spring non lacinia lacinia", "createdAt": 1677877144000}' to topic = 'twitter-topic'
2023-03-04 00:29:04 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:29:04 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 15 being sent to partition twitter-topic-2
2023-03-04 00:29:04 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=59) and timeout 60000 to node 3: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-2=192]}
2023-03-04 00:29:04 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 3 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=59): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=2, errorCode=0, baseOffset=15, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:29:04 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-2 to 15
2023-03-04 00:29:04 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:29:14 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text non dictum tempor non ante non metus vestibulum Java at metus ullamcorper arcu a arcu sending to kafka topic twitter-topic
2023-03-04 00:29:14 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 605323692985563524, "id": 6014954193815357040, "text": "non dictum tempor non ante non metus vestibulum Java at metus ullamcorper arcu a arcu", "createdAt": 1677877154000}' to topic = 'twitter-topic'
2023-03-04 00:29:14 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:29:14 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 17 being sent to partition twitter-topic-1
2023-03-04 00:29:14 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=60) and timeout 60000 to node 1: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-1=215]}
2023-03-04 00:29:14 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 1 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=60): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=1, errorCode=0, baseOffset=17, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:29:14 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-1 to 17
2023-03-04 00:29:14 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:29:24 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text euismod commodo tempor Spring feugiat at sending to kafka topic twitter-topic
2023-03-04 00:29:24 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 7754765283173036681, "id": 5914884936959311165, "text": "euismod commodo tempor Spring feugiat at", "createdAt": 1677877164000}' to topic = 'twitter-topic'
2023-03-04 00:29:24 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:29:24 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 16 being sent to partition twitter-topic-2
2023-03-04 00:29:24 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=61) and timeout 60000 to node 3: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-2=174]}
2023-03-04 00:29:24 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 3 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=61): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=2, errorCode=0, baseOffset=16, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:29:24 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-2 to 16
2023-03-04 00:29:24 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:29:34 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text arcu sed lacinia in metus Kafka metus dictum metus ante sending to kafka topic twitter-topic
2023-03-04 00:29:34 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 2169252206019726631, "id": 6240543563339518556, "text": "arcu sed lacinia in metus Kafka metus dictum metus ante", "createdAt": 1677877174000}' to topic = 'twitter-topic'
2023-03-04 00:29:34 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:29:34 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 17 being sent to partition twitter-topic-2
2023-03-04 00:29:34 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=62) and timeout 60000 to node 3: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-2=181]}
2023-03-04 00:29:34 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 3 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=62): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=2, errorCode=0, baseOffset=17, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:29:34 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-2 to 17
2023-03-04 00:29:34 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:29:44 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text euismod dictum a euismod sed lacus Elasticsearch vestibulum at ullamcorper arcu sending to kafka topic twitter-topic
2023-03-04 00:29:44 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 1894505763901629635, "id": 8376100766578940629, "text": "euismod dictum a euismod sed lacus Elasticsearch vestibulum at ullamcorper arcu", "createdAt": 1677877184000}' to topic = 'twitter-topic'
2023-03-04 00:29:44 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:29:44 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 14 being sent to partition twitter-topic-0
2023-03-04 00:29:44 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=63) and timeout 60000 to node 2: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-0=215]}
2023-03-04 00:29:44 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 2 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=63): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=0, errorCode=0, baseOffset=14, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:29:44 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-0 to 14
2023-03-04 00:29:44 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:29:54 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text in metus arcu Kafka metus quis sending to kafka topic twitter-topic
2023-03-04 00:29:54 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 447254648091233578, "id": 8492118804300512298, "text": "in metus arcu Kafka metus quis", "createdAt": 1677877194000}' to topic = 'twitter-topic'
2023-03-04 00:29:54 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:29:54 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 18 being sent to partition twitter-topic-2
2023-03-04 00:29:54 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=64) and timeout 60000 to node 3: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-2=163]}
2023-03-04 00:29:54 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 3 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=64): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=2, errorCode=0, baseOffset=18, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:29:54 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-2 to 18
2023-03-04 00:29:54 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:30:04 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text sed tempor a metus sed euismod arcu Microservices lacus euismod metus a sed sending to kafka topic twitter-topic
2023-03-04 00:30:04 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 8948305619698871999, "id": 8183162880204757810, "text": "sed tempor a metus sed euismod arcu Microservices lacus euismod metus a sed", "createdAt": 1677877204000}' to topic = 'twitter-topic'
2023-03-04 00:30:04 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:30:04 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 18 being sent to partition twitter-topic-1
2023-03-04 00:30:04 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=65) and timeout 60000 to node 1: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-1=210]}
2023-03-04 00:30:04 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 1 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=65): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=1, errorCode=0, baseOffset=18, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:30:04 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-1 to 18
2023-03-04 00:30:04 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:30:14 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text non lacus lacus sed Spring feugiat ullamcorper sending to kafka topic twitter-topic
2023-03-04 00:30:14 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 7448044732295147975, "id": 4838395001024782529, "text": "non lacus lacus sed Spring feugiat ullamcorper", "createdAt": 1677877214000}' to topic = 'twitter-topic'
2023-03-04 00:30:14 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:30:14 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 19 being sent to partition twitter-topic-2
2023-03-04 00:30:14 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=66) and timeout 60000 to node 3: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-2=175]}
2023-03-04 00:30:14 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 3 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=66): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=2, errorCode=0, baseOffset=19, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:30:14 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-2 to 19
2023-03-04 00:30:14 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:30:24 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text at lacinia tempor dictum vestibulum quis Spring ullamcorper commodo a tempor sending to kafka topic twitter-topic
2023-03-04 00:30:24 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 3467686249352947687, "id": 4729625349373742080, "text": "at lacinia tempor dictum vestibulum quis Spring ullamcorper commodo a tempor", "createdAt": 1677877224000}' to topic = 'twitter-topic'
2023-03-04 00:30:24 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:30:24 [kafka-producer-network-thread | producer-1] INFO  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Node -1 disconnected.
2023-03-04 00:30:24 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending metadata request MetadataRequestData(topics=[MetadataRequestTopic(topicId=AAAAAAAAAAAAAAAAAAAAAA, name='twitter-topic')], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to node localhost:29092 (id: 2 rack: null)
2023-03-04 00:30:24 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending METADATA request with header RequestHeader(apiKey=METADATA, apiVersion=6, clientId=producer-1, correlationId=67) and timeout 60000 to node 2: MetadataRequestData(topics=[MetadataRequestTopic(topicId=AAAAAAAAAAAAAAAAAAAAAA, name='twitter-topic')], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false)
2023-03-04 00:30:24 [kafka-producer-network-thread | producer-1] INFO  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Node -3 disconnected.
2023-03-04 00:30:24 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 20 being sent to partition twitter-topic-2
2023-03-04 00:30:24 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=68) and timeout 60000 to node 3: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-2=210]}
2023-03-04 00:30:24 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received METADATA response from node 2 for request with header RequestHeader(apiKey=METADATA, apiVersion=6, clientId=producer-1, correlationId=67): MetadataResponseData(throttleTimeMs=0, brokers=[MetadataResponseBroker(nodeId=2, host='localhost', port=29092, rack=null), MetadataResponseBroker(nodeId=1, host='localhost', port=19092, rack=null), MetadataResponseBroker(nodeId=3, host='localhost', port=39092, rack=null)], clusterId='QGDYypu5SSGtA9Bc36Rjow', controllerId=3, topics=[MetadataResponseTopic(errorCode=0, name='twitter-topic', topicId=AAAAAAAAAAAAAAAAAAAAAA, isInternal=false, partitions=[MetadataResponsePartition(errorCode=0, partitionIndex=2, leaderId=3, leaderEpoch=-1, replicaNodes=[3, 2, 1], isrNodes=[3, 2, 1], offlineReplicas=[]), MetadataResponsePartition(errorCode=0, partitionIndex=1, leaderId=1, leaderEpoch=-1, replicaNodes=[1, 3, 2], isrNodes=[1, 3, 2], offlineReplicas=[]), MetadataResponsePartition(errorCode=0, partitionIndex=0, leaderId=2, leaderEpoch=-1, replicaNodes=[2, 1, 3], isrNodes=[2, 1, 3], offlineReplicas=[])], topicAuthorizedOperations=-2147483648)], clusterAuthorizedOperations=-2147483648)
2023-03-04 00:30:24 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Updated cluster metadata updateVersion 4 to MetadataCache{clusterId='QGDYypu5SSGtA9Bc36Rjow', nodes={1=localhost:19092 (id: 1 rack: null), 2=localhost:29092 (id: 2 rack: null), 3=localhost:39092 (id: 3 rack: null)}, partitions=[PartitionMetadata(error=NONE, partition=twitter-topic-0, leader=Optional[2], leaderEpoch=Optional.empty, replicas=2,1,3, isr=2,1,3, offlineReplicas=), PartitionMetadata(error=NONE, partition=twitter-topic-1, leader=Optional[1], leaderEpoch=Optional.empty, replicas=1,3,2, isr=1,3,2, offlineReplicas=), PartitionMetadata(error=NONE, partition=twitter-topic-2, leader=Optional[3], leaderEpoch=Optional.empty, replicas=3,2,1, isr=3,2,1, offlineReplicas=)], controller=localhost:39092 (id: 3 rack: null)}
2023-03-04 00:30:24 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 3 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=68): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=2, errorCode=0, baseOffset=20, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:30:24 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-2 to 20
2023-03-04 00:30:24 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:30:34 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text quis feugiat in sed odio Kafka metus metus arcu sending to kafka topic twitter-topic
2023-03-04 00:30:34 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 5361917782063933200, "id": 4402593627230717499, "text": "quis feugiat in sed odio Kafka metus metus arcu", "createdAt": 1677877234000}' to topic = 'twitter-topic'
2023-03-04 00:30:34 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:30:34 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 19 being sent to partition twitter-topic-1
2023-03-04 00:30:34 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=69) and timeout 60000 to node 1: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-1=175]}
2023-03-04 00:30:34 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 1 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=69): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=1, errorCode=0, baseOffset=19, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:30:34 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-1 to 19
2023-03-04 00:30:34 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:30:44 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text sed feugiat in metus lacinia Spring non arcu arcu vestibulum sending to kafka topic twitter-topic
2023-03-04 00:30:44 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 3865590324436348243, "id": 7404805897935266666, "text": "sed feugiat in metus lacinia Spring non arcu arcu vestibulum", "createdAt": 1677877244000}' to topic = 'twitter-topic'
2023-03-04 00:30:44 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:30:44 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 20 being sent to partition twitter-topic-1
2023-03-04 00:30:44 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=70) and timeout 60000 to node 1: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-1=191]}
2023-03-04 00:30:44 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 1 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=70): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=1, errorCode=0, baseOffset=20, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:30:44 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-1 to 20
2023-03-04 00:30:44 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:30:54 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text ante euismod tempor feugiat quis Spring tempor at odio vestibulum sending to kafka topic twitter-topic
2023-03-04 00:30:54 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 4045533471814736881, "id": 955255595040177029, "text": "ante euismod tempor feugiat quis Spring tempor at odio vestibulum", "createdAt": 1677877254000}' to topic = 'twitter-topic'
2023-03-04 00:30:54 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:30:54 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 15 being sent to partition twitter-topic-0
2023-03-04 00:30:54 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=71) and timeout 60000 to node 2: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-0=198]}
2023-03-04 00:30:54 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 2 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=71): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=0, errorCode=0, baseOffset=15, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:30:54 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-0 to 15
2023-03-04 00:30:54 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:31:04 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text lacinia vestibulum non Kafka lacinia feugiat sending to kafka topic twitter-topic
2023-03-04 00:31:04 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 854935813471337744, "id": 3895721726891767395, "text": "lacinia vestibulum non Kafka lacinia feugiat", "createdAt": 1677877264000}' to topic = 'twitter-topic'
2023-03-04 00:31:04 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:31:04 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 16 being sent to partition twitter-topic-0
2023-03-04 00:31:04 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=72) and timeout 60000 to node 2: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-0=170]}
2023-03-04 00:31:04 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 2 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=72): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=0, errorCode=0, baseOffset=16, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:31:04 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-0 to 16
2023-03-04 00:31:04 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:31:14 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text vestibulum lacinia at non in euismod ullamcorper Kafka sed vestibulum quis arcu a sending to kafka topic twitter-topic
2023-03-04 00:31:14 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 8957218319462882919, "id": 8767972409909555265, "text": "vestibulum lacinia at non in euismod ullamcorper Kafka sed vestibulum quis arcu a", "createdAt": 1677877274000}' to topic = 'twitter-topic'
2023-03-04 00:31:14 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:31:14 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 21 being sent to partition twitter-topic-1
2023-03-04 00:31:14 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=73) and timeout 60000 to node 1: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-1=213]}
2023-03-04 00:31:14 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 1 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=73): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=1, errorCode=0, baseOffset=21, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:31:14 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-1 to 21
2023-03-04 00:31:14 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:31:21 [kafka-admin-client-thread | adminclient-1] INFO  o.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Node 3 disconnected.
2023-03-04 00:31:21 [kafka-admin-client-thread | adminclient-1] DEBUG o.a.k.c.a.i.AdminMetadataManager - [AdminClient clientId=adminclient-1] Requesting metadata update.
2023-03-04 00:31:21 [kafka-admin-client-thread | adminclient-1] DEBUG o.apache.kafka.clients.ClientUtils - Resolved host localhost as 127.0.0.1
2023-03-04 00:31:21 [kafka-admin-client-thread | adminclient-1] DEBUG o.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Initiating connection to node localhost:29092 (id: 2 rack: null) using address localhost/127.0.0.1
2023-03-04 00:31:21 [kafka-admin-client-thread | adminclient-1] DEBUG o.a.kafka.common.network.Selector - [AdminClient clientId=adminclient-1] Created socket with SO_RCVBUF = 342972, SO_SNDBUF = 146988, SO_TIMEOUT = 0 to node 2
2023-03-04 00:31:21 [kafka-admin-client-thread | adminclient-1] DEBUG o.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Completed connection to node 2. Fetching API versions.
2023-03-04 00:31:21 [kafka-admin-client-thread | adminclient-1] DEBUG o.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Initiating API versions fetch from node 2.
2023-03-04 00:31:21 [kafka-admin-client-thread | adminclient-1] DEBUG o.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Sending API_VERSIONS request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=adminclient-1, correlationId=8) and timeout 3600000 to node 2: ApiVersionsRequestData(clientSoftwareName='apache-kafka-java', clientSoftwareVersion='3.3.2')
2023-03-04 00:31:21 [kafka-admin-client-thread | adminclient-1] DEBUG o.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Received API_VERSIONS response from node 2 for request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=adminclient-1, correlationId=8): ApiVersionsResponseData(errorCode=35, apiKeys=[], throttleTimeMs=0, supportedFeatures=[], finalizedFeaturesEpoch=-1, finalizedFeatures=[])
2023-03-04 00:31:21 [kafka-admin-client-thread | adminclient-1] DEBUG o.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Initiating API versions fetch from node 2.
2023-03-04 00:31:21 [kafka-admin-client-thread | adminclient-1] DEBUG o.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Sending API_VERSIONS request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=0, clientId=adminclient-1, correlationId=9) and timeout 3600000 to node 2: ApiVersionsRequestData(clientSoftwareName='apache-kafka-java', clientSoftwareVersion='3.3.2')
2023-03-04 00:31:21 [kafka-admin-client-thread | adminclient-1] DEBUG o.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Received API_VERSIONS response from node 2 for request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=0, clientId=adminclient-1, correlationId=9): ApiVersionsResponseData(errorCode=0, apiKeys=[ApiVersion(apiKey=0, minVersion=0, maxVersion=6), ApiVersion(apiKey=1, minVersion=0, maxVersion=8), ApiVersion(apiKey=2, minVersion=0, maxVersion=3), ApiVersion(apiKey=3, minVersion=0, maxVersion=6), ApiVersion(apiKey=4, minVersion=0, maxVersion=1), ApiVersion(apiKey=5, minVersion=0, maxVersion=0), ApiVersion(apiKey=6, minVersion=0, maxVersion=4), ApiVersion(apiKey=7, minVersion=0, maxVersion=1), ApiVersion(apiKey=8, minVersion=0, maxVersion=4), ApiVersion(apiKey=9, minVersion=0, maxVersion=4), ApiVersion(apiKey=10, minVersion=0, maxVersion=2), ApiVersion(apiKey=11, minVersion=0, maxVersion=3), ApiVersion(apiKey=12, minVersion=0, maxVersion=2), ApiVersion(apiKey=13, minVersion=0, maxVersion=2), ApiVersion(apiKey=14, minVersion=0, maxVersion=2), ApiVersion(apiKey=15, minVersion=0, maxVersion=2), ApiVersion(apiKey=16, minVersion=0, maxVersion=2), ApiVersion(apiKey=17, minVersion=0, maxVersion=1), ApiVersion(apiKey=18, minVersion=0, maxVersion=2), ApiVersion(apiKey=19, minVersion=0, maxVersion=3), ApiVersion(apiKey=20, minVersion=0, maxVersion=2), ApiVersion(apiKey=21, minVersion=0, maxVersion=1), ApiVersion(apiKey=22, minVersion=0, maxVersion=1), ApiVersion(apiKey=23, minVersion=0, maxVersion=1), ApiVersion(apiKey=24, minVersion=0, maxVersion=1), ApiVersion(apiKey=25, minVersion=0, maxVersion=1), ApiVersion(apiKey=26, minVersion=0, maxVersion=1), ApiVersion(apiKey=27, minVersion=0, maxVersion=0), ApiVersion(apiKey=28, minVersion=0, maxVersion=1), ApiVersion(apiKey=29, minVersion=0, maxVersion=1), ApiVersion(apiKey=30, minVersion=0, maxVersion=1), ApiVersion(apiKey=31, minVersion=0, maxVersion=1), ApiVersion(apiKey=32, minVersion=0, maxVersion=2), ApiVersion(apiKey=33, minVersion=0, maxVersion=1), ApiVersion(apiKey=34, minVersion=0, maxVersion=1), ApiVersion(apiKey=35, minVersion=0, maxVersion=1), ApiVersion(apiKey=36, minVersion=0, maxVersion=0), ApiVersion(apiKey=37, minVersion=0, maxVersion=1), ApiVersion(apiKey=38, minVersion=0, maxVersion=1), ApiVersion(apiKey=39, minVersion=0, maxVersion=1), ApiVersion(apiKey=40, minVersion=0, maxVersion=1), ApiVersion(apiKey=41, minVersion=0, maxVersion=1), ApiVersion(apiKey=42, minVersion=0, maxVersion=1)], throttleTimeMs=0, supportedFeatures=[], finalizedFeaturesEpoch=-1, finalizedFeatures=[])
2023-03-04 00:31:21 [kafka-admin-client-thread | adminclient-1] DEBUG o.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Node 2 has finalized features epoch: -1, finalized features: [], supported features: [], API versions: (Produce(0): 0 to 6 [usable: 6], Fetch(1): 0 to 8 [usable: 8], ListOffsets(2): 0 to 3 [usable: 3], Metadata(3): 0 to 6 [usable: 6], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 4 [usable: 4], OffsetFetch(9): 0 to 4 [usable: 4], FindCoordinator(10): 0 to 2 [usable: 2], JoinGroup(11): 0 to 3 [usable: 3], Heartbeat(12): 0 to 2 [usable: 2], LeaveGroup(13): 0 to 2 [usable: 2], SyncGroup(14): 0 to 2 [usable: 2], DescribeGroups(15): 0 to 2 [usable: 2], ListGroups(16): 0 to 2 [usable: 2], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 2], CreateTopics(19): 0 to 3 [usable: 3], DeleteTopics(20): 0 to 2 [usable: 2], DeleteRecords(21): 0 to 1 [usable: 1], InitProducerId(22): 0 to 1 [usable: 1], OffsetForLeaderEpoch(23): 0 to 1 [usable: 1], AddPartitionsToTxn(24): 0 to 1 [usable: 1], AddOffsetsToTxn(25): 0 to 1 [usable: 1], EndTxn(26): 0 to 1 [usable: 1], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 1 [usable: 1], DescribeAcls(29): 0 to 1 [usable: 1], CreateAcls(30): 0 to 1 [usable: 1], DeleteAcls(31): 0 to 1 [usable: 1], DescribeConfigs(32): 0 to 2 [usable: 2], AlterConfigs(33): 0 to 1 [usable: 1], AlterReplicaLogDirs(34): 0 to 1 [usable: 1], DescribeLogDirs(35): 0 to 1 [usable: 1], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 1], CreateDelegationToken(38): 0 to 1 [usable: 1], RenewDelegationToken(39): 0 to 1 [usable: 1], ExpireDelegationToken(40): 0 to 1 [usable: 1], DescribeDelegationToken(41): 0 to 1 [usable: 1], DeleteGroups(42): 0 to 1 [usable: 1], ElectLeaders(43): UNSUPPORTED, IncrementalAlterConfigs(44): UNSUPPORTED, AlterPartitionReassignments(45): UNSUPPORTED, ListPartitionReassignments(46): UNSUPPORTED, OffsetDelete(47): UNSUPPORTED, DescribeClientQuotas(48): UNSUPPORTED, AlterClientQuotas(49): UNSUPPORTED, DescribeUserScramCredentials(50): UNSUPPORTED, AlterUserScramCredentials(51): UNSUPPORTED, AlterPartition(56): UNSUPPORTED, UpdateFeatures(57): UNSUPPORTED, DescribeCluster(60): UNSUPPORTED, DescribeProducers(61): UNSUPPORTED, DescribeTransactions(65): UNSUPPORTED, ListTransactions(66): UNSUPPORTED, AllocateProducerIds(67): UNSUPPORTED).
2023-03-04 00:31:21 [kafka-admin-client-thread | adminclient-1] DEBUG o.a.k.clients.admin.KafkaAdminClient - [AdminClient clientId=adminclient-1] Sending MetadataRequestData(topics=[], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to localhost:29092 (id: 2 rack: null). correlationId=10, timeoutMs=29980
2023-03-04 00:31:21 [kafka-admin-client-thread | adminclient-1] DEBUG o.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Sending METADATA request with header RequestHeader(apiKey=METADATA, apiVersion=6, clientId=adminclient-1, correlationId=10) and timeout 29980 to node 2: MetadataRequestData(topics=[], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false)
2023-03-04 00:31:21 [kafka-admin-client-thread | adminclient-1] DEBUG o.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Received METADATA response from node 2 for request with header RequestHeader(apiKey=METADATA, apiVersion=6, clientId=adminclient-1, correlationId=10): MetadataResponseData(throttleTimeMs=0, brokers=[MetadataResponseBroker(nodeId=2, host='localhost', port=29092, rack=null), MetadataResponseBroker(nodeId=1, host='localhost', port=19092, rack=null), MetadataResponseBroker(nodeId=3, host='localhost', port=39092, rack=null)], clusterId='QGDYypu5SSGtA9Bc36Rjow', controllerId=3, topics=[], clusterAuthorizedOperations=-2147483648)
2023-03-04 00:31:21 [kafka-admin-client-thread | adminclient-1] DEBUG o.a.k.c.a.i.AdminMetadataManager - [AdminClient clientId=adminclient-1] Updating cluster metadata to Cluster(id = QGDYypu5SSGtA9Bc36Rjow, nodes = [localhost:39092 (id: 3 rack: null), localhost:19092 (id: 1 rack: null), localhost:29092 (id: 2 rack: null)], partitions = [], controller = localhost:39092 (id: 3 rack: null))
2023-03-04 00:31:24 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text metus odio arcu feugiat quis Spring dictum commodo quis metus sending to kafka topic twitter-topic
2023-03-04 00:31:24 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 6804419321142216931, "id": 4511053147876726213, "text": "metus odio arcu feugiat quis Spring dictum commodo quis metus", "createdAt": 1677877284000}' to topic = 'twitter-topic'
2023-03-04 00:31:24 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:31:24 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 17 being sent to partition twitter-topic-0
2023-03-04 00:31:24 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=74) and timeout 60000 to node 2: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-0=192]}
2023-03-04 00:31:24 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 2 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=74): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=0, errorCode=0, baseOffset=17, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:31:24 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-0 to 17
2023-03-04 00:31:24 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:31:34 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text arcu in at ullamcorper at arcu commodo Elasticsearch odio in vestibulum at at dictum sending to kafka topic twitter-topic
2023-03-04 00:31:34 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 2826117467494341282, "id": 6094092141324705426, "text": "arcu in at ullamcorper at arcu commodo Elasticsearch odio in vestibulum at at dictum", "createdAt": 1677877294000}' to topic = 'twitter-topic'
2023-03-04 00:31:34 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:31:34 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 18 being sent to partition twitter-topic-0
2023-03-04 00:31:34 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=75) and timeout 60000 to node 2: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-0=218]}
2023-03-04 00:31:34 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 2 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=75): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=0, errorCode=0, baseOffset=18, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:31:34 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-0 to 18
2023-03-04 00:31:34 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:31:44 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text dictum commodo lacinia ullamcorper ante ullamcorper lacinia Kafka dictum arcu ullamcorper euismod lacus sending to kafka topic twitter-topic
2023-03-04 00:31:44 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 8356364386968560667, "id": 9161016555797513464, "text": "dictum commodo lacinia ullamcorper ante ullamcorper lacinia Kafka dictum arcu ullamcorper euismod lacus", "createdAt": 1677877304000}' to topic = 'twitter-topic'
2023-03-04 00:31:44 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:31:44 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 22 being sent to partition twitter-topic-1
2023-03-04 00:31:44 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=76) and timeout 60000 to node 1: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-1=217]}
2023-03-04 00:31:44 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 1 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=76): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=1, errorCode=0, baseOffset=22, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:31:44 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-1 to 22
2023-03-04 00:31:44 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:31:54 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text a tempor lacus tempor Elasticsearch non commodo sending to kafka topic twitter-topic
2023-03-04 00:31:54 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 720121426635760499, "id": 6763009059894079, "text": "a tempor lacus tempor Elasticsearch non commodo", "createdAt": 1677877314000}' to topic = 'twitter-topic'
2023-03-04 00:31:54 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:31:54 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 19 being sent to partition twitter-topic-0
2023-03-04 00:31:54 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=77) and timeout 60000 to node 2: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-0=172]}
2023-03-04 00:31:54 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 2 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=77): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=0, errorCode=0, baseOffset=19, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:31:54 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-0 to 19
2023-03-04 00:31:54 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:32:04 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text at lacinia in euismod in ante quis Microservices ullamcorper metus metus non tempor quis sending to kafka topic twitter-topic
2023-03-04 00:32:04 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 2850942808145018573, "id": 3781246315903019913, "text": "at lacinia in euismod in ante quis Microservices ullamcorper metus metus non tempor quis", "createdAt": 1677877324000}' to topic = 'twitter-topic'
2023-03-04 00:32:04 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:32:04 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 21 being sent to partition twitter-topic-2
2023-03-04 00:32:04 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=78) and timeout 60000 to node 3: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-2=223]}
2023-03-04 00:32:04 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 3 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=78): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=2, errorCode=0, baseOffset=21, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:32:04 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-2 to 21
2023-03-04 00:32:04 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:32:14 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text euismod metus quis lacus lacus vestibulum euismod Kafka non euismod sed vestibulum dictum sending to kafka topic twitter-topic
2023-03-04 00:32:14 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 8143265704330677491, "id": 215468086068468362, "text": "euismod metus quis lacus lacus vestibulum euismod Kafka non euismod sed vestibulum dictum", "createdAt": 1677877334000}' to topic = 'twitter-topic'
2023-03-04 00:32:14 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:32:14 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 22 being sent to partition twitter-topic-2
2023-03-04 00:32:14 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=79) and timeout 60000 to node 3: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-2=211]}
2023-03-04 00:32:14 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 3 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=79): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=2, errorCode=0, baseOffset=22, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:32:14 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-2 to 22
2023-03-04 00:32:14 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:32:24 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text feugiat a metus quis Kafka odio lacus quis sending to kafka topic twitter-topic
2023-03-04 00:32:24 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 1205113499803940004, "id": 8499655082666999722, "text": "feugiat a metus quis Kafka odio lacus quis", "createdAt": 1677877344000}' to topic = 'twitter-topic'
2023-03-04 00:32:24 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:32:24 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 23 being sent to partition twitter-topic-1
2023-03-04 00:32:24 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=80) and timeout 60000 to node 1: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-1=175]}
2023-03-04 00:32:24 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 1 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=80): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=1, errorCode=0, baseOffset=23, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:32:24 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-1 to 23
2023-03-04 00:32:24 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:32:34 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text metus odio commodo lacus ullamcorper Java dictum in at non sending to kafka topic twitter-topic
2023-03-04 00:32:34 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 3887090792310453497, "id": 7318853428251109680, "text": "metus odio commodo lacus ullamcorper Java dictum in at non", "createdAt": 1677877354000}' to topic = 'twitter-topic'
2023-03-04 00:32:34 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:32:34 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 23 being sent to partition twitter-topic-2
2023-03-04 00:32:34 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=81) and timeout 60000 to node 3: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-2=191]}
2023-03-04 00:32:34 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 3 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=81): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=2, errorCode=0, baseOffset=23, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:32:34 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-2 to 23
2023-03-04 00:32:34 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:32:44 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text dictum feugiat vestibulum ante dictum vestibulum quis euismod Elasticsearch at ullamcorper sed dictum metus commodo euismod sending to kafka topic twitter-topic
2023-03-04 00:32:44 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 3501744088166843842, "id": 3972960392801808258, "text": "dictum feugiat vestibulum ante dictum vestibulum quis euismod Elasticsearch at ullamcorper sed dictum metus commodo euismod", "createdAt": 1677877364000}' to topic = 'twitter-topic'
2023-03-04 00:32:44 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:32:44 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 20 being sent to partition twitter-topic-0
2023-03-04 00:32:44 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=82) and timeout 60000 to node 2: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-0=236]}
2023-03-04 00:32:44 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 2 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=82): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=0, errorCode=0, baseOffset=20, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:32:44 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-0 to 20
2023-03-04 00:32:44 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:32:54 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text at quis a vestibulum Elasticsearch arcu non at sending to kafka topic twitter-topic
2023-03-04 00:32:54 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 7204202028290524433, "id": 3686352456166028395, "text": "at quis a vestibulum Elasticsearch arcu non at", "createdAt": 1677877374000}' to topic = 'twitter-topic'
2023-03-04 00:32:54 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:32:54 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 24 being sent to partition twitter-topic-1
2023-03-04 00:32:54 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=83) and timeout 60000 to node 1: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-1=179]}
2023-03-04 00:32:54 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 1 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=83): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=1, errorCode=0, baseOffset=24, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:32:54 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-1 to 24
2023-03-04 00:32:54 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:33:04 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text lacinia tempor commodo sed Spring lacinia quis lacus sending to kafka topic twitter-topic
2023-03-04 00:33:04 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 1170987238994258574, "id": 2161703975687578170, "text": "lacinia tempor commodo sed Spring lacinia quis lacus", "createdAt": 1677877384000}' to topic = 'twitter-topic'
2023-03-04 00:33:04 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:33:04 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 24 being sent to partition twitter-topic-2
2023-03-04 00:33:04 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=84) and timeout 60000 to node 3: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-2=179]}
2023-03-04 00:33:04 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 3 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=84): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=2, errorCode=0, baseOffset=24, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:33:04 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-2 to 24
2023-03-04 00:33:04 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:33:14 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text metus dictum ante quis ante ullamcorper in Elasticsearch lacus euismod commodo odio metus sending to kafka topic twitter-topic
2023-03-04 00:33:14 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 793348635891892392, "id": 1193250127560922284, "text": "metus dictum ante quis ante ullamcorper in Elasticsearch lacus euismod commodo odio metus", "createdAt": 1677877394000}' to topic = 'twitter-topic'
2023-03-04 00:33:14 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:33:14 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 21 being sent to partition twitter-topic-0
2023-03-04 00:33:14 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=85) and timeout 60000 to node 2: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-0=223]}
2023-03-04 00:33:14 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 2 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=85): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=0, errorCode=0, baseOffset=21, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:33:14 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-0 to 21
2023-03-04 00:33:14 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:33:24 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text quis at lacinia in tempor Elasticsearch at non ullamcorper at sending to kafka topic twitter-topic
2023-03-04 00:33:24 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 51713989072709259, "id": 8544908883577647419, "text": "quis at lacinia in tempor Elasticsearch at non ullamcorper at", "createdAt": 1677877404000}' to topic = 'twitter-topic'
2023-03-04 00:33:24 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:33:24 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 25 being sent to partition twitter-topic-1
2023-03-04 00:33:24 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=86) and timeout 60000 to node 1: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-1=194]}
2023-03-04 00:33:24 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 1 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=86): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=1, errorCode=0, baseOffset=25, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:33:24 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-1 to 25
2023-03-04 00:33:24 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:33:34 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text feugiat lacinia lacus in sed vestibulum Microservices ullamcorper at in ante sending to kafka topic twitter-topic
2023-03-04 00:33:34 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 5686524308279478190, "id": 6493437708020779569, "text": "feugiat lacinia lacus in sed vestibulum Microservices ullamcorper at in ante", "createdAt": 1677877414000}' to topic = 'twitter-topic'
2023-03-04 00:33:34 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:33:34 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 26 being sent to partition twitter-topic-1
2023-03-04 00:33:34 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=87) and timeout 60000 to node 1: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-1=212]}
2023-03-04 00:33:34 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 1 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=87): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=1, errorCode=0, baseOffset=26, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:33:34 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-1 to 26
2023-03-04 00:33:34 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:33:44 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text non in lacus in odio ullamcorper Spring ullamcorper ante at commodo sending to kafka topic twitter-topic
2023-03-04 00:33:44 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 6880742108939540547, "id": 6953838970218807618, "text": "non in lacus in odio ullamcorper Spring ullamcorper ante at commodo", "createdAt": 1677877424000}' to topic = 'twitter-topic'
2023-03-04 00:33:44 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:33:44 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 27 being sent to partition twitter-topic-1
2023-03-04 00:33:44 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=88) and timeout 60000 to node 1: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-1=191]}
2023-03-04 00:33:44 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 1 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=88): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=1, errorCode=0, baseOffset=27, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:33:44 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-1 to 27
2023-03-04 00:33:44 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:33:54 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text non arcu quis odio sed Kafka at at dictum sending to kafka topic twitter-topic
2023-03-04 00:33:54 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 4300415604955479217, "id": 2227130089172612385, "text": "non arcu quis odio sed Kafka at at dictum", "createdAt": 1677877434000}' to topic = 'twitter-topic'
2023-03-04 00:33:54 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:33:54 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 28 being sent to partition twitter-topic-1
2023-03-04 00:33:54 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=89) and timeout 60000 to node 1: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-1=173]}
2023-03-04 00:33:54 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 1 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=89): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=1, errorCode=0, baseOffset=28, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:33:54 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-1 to 28
2023-03-04 00:33:54 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:34:04 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text in lacinia vestibulum dictum vestibulum Java quis lacinia quis commodo sending to kafka topic twitter-topic
2023-03-04 00:34:04 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 1055704884336597196, "id": 565494467606413464, "text": "in lacinia vestibulum dictum vestibulum Java quis lacinia quis commodo", "createdAt": 1677877444000}' to topic = 'twitter-topic'
2023-03-04 00:34:04 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:34:04 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 29 being sent to partition twitter-topic-1
2023-03-04 00:34:04 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=90) and timeout 60000 to node 1: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-1=185]}
2023-03-04 00:34:04 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 1 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=90): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=1, errorCode=0, baseOffset=29, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:34:04 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-1 to 29
2023-03-04 00:34:04 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:34:14 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text at euismod metus Elasticsearch at at sending to kafka topic twitter-topic
2023-03-04 00:34:14 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 3840173527467716734, "id": 6703559184918934861, "text": "at euismod metus Elasticsearch at at", "createdAt": 1677877454000}' to topic = 'twitter-topic'
2023-03-04 00:34:14 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:34:14 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 22 being sent to partition twitter-topic-0
2023-03-04 00:34:14 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=91) and timeout 60000 to node 2: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-0=169]}
2023-03-04 00:34:14 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 2 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=91): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=0, errorCode=0, baseOffset=22, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:34:14 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-0 to 22
2023-03-04 00:34:14 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:34:24 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text euismod commodo lacus vestibulum Elasticsearch ante quis euismod sending to kafka topic twitter-topic
2023-03-04 00:34:24 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 7912906370155052741, "id": 2829979295708421476, "text": "euismod commodo lacus vestibulum Elasticsearch ante quis euismod", "createdAt": 1677877464000}' to topic = 'twitter-topic'
2023-03-04 00:34:24 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:34:24 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 23 being sent to partition twitter-topic-0
2023-03-04 00:34:24 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=92) and timeout 60000 to node 2: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-0=198]}
2023-03-04 00:34:24 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 2 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=92): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=0, errorCode=0, baseOffset=23, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:34:24 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-0 to 23
2023-03-04 00:34:24 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:34:34 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text commodo ullamcorper sed feugiat quis arcu Microservices euismod ante a at sed sending to kafka topic twitter-topic
2023-03-04 00:34:34 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 4103488127086801290, "id": 8661717214002166807, "text": "commodo ullamcorper sed feugiat quis arcu Microservices euismod ante a at sed", "createdAt": 1677877474000}' to topic = 'twitter-topic'
2023-03-04 00:34:34 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:34:34 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 25 being sent to partition twitter-topic-2
2023-03-04 00:34:34 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=93) and timeout 60000 to node 3: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-2=212]}
2023-03-04 00:34:34 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 3 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=93): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=2, errorCode=0, baseOffset=25, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:34:34 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-2 to 25
2023-03-04 00:34:34 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:34:44 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text vestibulum ante dictum sed ullamcorper Elasticsearch commodo lacus ullamcorper vestibulum sending to kafka topic twitter-topic
2023-03-04 00:34:44 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 8591688516353308558, "id": 6764246191274368158, "text": "vestibulum ante dictum sed ullamcorper Elasticsearch commodo lacus ullamcorper vestibulum", "createdAt": 1677877484000}' to topic = 'twitter-topic'
2023-03-04 00:34:44 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:34:44 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 30 being sent to partition twitter-topic-1
2023-03-04 00:34:44 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=94) and timeout 60000 to node 1: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-1=214]}
2023-03-04 00:34:44 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 1 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=94): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=1, errorCode=0, baseOffset=30, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:34:44 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-1 to 30
2023-03-04 00:34:44 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:34:54 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text in vestibulum a vestibulum Kafka ullamcorper a lacinia sending to kafka topic twitter-topic
2023-03-04 00:34:54 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 8063910556452327491, "id": 7531996567936391873, "text": "in vestibulum a vestibulum Kafka ullamcorper a lacinia", "createdAt": 1677877494000}' to topic = 'twitter-topic'
2023-03-04 00:34:54 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:34:54 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 24 being sent to partition twitter-topic-0
2023-03-04 00:34:54 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=95) and timeout 60000 to node 2: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-0=179]}
2023-03-04 00:34:54 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 2 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=95): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=0, errorCode=0, baseOffset=24, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:34:54 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-0 to 24
2023-03-04 00:34:54 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:35:04 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text ante lacus commodo quis dictum Microservices tempor ante vestibulum commodo sending to kafka topic twitter-topic
2023-03-04 00:35:04 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 2139595297570393839, "id": 5803977475353674539, "text": "ante lacus commodo quis dictum Microservices tempor ante vestibulum commodo", "createdAt": 1677877504000}' to topic = 'twitter-topic'
2023-03-04 00:35:04 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:35:04 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 31 being sent to partition twitter-topic-1
2023-03-04 00:35:04 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=96) and timeout 60000 to node 1: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-1=209]}
2023-03-04 00:35:04 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 1 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=96): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=1, errorCode=0, baseOffset=31, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:35:04 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-1 to 31
2023-03-04 00:35:04 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:35:14 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text lacinia at non vestibulum non at odio Kafka lacus lacus ullamcorper at non metus sending to kafka topic twitter-topic
2023-03-04 00:35:14 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 6201454867724521044, "id": 8306573281908817794, "text": "lacinia at non vestibulum non at odio Kafka lacus lacus ullamcorper at non metus", "createdAt": 1677877514000}' to topic = 'twitter-topic'
2023-03-04 00:35:14 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:35:14 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 26 being sent to partition twitter-topic-2
2023-03-04 00:35:14 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=97) and timeout 60000 to node 3: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-2=210]}
2023-03-04 00:35:14 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 3 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=97): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=2, errorCode=0, baseOffset=26, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:35:14 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-2 to 26
2023-03-04 00:35:14 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:35:24 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending metadata request MetadataRequestData(topics=[MetadataRequestTopic(topicId=AAAAAAAAAAAAAAAAAAAAAA, name='twitter-topic')], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to node localhost:29092 (id: 2 rack: null)
2023-03-04 00:35:24 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending METADATA request with header RequestHeader(apiKey=METADATA, apiVersion=6, clientId=producer-1, correlationId=98) and timeout 60000 to node 2: MetadataRequestData(topics=[MetadataRequestTopic(topicId=AAAAAAAAAAAAAAAAAAAAAA, name='twitter-topic')], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false)
2023-03-04 00:35:24 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received METADATA response from node 2 for request with header RequestHeader(apiKey=METADATA, apiVersion=6, clientId=producer-1, correlationId=98): MetadataResponseData(throttleTimeMs=0, brokers=[MetadataResponseBroker(nodeId=2, host='localhost', port=29092, rack=null), MetadataResponseBroker(nodeId=1, host='localhost', port=19092, rack=null), MetadataResponseBroker(nodeId=3, host='localhost', port=39092, rack=null)], clusterId='QGDYypu5SSGtA9Bc36Rjow', controllerId=3, topics=[MetadataResponseTopic(errorCode=0, name='twitter-topic', topicId=AAAAAAAAAAAAAAAAAAAAAA, isInternal=false, partitions=[MetadataResponsePartition(errorCode=0, partitionIndex=2, leaderId=3, leaderEpoch=-1, replicaNodes=[3, 2, 1], isrNodes=[3, 2, 1], offlineReplicas=[]), MetadataResponsePartition(errorCode=0, partitionIndex=1, leaderId=1, leaderEpoch=-1, replicaNodes=[1, 3, 2], isrNodes=[1, 3, 2], offlineReplicas=[]), MetadataResponsePartition(errorCode=0, partitionIndex=0, leaderId=2, leaderEpoch=-1, replicaNodes=[2, 1, 3], isrNodes=[2, 1, 3], offlineReplicas=[])], topicAuthorizedOperations=-2147483648)], clusterAuthorizedOperations=-2147483648)
2023-03-04 00:35:24 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Updated cluster metadata updateVersion 5 to MetadataCache{clusterId='QGDYypu5SSGtA9Bc36Rjow', nodes={1=localhost:19092 (id: 1 rack: null), 2=localhost:29092 (id: 2 rack: null), 3=localhost:39092 (id: 3 rack: null)}, partitions=[PartitionMetadata(error=NONE, partition=twitter-topic-0, leader=Optional[2], leaderEpoch=Optional.empty, replicas=2,1,3, isr=2,1,3, offlineReplicas=), PartitionMetadata(error=NONE, partition=twitter-topic-1, leader=Optional[1], leaderEpoch=Optional.empty, replicas=1,3,2, isr=1,3,2, offlineReplicas=), PartitionMetadata(error=NONE, partition=twitter-topic-2, leader=Optional[3], leaderEpoch=Optional.empty, replicas=3,2,1, isr=3,2,1, offlineReplicas=)], controller=localhost:39092 (id: 3 rack: null)}
2023-03-04 00:35:24 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text commodo metus in at at a feugiat Elasticsearch ante lacus quis ante metus commodo sending to kafka topic twitter-topic
2023-03-04 00:35:24 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 7350131899485672469, "id": 6684181750835463793, "text": "commodo metus in at at a feugiat Elasticsearch ante lacus quis ante metus commodo", "createdAt": 1677877524000}' to topic = 'twitter-topic'
2023-03-04 00:35:24 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:35:24 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 27 being sent to partition twitter-topic-2
2023-03-04 00:35:24 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=99) and timeout 60000 to node 3: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-2=218]}
2023-03-04 00:35:24 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 3 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=99): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=2, errorCode=0, baseOffset=27, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:35:24 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-2 to 27
2023-03-04 00:35:24 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:35:34 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text feugiat a a odio euismod Microservices ante dictum odio at sending to kafka topic twitter-topic
2023-03-04 00:35:34 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 6092593724119840864, "id": 6132367010197685166, "text": "feugiat a a odio euismod Microservices ante dictum odio at", "createdAt": 1677877534000}' to topic = 'twitter-topic'
2023-03-04 00:35:34 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:35:34 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 25 being sent to partition twitter-topic-0
2023-03-04 00:35:34 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=100) and timeout 60000 to node 2: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-0=192]}
2023-03-04 00:35:34 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 2 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=100): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=0, errorCode=0, baseOffset=25, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:35:34 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-0 to 25
2023-03-04 00:35:34 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:35:44 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text euismod sed metus euismod euismod a Spring commodo metus ante non non sending to kafka topic twitter-topic
2023-03-04 00:35:44 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 7809176980978683873, "id": 7742381352425863814, "text": "euismod sed metus euismod euismod a Spring commodo metus ante non non", "createdAt": 1677877544000}' to topic = 'twitter-topic'
2023-03-04 00:35:44 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:35:44 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 32 being sent to partition twitter-topic-1
2023-03-04 00:35:44 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=101) and timeout 60000 to node 1: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-1=189]}
2023-03-04 00:35:44 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 1 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=101): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=1, errorCode=0, baseOffset=32, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:35:44 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-1 to 32
2023-03-04 00:35:44 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:35:54 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text lacus dictum euismod arcu euismod in feugiat commodo Java ullamcorper lacus metus vestibulum lacus tempor odio sending to kafka topic twitter-topic
2023-03-04 00:35:54 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 1417445994725427598, "id": 2116259619963362448, "text": "lacus dictum euismod arcu euismod in feugiat commodo Java ullamcorper lacus metus vestibulum lacus tempor odio", "createdAt": 1677877554000}' to topic = 'twitter-topic'
2023-03-04 00:35:54 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:35:54 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 28 being sent to partition twitter-topic-2
2023-03-04 00:35:54 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=102) and timeout 60000 to node 3: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-2=239]}
2023-03-04 00:35:54 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 3 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=102): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=2, errorCode=0, baseOffset=28, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:35:54 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-2 to 28
2023-03-04 00:35:54 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:36:04 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text commodo dictum at commodo sed odio Spring quis non lacus tempor sending to kafka topic twitter-topic
2023-03-04 00:36:04 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 5647855315704891745, "id": 5383738492504589995, "text": "commodo dictum at commodo sed odio Spring quis non lacus tempor", "createdAt": 1677877564000}' to topic = 'twitter-topic'
2023-03-04 00:36:04 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:36:04 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 26 being sent to partition twitter-topic-0
2023-03-04 00:36:04 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=103) and timeout 60000 to node 2: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-0=194]}
2023-03-04 00:36:04 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 2 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=103): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=0, errorCode=0, baseOffset=26, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:36:04 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-0 to 26
2023-03-04 00:36:04 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:36:14 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text sed lacus metus feugiat lacinia at Elasticsearch odio arcu ullamcorper lacus sending to kafka topic twitter-topic
2023-03-04 00:36:14 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 2951179302371499508, "id": 3995156523841293717, "text": "sed lacus metus feugiat lacinia at Elasticsearch odio arcu ullamcorper lacus", "createdAt": 1677877574000}' to topic = 'twitter-topic'
2023-03-04 00:36:14 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:36:14 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 27 being sent to partition twitter-topic-0
2023-03-04 00:36:14 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=104) and timeout 60000 to node 2: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-0=209]}
2023-03-04 00:36:14 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 2 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=104): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=0, errorCode=0, baseOffset=27, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:36:14 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-0 to 27
2023-03-04 00:36:14 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:36:21 [kafka-admin-client-thread | adminclient-1] INFO  o.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Node 2 disconnected.
2023-03-04 00:36:21 [kafka-admin-client-thread | adminclient-1] DEBUG o.a.k.c.a.i.AdminMetadataManager - [AdminClient clientId=adminclient-1] Requesting metadata update.
2023-03-04 00:36:21 [kafka-admin-client-thread | adminclient-1] DEBUG o.apache.kafka.clients.ClientUtils - Resolved host localhost as 127.0.0.1
2023-03-04 00:36:21 [kafka-admin-client-thread | adminclient-1] DEBUG o.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Initiating connection to node localhost:19092 (id: 1 rack: null) using address localhost/127.0.0.1
2023-03-04 00:36:21 [kafka-admin-client-thread | adminclient-1] DEBUG o.a.kafka.common.network.Selector - [AdminClient clientId=adminclient-1] Created socket with SO_RCVBUF = 342972, SO_SNDBUF = 146988, SO_TIMEOUT = 0 to node 1
2023-03-04 00:36:21 [kafka-admin-client-thread | adminclient-1] DEBUG o.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Completed connection to node 1. Fetching API versions.
2023-03-04 00:36:21 [kafka-admin-client-thread | adminclient-1] DEBUG o.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Initiating API versions fetch from node 1.
2023-03-04 00:36:21 [kafka-admin-client-thread | adminclient-1] DEBUG o.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Sending API_VERSIONS request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=adminclient-1, correlationId=11) and timeout 3600000 to node 1: ApiVersionsRequestData(clientSoftwareName='apache-kafka-java', clientSoftwareVersion='3.3.2')
2023-03-04 00:36:21 [kafka-admin-client-thread | adminclient-1] DEBUG o.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Received API_VERSIONS response from node 1 for request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=adminclient-1, correlationId=11): ApiVersionsResponseData(errorCode=35, apiKeys=[], throttleTimeMs=0, supportedFeatures=[], finalizedFeaturesEpoch=-1, finalizedFeatures=[])
2023-03-04 00:36:21 [kafka-admin-client-thread | adminclient-1] DEBUG o.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Initiating API versions fetch from node 1.
2023-03-04 00:36:21 [kafka-admin-client-thread | adminclient-1] DEBUG o.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Sending API_VERSIONS request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=0, clientId=adminclient-1, correlationId=12) and timeout 3600000 to node 1: ApiVersionsRequestData(clientSoftwareName='apache-kafka-java', clientSoftwareVersion='3.3.2')
2023-03-04 00:36:21 [kafka-admin-client-thread | adminclient-1] DEBUG o.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Received API_VERSIONS response from node 1 for request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=0, clientId=adminclient-1, correlationId=12): ApiVersionsResponseData(errorCode=0, apiKeys=[ApiVersion(apiKey=0, minVersion=0, maxVersion=6), ApiVersion(apiKey=1, minVersion=0, maxVersion=8), ApiVersion(apiKey=2, minVersion=0, maxVersion=3), ApiVersion(apiKey=3, minVersion=0, maxVersion=6), ApiVersion(apiKey=4, minVersion=0, maxVersion=1), ApiVersion(apiKey=5, minVersion=0, maxVersion=0), ApiVersion(apiKey=6, minVersion=0, maxVersion=4), ApiVersion(apiKey=7, minVersion=0, maxVersion=1), ApiVersion(apiKey=8, minVersion=0, maxVersion=4), ApiVersion(apiKey=9, minVersion=0, maxVersion=4), ApiVersion(apiKey=10, minVersion=0, maxVersion=2), ApiVersion(apiKey=11, minVersion=0, maxVersion=3), ApiVersion(apiKey=12, minVersion=0, maxVersion=2), ApiVersion(apiKey=13, minVersion=0, maxVersion=2), ApiVersion(apiKey=14, minVersion=0, maxVersion=2), ApiVersion(apiKey=15, minVersion=0, maxVersion=2), ApiVersion(apiKey=16, minVersion=0, maxVersion=2), ApiVersion(apiKey=17, minVersion=0, maxVersion=1), ApiVersion(apiKey=18, minVersion=0, maxVersion=2), ApiVersion(apiKey=19, minVersion=0, maxVersion=3), ApiVersion(apiKey=20, minVersion=0, maxVersion=2), ApiVersion(apiKey=21, minVersion=0, maxVersion=1), ApiVersion(apiKey=22, minVersion=0, maxVersion=1), ApiVersion(apiKey=23, minVersion=0, maxVersion=1), ApiVersion(apiKey=24, minVersion=0, maxVersion=1), ApiVersion(apiKey=25, minVersion=0, maxVersion=1), ApiVersion(apiKey=26, minVersion=0, maxVersion=1), ApiVersion(apiKey=27, minVersion=0, maxVersion=0), ApiVersion(apiKey=28, minVersion=0, maxVersion=1), ApiVersion(apiKey=29, minVersion=0, maxVersion=1), ApiVersion(apiKey=30, minVersion=0, maxVersion=1), ApiVersion(apiKey=31, minVersion=0, maxVersion=1), ApiVersion(apiKey=32, minVersion=0, maxVersion=2), ApiVersion(apiKey=33, minVersion=0, maxVersion=1), ApiVersion(apiKey=34, minVersion=0, maxVersion=1), ApiVersion(apiKey=35, minVersion=0, maxVersion=1), ApiVersion(apiKey=36, minVersion=0, maxVersion=0), ApiVersion(apiKey=37, minVersion=0, maxVersion=1), ApiVersion(apiKey=38, minVersion=0, maxVersion=1), ApiVersion(apiKey=39, minVersion=0, maxVersion=1), ApiVersion(apiKey=40, minVersion=0, maxVersion=1), ApiVersion(apiKey=41, minVersion=0, maxVersion=1), ApiVersion(apiKey=42, minVersion=0, maxVersion=1)], throttleTimeMs=0, supportedFeatures=[], finalizedFeaturesEpoch=-1, finalizedFeatures=[])
2023-03-04 00:36:21 [kafka-admin-client-thread | adminclient-1] DEBUG o.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Node 1 has finalized features epoch: -1, finalized features: [], supported features: [], API versions: (Produce(0): 0 to 6 [usable: 6], Fetch(1): 0 to 8 [usable: 8], ListOffsets(2): 0 to 3 [usable: 3], Metadata(3): 0 to 6 [usable: 6], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 4 [usable: 4], OffsetFetch(9): 0 to 4 [usable: 4], FindCoordinator(10): 0 to 2 [usable: 2], JoinGroup(11): 0 to 3 [usable: 3], Heartbeat(12): 0 to 2 [usable: 2], LeaveGroup(13): 0 to 2 [usable: 2], SyncGroup(14): 0 to 2 [usable: 2], DescribeGroups(15): 0 to 2 [usable: 2], ListGroups(16): 0 to 2 [usable: 2], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 2], CreateTopics(19): 0 to 3 [usable: 3], DeleteTopics(20): 0 to 2 [usable: 2], DeleteRecords(21): 0 to 1 [usable: 1], InitProducerId(22): 0 to 1 [usable: 1], OffsetForLeaderEpoch(23): 0 to 1 [usable: 1], AddPartitionsToTxn(24): 0 to 1 [usable: 1], AddOffsetsToTxn(25): 0 to 1 [usable: 1], EndTxn(26): 0 to 1 [usable: 1], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 1 [usable: 1], DescribeAcls(29): 0 to 1 [usable: 1], CreateAcls(30): 0 to 1 [usable: 1], DeleteAcls(31): 0 to 1 [usable: 1], DescribeConfigs(32): 0 to 2 [usable: 2], AlterConfigs(33): 0 to 1 [usable: 1], AlterReplicaLogDirs(34): 0 to 1 [usable: 1], DescribeLogDirs(35): 0 to 1 [usable: 1], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 1], CreateDelegationToken(38): 0 to 1 [usable: 1], RenewDelegationToken(39): 0 to 1 [usable: 1], ExpireDelegationToken(40): 0 to 1 [usable: 1], DescribeDelegationToken(41): 0 to 1 [usable: 1], DeleteGroups(42): 0 to 1 [usable: 1], ElectLeaders(43): UNSUPPORTED, IncrementalAlterConfigs(44): UNSUPPORTED, AlterPartitionReassignments(45): UNSUPPORTED, ListPartitionReassignments(46): UNSUPPORTED, OffsetDelete(47): UNSUPPORTED, DescribeClientQuotas(48): UNSUPPORTED, AlterClientQuotas(49): UNSUPPORTED, DescribeUserScramCredentials(50): UNSUPPORTED, AlterUserScramCredentials(51): UNSUPPORTED, AlterPartition(56): UNSUPPORTED, UpdateFeatures(57): UNSUPPORTED, DescribeCluster(60): UNSUPPORTED, DescribeProducers(61): UNSUPPORTED, DescribeTransactions(65): UNSUPPORTED, ListTransactions(66): UNSUPPORTED, AllocateProducerIds(67): UNSUPPORTED).
2023-03-04 00:36:21 [kafka-admin-client-thread | adminclient-1] DEBUG o.a.k.clients.admin.KafkaAdminClient - [AdminClient clientId=adminclient-1] Sending MetadataRequestData(topics=[], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to localhost:19092 (id: 1 rack: null). correlationId=13, timeoutMs=29985
2023-03-04 00:36:21 [kafka-admin-client-thread | adminclient-1] DEBUG o.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Sending METADATA request with header RequestHeader(apiKey=METADATA, apiVersion=6, clientId=adminclient-1, correlationId=13) and timeout 29985 to node 1: MetadataRequestData(topics=[], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false)
2023-03-04 00:36:21 [kafka-admin-client-thread | adminclient-1] DEBUG o.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Received METADATA response from node 1 for request with header RequestHeader(apiKey=METADATA, apiVersion=6, clientId=adminclient-1, correlationId=13): MetadataResponseData(throttleTimeMs=0, brokers=[MetadataResponseBroker(nodeId=2, host='localhost', port=29092, rack=null), MetadataResponseBroker(nodeId=1, host='localhost', port=19092, rack=null), MetadataResponseBroker(nodeId=3, host='localhost', port=39092, rack=null)], clusterId='QGDYypu5SSGtA9Bc36Rjow', controllerId=3, topics=[], clusterAuthorizedOperations=-2147483648)
2023-03-04 00:36:21 [kafka-admin-client-thread | adminclient-1] DEBUG o.a.k.c.a.i.AdminMetadataManager - [AdminClient clientId=adminclient-1] Updating cluster metadata to Cluster(id = QGDYypu5SSGtA9Bc36Rjow, nodes = [localhost:39092 (id: 3 rack: null), localhost:29092 (id: 2 rack: null), localhost:19092 (id: 1 rack: null)], partitions = [], controller = localhost:39092 (id: 3 rack: null))
2023-03-04 00:36:24 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text euismod vestibulum a sed Spring metus quis sending to kafka topic twitter-topic
2023-03-04 00:36:24 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 3961465599766869347, "id": 5915367127898365660, "text": "euismod vestibulum a sed Spring metus quis", "createdAt": 1677877584000}' to topic = 'twitter-topic'
2023-03-04 00:36:24 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:36:24 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 29 being sent to partition twitter-topic-2
2023-03-04 00:36:24 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=105) and timeout 60000 to node 3: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-2=175]}
2023-03-04 00:36:24 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 3 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=105): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=2, errorCode=0, baseOffset=29, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:36:24 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-2 to 29
2023-03-04 00:36:24 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:36:34 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text in arcu quis odio ullamcorper a ante lacinia Microservices non at sed vestibulum sed ante tempor sending to kafka topic twitter-topic
2023-03-04 00:36:34 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 5590450219733517684, "id": 7069304751058001587, "text": "in arcu quis odio ullamcorper a ante lacinia Microservices non at sed vestibulum sed ante tempor", "createdAt": 1677877594000}' to topic = 'twitter-topic'
2023-03-04 00:36:34 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:36:34 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 30 being sent to partition twitter-topic-2
2023-03-04 00:36:34 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=106) and timeout 60000 to node 3: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-2=230]}
2023-03-04 00:36:34 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 3 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=106): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=2, errorCode=0, baseOffset=30, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:36:34 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-2 to 30
2023-03-04 00:36:34 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:36:44 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text non euismod quis vestibulum ullamcorper feugiat metus Microservices feugiat ante lacus at feugiat sending to kafka topic twitter-topic
2023-03-04 00:36:44 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 5970059122559470898, "id": 3939090238778342724, "text": "non euismod quis vestibulum ullamcorper feugiat metus Microservices feugiat ante lacus at feugiat", "createdAt": 1677877604000}' to topic = 'twitter-topic'
2023-03-04 00:36:44 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:36:44 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 28 being sent to partition twitter-topic-0
2023-03-04 00:36:44 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=107) and timeout 60000 to node 2: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-0=232]}
2023-03-04 00:36:44 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 2 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=107): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=0, errorCode=0, baseOffset=28, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:36:44 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-0 to 28
2023-03-04 00:36:44 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:36:54 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text non ante metus ullamcorper odio lacinia ullamcorper Microservices non ante in ante metus sending to kafka topic twitter-topic
2023-03-04 00:36:54 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 1723049790964167489, "id": 7415452791143580025, "text": "non ante metus ullamcorper odio lacinia ullamcorper Microservices non ante in ante metus", "createdAt": 1677877614000}' to topic = 'twitter-topic'
2023-03-04 00:36:54 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:36:54 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 29 being sent to partition twitter-topic-0
2023-03-04 00:36:54 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=108) and timeout 60000 to node 2: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-0=204]}
2023-03-04 00:36:54 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 2 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=108): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=0, errorCode=0, baseOffset=29, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:36:54 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-0 to 29
2023-03-04 00:36:54 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:37:04 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text tempor ullamcorper euismod lacus tempor metus Spring metus dictum quis lacinia feugiat sending to kafka topic twitter-topic
2023-03-04 00:37:04 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 7233418604064303967, "id": 3065708110082949237, "text": "tempor ullamcorper euismod lacus tempor metus Spring metus dictum quis lacinia feugiat", "createdAt": 1677877624000}' to topic = 'twitter-topic'
2023-03-04 00:37:04 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:37:04 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 31 being sent to partition twitter-topic-2
2023-03-04 00:37:04 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=109) and timeout 60000 to node 3: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-2=222]}
2023-03-04 00:37:04 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 3 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=109): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=2, errorCode=0, baseOffset=31, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:37:04 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-2 to 31
2023-03-04 00:37:04 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:37:14 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text lacus at vestibulum at feugiat Java vestibulum at in arcu sending to kafka topic twitter-topic
2023-03-04 00:37:14 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 4092363665513751541, "id": 8370660750146395467, "text": "lacus at vestibulum at feugiat Java vestibulum at in arcu", "createdAt": 1677877634000}' to topic = 'twitter-topic'
2023-03-04 00:37:14 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:37:14 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 32 being sent to partition twitter-topic-2
2023-03-04 00:37:14 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=110) and timeout 60000 to node 3: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-2=179]}
2023-03-04 00:37:14 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 3 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=110): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=2, errorCode=0, baseOffset=32, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:37:14 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-2 to 32
2023-03-04 00:37:14 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:37:24 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text tempor at at Elasticsearch metus ante sending to kafka topic twitter-topic
2023-03-04 00:37:24 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 8639808260227019528, "id": 5387097055829046154, "text": "tempor at at Elasticsearch metus ante", "createdAt": 1677877644000}' to topic = 'twitter-topic'
2023-03-04 00:37:24 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:37:24 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 33 being sent to partition twitter-topic-1
2023-03-04 00:37:24 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=111) and timeout 60000 to node 1: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-1=169]}
2023-03-04 00:37:24 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 1 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=111): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=1, errorCode=0, baseOffset=33, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:37:24 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-1 to 33
2023-03-04 00:37:24 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:37:34 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text commodo at at non at lacus quis feugiat Java metus tempor dictum dictum euismod a dictum sending to kafka topic twitter-topic
2023-03-04 00:37:34 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 7212083641176304209, "id": 2708541919068843183, "text": "commodo at at non at lacus quis feugiat Java metus tempor dictum dictum euismod a dictum", "createdAt": 1677877654000}' to topic = 'twitter-topic'
2023-03-04 00:37:34 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:37:34 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 33 being sent to partition twitter-topic-2
2023-03-04 00:37:34 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=112) and timeout 60000 to node 3: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-2=224]}
2023-03-04 00:37:34 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 3 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=112): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=2, errorCode=0, baseOffset=33, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:37:34 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-2 to 33
2023-03-04 00:37:34 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:37:44 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text non euismod commodo non at a Microservices ante arcu in euismod a sending to kafka topic twitter-topic
2023-03-04 00:37:44 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 6607172987542337976, "id": 7615851691667340180, "text": "non euismod commodo non at a Microservices ante arcu in euismod a", "createdAt": 1677877664000}' to topic = 'twitter-topic'
2023-03-04 00:37:44 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:37:44 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 34 being sent to partition twitter-topic-2
2023-03-04 00:37:44 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=113) and timeout 60000 to node 3: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-2=191]}
2023-03-04 00:37:44 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 3 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=113): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=2, errorCode=0, baseOffset=34, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:37:44 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-2 to 34
2023-03-04 00:37:44 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:37:54 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text euismod commodo lacinia Java at ullamcorper sending to kafka topic twitter-topic
2023-03-04 00:37:54 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 9211389035696671514, "id": 2633252639945348784, "text": "euismod commodo lacinia Java at ullamcorper", "createdAt": 1677877674000}' to topic = 'twitter-topic'
2023-03-04 00:37:54 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:37:54 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 30 being sent to partition twitter-topic-0
2023-03-04 00:37:54 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=114) and timeout 60000 to node 2: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-0=176]}
2023-03-04 00:37:54 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 2 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=114): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=0, errorCode=0, baseOffset=30, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:37:54 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-0 to 30
2023-03-04 00:37:54 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:38:04 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text euismod ullamcorper at in odio in Spring lacinia lacus non odio quis sending to kafka topic twitter-topic
2023-03-04 00:38:04 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 9157303744450564562, "id": 5561084018276153716, "text": "euismod ullamcorper at in odio in Spring lacinia lacus non odio quis", "createdAt": 1677877684000}' to topic = 'twitter-topic'
2023-03-04 00:38:04 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:38:04 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 34 being sent to partition twitter-topic-1
2023-03-04 00:38:04 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=115) and timeout 60000 to node 1: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-1=196]}
2023-03-04 00:38:04 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 1 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=115): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=1, errorCode=0, baseOffset=34, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:38:04 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-1 to 34
2023-03-04 00:38:04 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:38:14 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text at commodo lacus euismod in dictum Java lacinia feugiat lacus a sending to kafka topic twitter-topic
2023-03-04 00:38:14 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 2079409715292655626, "id": 3305203625646282634, "text": "at commodo lacus euismod in dictum Java lacinia feugiat lacus a", "createdAt": 1677877694000}' to topic = 'twitter-topic'
2023-03-04 00:38:14 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:38:14 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 31 being sent to partition twitter-topic-0
2023-03-04 00:38:14 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=116) and timeout 60000 to node 2: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-0=193]}
2023-03-04 00:38:14 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 2 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=116): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=0, errorCode=0, baseOffset=31, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:38:14 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-0 to 31
2023-03-04 00:38:14 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:38:24 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text ante ullamcorper commodo metus feugiat Microservices euismod at commodo odio sending to kafka topic twitter-topic
2023-03-04 00:38:24 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 5745052394996622011, "id": 4982886098745247654, "text": "ante ullamcorper commodo metus feugiat Microservices euismod at commodo odio", "createdAt": 1677877704000}' to topic = 'twitter-topic'
2023-03-04 00:38:24 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:38:24 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 35 being sent to partition twitter-topic-2
2023-03-04 00:38:24 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=117) and timeout 60000 to node 3: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-2=212]}
2023-03-04 00:38:24 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 3 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=117): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=2, errorCode=0, baseOffset=35, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:38:24 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-2 to 35
2023-03-04 00:38:24 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:38:34 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text ante feugiat arcu metus feugiat tempor vestibulum Kafka at commodo feugiat feugiat vestibulum sending to kafka topic twitter-topic
2023-03-04 00:38:34 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 7529857092464438226, "id": 6922624080045648875, "text": "ante feugiat arcu metus feugiat tempor vestibulum Kafka at commodo feugiat feugiat vestibulum", "createdAt": 1677877714000}' to topic = 'twitter-topic'
2023-03-04 00:38:34 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:38:34 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 32 being sent to partition twitter-topic-0
2023-03-04 00:38:34 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=118) and timeout 60000 to node 2: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-0=204]}
2023-03-04 00:38:34 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 2 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=118): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=0, errorCode=0, baseOffset=32, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:38:34 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-0 to 32
2023-03-04 00:38:34 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:38:44 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text tempor odio feugiat sed vestibulum lacinia Java dictum a commodo sed ante sending to kafka topic twitter-topic
2023-03-04 00:38:44 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 7634754118151609596, "id": 2109105534890347371, "text": "tempor odio feugiat sed vestibulum lacinia Java dictum a commodo sed ante", "createdAt": 1677877724000}' to topic = 'twitter-topic'
2023-03-04 00:38:44 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:38:44 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 35 being sent to partition twitter-topic-1
2023-03-04 00:38:44 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=119) and timeout 60000 to node 1: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-1=207]}
2023-03-04 00:38:44 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 1 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=119): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=1, errorCode=0, baseOffset=35, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:38:44 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-1 to 35
2023-03-04 00:38:44 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:38:54 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text lacinia sed sed a vestibulum Microservices vestibulum non in commodo sending to kafka topic twitter-topic
2023-03-04 00:38:54 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 5332548613648228325, "id": 1337064201275684129, "text": "lacinia sed sed a vestibulum Microservices vestibulum non in commodo", "createdAt": 1677877734000}' to topic = 'twitter-topic'
2023-03-04 00:38:54 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:38:54 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 36 being sent to partition twitter-topic-2
2023-03-04 00:38:54 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=120) and timeout 60000 to node 3: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-2=191]}
2023-03-04 00:38:54 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 3 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=120): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=2, errorCode=0, baseOffset=36, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:38:54 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-2 to 36
2023-03-04 00:38:54 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:39:04 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text at non euismod quis feugiat commodo ullamcorper sed Spring commodo ullamcorper vestibulum odio non non sending to kafka topic twitter-topic
2023-03-04 00:39:04 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 8613655846798867807, "id": 5850136175473002525, "text": "at non euismod quis feugiat commodo ullamcorper sed Spring commodo ullamcorper vestibulum odio non non", "createdAt": 1677877744000}' to topic = 'twitter-topic'
2023-03-04 00:39:04 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:39:04 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 36 being sent to partition twitter-topic-1
2023-03-04 00:39:04 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=121) and timeout 60000 to node 1: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-1=228]}
2023-03-04 00:39:04 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 1 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=121): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=1, errorCode=0, baseOffset=36, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:39:04 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-1 to 36
2023-03-04 00:39:04 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:39:14 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text arcu commodo vestibulum sed vestibulum commodo sed commodo Java arcu vestibulum quis in commodo lacus a sending to kafka topic twitter-topic
2023-03-04 00:39:14 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 709208295894100459, "id": 6851617767257973293, "text": "arcu commodo vestibulum sed vestibulum commodo sed commodo Java arcu vestibulum quis in commodo lacus a", "createdAt": 1677877754000}' to topic = 'twitter-topic'
2023-03-04 00:39:14 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:39:14 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 37 being sent to partition twitter-topic-2
2023-03-04 00:39:14 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=122) and timeout 60000 to node 3: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-2=211]}
2023-03-04 00:39:14 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 3 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=122): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=2, errorCode=0, baseOffset=37, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:39:14 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-2 to 37
2023-03-04 00:39:14 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:39:24 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text quis ante ullamcorper at odio lacinia commodo dictum Kafka at euismod lacus non quis dictum a sending to kafka topic twitter-topic
2023-03-04 00:39:24 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 3407011746155423977, "id": 7430088067928464631, "text": "quis ante ullamcorper at odio lacinia commodo dictum Kafka at euismod lacus non quis dictum a", "createdAt": 1677877764000}' to topic = 'twitter-topic'
2023-03-04 00:39:24 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:39:24 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 33 being sent to partition twitter-topic-0
2023-03-04 00:39:24 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=123) and timeout 60000 to node 2: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-0=229]}
2023-03-04 00:39:24 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 2 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=123): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=0, errorCode=0, baseOffset=33, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:39:24 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-0 to 33
2023-03-04 00:39:24 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:39:34 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text at in a commodo Kafka quis vestibulum sending to kafka topic twitter-topic
2023-03-04 00:39:34 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 1105952480895509820, "id": 244742728608610031, "text": "at in a commodo Kafka quis vestibulum", "createdAt": 1677877774000}' to topic = 'twitter-topic'
2023-03-04 00:39:34 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:39:34 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 37 being sent to partition twitter-topic-1
2023-03-04 00:39:34 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=124) and timeout 60000 to node 1: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-1=169]}
2023-03-04 00:39:34 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 1 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=124): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=1, errorCode=0, baseOffset=37, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:39:34 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-1 to 37
2023-03-04 00:39:34 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:39:44 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text lacus at arcu tempor at Elasticsearch non lacus lacinia sending to kafka topic twitter-topic
2023-03-04 00:39:44 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 1567387483674123686, "id": 8015205299914175772, "text": "lacus at arcu tempor at Elasticsearch non lacus lacinia", "createdAt": 1677877784000}' to topic = 'twitter-topic'
2023-03-04 00:39:44 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:39:44 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 38 being sent to partition twitter-topic-2
2023-03-04 00:39:44 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=125) and timeout 60000 to node 3: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-2=183]}
2023-03-04 00:39:44 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 3 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=125): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=2, errorCode=0, baseOffset=38, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:39:44 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-2 to 38
2023-03-04 00:39:44 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:39:54 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text at at ullamcorper ante arcu Elasticsearch ante vestibulum euismod sed sending to kafka topic twitter-topic
2023-03-04 00:39:54 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 3522313406125975451, "id": 8518589021761937405, "text": "at at ullamcorper ante arcu Elasticsearch ante vestibulum euismod sed", "createdAt": 1677877794000}' to topic = 'twitter-topic'
2023-03-04 00:39:54 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:39:54 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 34 being sent to partition twitter-topic-0
2023-03-04 00:39:54 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=126) and timeout 60000 to node 2: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-0=200]}
2023-03-04 00:39:54 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 2 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=126): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=0, errorCode=0, baseOffset=34, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:39:54 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-0 to 34
2023-03-04 00:39:54 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:40:04 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text sed sed at tempor sed Spring sed commodo arcu quis sending to kafka topic twitter-topic
2023-03-04 00:40:04 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 7673597776476806663, "id": 6760887464716373366, "text": "sed sed at tempor sed Spring sed commodo arcu quis", "createdAt": 1677877804000}' to topic = 'twitter-topic'
2023-03-04 00:40:04 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:40:04 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 39 being sent to partition twitter-topic-2
2023-03-04 00:40:04 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=127) and timeout 60000 to node 3: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-2=178]}
2023-03-04 00:40:04 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 3 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=127): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=2, errorCode=0, baseOffset=39, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:40:04 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-2 to 39
2023-03-04 00:40:04 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:40:14 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text ullamcorper lacus ante lacinia lacinia dictum dictum sed Elasticsearch dictum vestibulum lacinia at dictum lacinia sending to kafka topic twitter-topic
2023-03-04 00:40:14 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 1165648641496682315, "id": 8833454561253852261, "text": "ullamcorper lacus ante lacinia lacinia dictum dictum sed Elasticsearch dictum vestibulum lacinia at dictum lacinia", "createdAt": 1677877814000}' to topic = 'twitter-topic'
2023-03-04 00:40:14 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:40:14 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 35 being sent to partition twitter-topic-0
2023-03-04 00:40:14 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=128) and timeout 60000 to node 2: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-0=226]}
2023-03-04 00:40:14 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 2 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=128): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=0, errorCode=0, baseOffset=35, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:40:14 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-0 to 35
2023-03-04 00:40:14 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:40:24 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending metadata request MetadataRequestData(topics=[MetadataRequestTopic(topicId=AAAAAAAAAAAAAAAAAAAAAA, name='twitter-topic')], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to node localhost:19092 (id: 1 rack: null)
2023-03-04 00:40:24 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending METADATA request with header RequestHeader(apiKey=METADATA, apiVersion=6, clientId=producer-1, correlationId=129) and timeout 60000 to node 1: MetadataRequestData(topics=[MetadataRequestTopic(topicId=AAAAAAAAAAAAAAAAAAAAAA, name='twitter-topic')], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false)
2023-03-04 00:40:24 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received METADATA response from node 1 for request with header RequestHeader(apiKey=METADATA, apiVersion=6, clientId=producer-1, correlationId=129): MetadataResponseData(throttleTimeMs=0, brokers=[MetadataResponseBroker(nodeId=2, host='localhost', port=29092, rack=null), MetadataResponseBroker(nodeId=1, host='localhost', port=19092, rack=null), MetadataResponseBroker(nodeId=3, host='localhost', port=39092, rack=null)], clusterId='QGDYypu5SSGtA9Bc36Rjow', controllerId=3, topics=[MetadataResponseTopic(errorCode=0, name='twitter-topic', topicId=AAAAAAAAAAAAAAAAAAAAAA, isInternal=false, partitions=[MetadataResponsePartition(errorCode=0, partitionIndex=2, leaderId=3, leaderEpoch=-1, replicaNodes=[3, 2, 1], isrNodes=[3, 2, 1], offlineReplicas=[]), MetadataResponsePartition(errorCode=0, partitionIndex=1, leaderId=1, leaderEpoch=-1, replicaNodes=[1, 3, 2], isrNodes=[1, 3, 2], offlineReplicas=[]), MetadataResponsePartition(errorCode=0, partitionIndex=0, leaderId=2, leaderEpoch=-1, replicaNodes=[2, 1, 3], isrNodes=[2, 1, 3], offlineReplicas=[])], topicAuthorizedOperations=-2147483648)], clusterAuthorizedOperations=-2147483648)
2023-03-04 00:40:24 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Updated cluster metadata updateVersion 6 to MetadataCache{clusterId='QGDYypu5SSGtA9Bc36Rjow', nodes={1=localhost:19092 (id: 1 rack: null), 2=localhost:29092 (id: 2 rack: null), 3=localhost:39092 (id: 3 rack: null)}, partitions=[PartitionMetadata(error=NONE, partition=twitter-topic-0, leader=Optional[2], leaderEpoch=Optional.empty, replicas=2,1,3, isr=2,1,3, offlineReplicas=), PartitionMetadata(error=NONE, partition=twitter-topic-1, leader=Optional[1], leaderEpoch=Optional.empty, replicas=1,3,2, isr=1,3,2, offlineReplicas=), PartitionMetadata(error=NONE, partition=twitter-topic-2, leader=Optional[3], leaderEpoch=Optional.empty, replicas=3,2,1, isr=3,2,1, offlineReplicas=)], controller=localhost:39092 (id: 3 rack: null)}
2023-03-04 00:40:24 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text dictum a lacinia at quis lacus vestibulum arcu Spring quis tempor quis at arcu quis sending to kafka topic twitter-topic
2023-03-04 00:40:24 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 15836938328733719, "id": 1976548558463351413, "text": "dictum a lacinia at quis lacus vestibulum arcu Spring quis tempor quis at arcu quis", "createdAt": 1677877824000}' to topic = 'twitter-topic'
2023-03-04 00:40:24 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:40:24 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 40 being sent to partition twitter-topic-2
2023-03-04 00:40:24 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=130) and timeout 60000 to node 3: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-2=208]}
2023-03-04 00:40:24 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 3 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=130): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=2, errorCode=0, baseOffset=40, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:40:24 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-2 to 40
2023-03-04 00:40:24 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:40:34 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text at ante feugiat feugiat Microservices in in a sending to kafka topic twitter-topic
2023-03-04 00:40:34 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 874382354777694830, "id": 583089772619442219, "text": "at ante feugiat feugiat Microservices in in a", "createdAt": 1677877834000}' to topic = 'twitter-topic'
2023-03-04 00:40:34 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:40:34 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 38 being sent to partition twitter-topic-1
2023-03-04 00:40:34 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=131) and timeout 60000 to node 1: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-1=170]}
2023-03-04 00:40:34 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 1 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=131): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=1, errorCode=0, baseOffset=38, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:40:34 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-1 to 38
2023-03-04 00:40:34 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:40:44 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text dictum vestibulum a at tempor metus tempor Elasticsearch ullamcorper a dictum lacus vestibulum at sending to kafka topic twitter-topic
2023-03-04 00:40:44 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 7040032449777532183, "id": 2157902966119972402, "text": "dictum vestibulum a at tempor metus tempor Elasticsearch ullamcorper a dictum lacus vestibulum at", "createdAt": 1677877844000}' to topic = 'twitter-topic'
2023-03-04 00:40:44 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:40:44 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 41 being sent to partition twitter-topic-2
2023-03-04 00:40:44 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=132) and timeout 60000 to node 3: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-2=219]}
2023-03-04 00:40:44 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 3 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=132): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=2, errorCode=0, baseOffset=41, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:40:44 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-2 to 41
2023-03-04 00:40:44 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:40:54 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text sed tempor sed lacus commodo non Java lacus ullamcorper non odio sending to kafka topic twitter-topic
2023-03-04 00:40:54 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 5376310604064797455, "id": 5793014753056865653, "text": "sed tempor sed lacus commodo non Java lacus ullamcorper non odio", "createdAt": 1677877854000}' to topic = 'twitter-topic'
2023-03-04 00:40:54 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:40:54 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 39 being sent to partition twitter-topic-1
2023-03-04 00:40:54 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=133) and timeout 60000 to node 1: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-1=199]}
2023-03-04 00:40:54 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 1 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=133): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=1, errorCode=0, baseOffset=39, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:40:54 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-1 to 39
2023-03-04 00:40:54 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:41:04 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text in sed tempor Microservices quis lacus sending to kafka topic twitter-topic
2023-03-04 00:41:04 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 3632855546992288263, "id": 3801965478734029663, "text": "in sed tempor Microservices quis lacus", "createdAt": 1677877864000}' to topic = 'twitter-topic'
2023-03-04 00:41:04 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:41:04 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 36 being sent to partition twitter-topic-0
2023-03-04 00:41:04 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=134) and timeout 60000 to node 2: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-0=170]}
2023-03-04 00:41:04 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 2 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=134): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=0, errorCode=0, baseOffset=36, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:41:04 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-0 to 36
2023-03-04 00:41:04 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:41:14 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text quis arcu metus feugiat lacus Spring tempor dictum at sending to kafka topic twitter-topic
2023-03-04 00:41:14 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 1710062072451668848, "id": 283473867590846616, "text": "quis arcu metus feugiat lacus Spring tempor dictum at", "createdAt": 1677877874000}' to topic = 'twitter-topic'
2023-03-04 00:41:14 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:41:14 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 40 being sent to partition twitter-topic-1
2023-03-04 00:41:14 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=135) and timeout 60000 to node 1: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-1=185]}
2023-03-04 00:41:14 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 1 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=135): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=1, errorCode=0, baseOffset=40, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:41:14 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-1 to 40
2023-03-04 00:41:14 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:41:21 [kafka-admin-client-thread | adminclient-1] INFO  o.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Node 1 disconnected.
2023-03-04 00:41:21 [kafka-admin-client-thread | adminclient-1] DEBUG o.a.k.c.a.i.AdminMetadataManager - [AdminClient clientId=adminclient-1] Requesting metadata update.
2023-03-04 00:41:21 [kafka-admin-client-thread | adminclient-1] DEBUG o.apache.kafka.clients.ClientUtils - Resolved host localhost as 127.0.0.1
2023-03-04 00:41:21 [kafka-admin-client-thread | adminclient-1] DEBUG o.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Initiating connection to node localhost:39092 (id: 3 rack: null) using address localhost/127.0.0.1
2023-03-04 00:41:21 [kafka-admin-client-thread | adminclient-1] DEBUG o.a.kafka.common.network.Selector - [AdminClient clientId=adminclient-1] Created socket with SO_RCVBUF = 342972, SO_SNDBUF = 146988, SO_TIMEOUT = 0 to node 3
2023-03-04 00:41:21 [kafka-admin-client-thread | adminclient-1] DEBUG o.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Completed connection to node 3. Fetching API versions.
2023-03-04 00:41:21 [kafka-admin-client-thread | adminclient-1] DEBUG o.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Initiating API versions fetch from node 3.
2023-03-04 00:41:21 [kafka-admin-client-thread | adminclient-1] DEBUG o.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Sending API_VERSIONS request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=adminclient-1, correlationId=14) and timeout 3600000 to node 3: ApiVersionsRequestData(clientSoftwareName='apache-kafka-java', clientSoftwareVersion='3.3.2')
2023-03-04 00:41:21 [kafka-admin-client-thread | adminclient-1] DEBUG o.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Received API_VERSIONS response from node 3 for request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=adminclient-1, correlationId=14): ApiVersionsResponseData(errorCode=35, apiKeys=[], throttleTimeMs=0, supportedFeatures=[], finalizedFeaturesEpoch=-1, finalizedFeatures=[])
2023-03-04 00:41:21 [kafka-admin-client-thread | adminclient-1] DEBUG o.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Initiating API versions fetch from node 3.
2023-03-04 00:41:21 [kafka-admin-client-thread | adminclient-1] DEBUG o.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Sending API_VERSIONS request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=0, clientId=adminclient-1, correlationId=15) and timeout 3600000 to node 3: ApiVersionsRequestData(clientSoftwareName='apache-kafka-java', clientSoftwareVersion='3.3.2')
2023-03-04 00:41:21 [kafka-admin-client-thread | adminclient-1] DEBUG o.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Received API_VERSIONS response from node 3 for request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=0, clientId=adminclient-1, correlationId=15): ApiVersionsResponseData(errorCode=0, apiKeys=[ApiVersion(apiKey=0, minVersion=0, maxVersion=6), ApiVersion(apiKey=1, minVersion=0, maxVersion=8), ApiVersion(apiKey=2, minVersion=0, maxVersion=3), ApiVersion(apiKey=3, minVersion=0, maxVersion=6), ApiVersion(apiKey=4, minVersion=0, maxVersion=1), ApiVersion(apiKey=5, minVersion=0, maxVersion=0), ApiVersion(apiKey=6, minVersion=0, maxVersion=4), ApiVersion(apiKey=7, minVersion=0, maxVersion=1), ApiVersion(apiKey=8, minVersion=0, maxVersion=4), ApiVersion(apiKey=9, minVersion=0, maxVersion=4), ApiVersion(apiKey=10, minVersion=0, maxVersion=2), ApiVersion(apiKey=11, minVersion=0, maxVersion=3), ApiVersion(apiKey=12, minVersion=0, maxVersion=2), ApiVersion(apiKey=13, minVersion=0, maxVersion=2), ApiVersion(apiKey=14, minVersion=0, maxVersion=2), ApiVersion(apiKey=15, minVersion=0, maxVersion=2), ApiVersion(apiKey=16, minVersion=0, maxVersion=2), ApiVersion(apiKey=17, minVersion=0, maxVersion=1), ApiVersion(apiKey=18, minVersion=0, maxVersion=2), ApiVersion(apiKey=19, minVersion=0, maxVersion=3), ApiVersion(apiKey=20, minVersion=0, maxVersion=2), ApiVersion(apiKey=21, minVersion=0, maxVersion=1), ApiVersion(apiKey=22, minVersion=0, maxVersion=1), ApiVersion(apiKey=23, minVersion=0, maxVersion=1), ApiVersion(apiKey=24, minVersion=0, maxVersion=1), ApiVersion(apiKey=25, minVersion=0, maxVersion=1), ApiVersion(apiKey=26, minVersion=0, maxVersion=1), ApiVersion(apiKey=27, minVersion=0, maxVersion=0), ApiVersion(apiKey=28, minVersion=0, maxVersion=1), ApiVersion(apiKey=29, minVersion=0, maxVersion=1), ApiVersion(apiKey=30, minVersion=0, maxVersion=1), ApiVersion(apiKey=31, minVersion=0, maxVersion=1), ApiVersion(apiKey=32, minVersion=0, maxVersion=2), ApiVersion(apiKey=33, minVersion=0, maxVersion=1), ApiVersion(apiKey=34, minVersion=0, maxVersion=1), ApiVersion(apiKey=35, minVersion=0, maxVersion=1), ApiVersion(apiKey=36, minVersion=0, maxVersion=0), ApiVersion(apiKey=37, minVersion=0, maxVersion=1), ApiVersion(apiKey=38, minVersion=0, maxVersion=1), ApiVersion(apiKey=39, minVersion=0, maxVersion=1), ApiVersion(apiKey=40, minVersion=0, maxVersion=1), ApiVersion(apiKey=41, minVersion=0, maxVersion=1), ApiVersion(apiKey=42, minVersion=0, maxVersion=1)], throttleTimeMs=0, supportedFeatures=[], finalizedFeaturesEpoch=-1, finalizedFeatures=[])
2023-03-04 00:41:21 [kafka-admin-client-thread | adminclient-1] DEBUG o.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Node 3 has finalized features epoch: -1, finalized features: [], supported features: [], API versions: (Produce(0): 0 to 6 [usable: 6], Fetch(1): 0 to 8 [usable: 8], ListOffsets(2): 0 to 3 [usable: 3], Metadata(3): 0 to 6 [usable: 6], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 4 [usable: 4], OffsetFetch(9): 0 to 4 [usable: 4], FindCoordinator(10): 0 to 2 [usable: 2], JoinGroup(11): 0 to 3 [usable: 3], Heartbeat(12): 0 to 2 [usable: 2], LeaveGroup(13): 0 to 2 [usable: 2], SyncGroup(14): 0 to 2 [usable: 2], DescribeGroups(15): 0 to 2 [usable: 2], ListGroups(16): 0 to 2 [usable: 2], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 2], CreateTopics(19): 0 to 3 [usable: 3], DeleteTopics(20): 0 to 2 [usable: 2], DeleteRecords(21): 0 to 1 [usable: 1], InitProducerId(22): 0 to 1 [usable: 1], OffsetForLeaderEpoch(23): 0 to 1 [usable: 1], AddPartitionsToTxn(24): 0 to 1 [usable: 1], AddOffsetsToTxn(25): 0 to 1 [usable: 1], EndTxn(26): 0 to 1 [usable: 1], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 1 [usable: 1], DescribeAcls(29): 0 to 1 [usable: 1], CreateAcls(30): 0 to 1 [usable: 1], DeleteAcls(31): 0 to 1 [usable: 1], DescribeConfigs(32): 0 to 2 [usable: 2], AlterConfigs(33): 0 to 1 [usable: 1], AlterReplicaLogDirs(34): 0 to 1 [usable: 1], DescribeLogDirs(35): 0 to 1 [usable: 1], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 1], CreateDelegationToken(38): 0 to 1 [usable: 1], RenewDelegationToken(39): 0 to 1 [usable: 1], ExpireDelegationToken(40): 0 to 1 [usable: 1], DescribeDelegationToken(41): 0 to 1 [usable: 1], DeleteGroups(42): 0 to 1 [usable: 1], ElectLeaders(43): UNSUPPORTED, IncrementalAlterConfigs(44): UNSUPPORTED, AlterPartitionReassignments(45): UNSUPPORTED, ListPartitionReassignments(46): UNSUPPORTED, OffsetDelete(47): UNSUPPORTED, DescribeClientQuotas(48): UNSUPPORTED, AlterClientQuotas(49): UNSUPPORTED, DescribeUserScramCredentials(50): UNSUPPORTED, AlterUserScramCredentials(51): UNSUPPORTED, AlterPartition(56): UNSUPPORTED, UpdateFeatures(57): UNSUPPORTED, DescribeCluster(60): UNSUPPORTED, DescribeProducers(61): UNSUPPORTED, DescribeTransactions(65): UNSUPPORTED, ListTransactions(66): UNSUPPORTED, AllocateProducerIds(67): UNSUPPORTED).
2023-03-04 00:41:21 [kafka-admin-client-thread | adminclient-1] DEBUG o.a.k.clients.admin.KafkaAdminClient - [AdminClient clientId=adminclient-1] Sending MetadataRequestData(topics=[], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to localhost:39092 (id: 3 rack: null). correlationId=16, timeoutMs=29989
2023-03-04 00:41:21 [kafka-admin-client-thread | adminclient-1] DEBUG o.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Sending METADATA request with header RequestHeader(apiKey=METADATA, apiVersion=6, clientId=adminclient-1, correlationId=16) and timeout 29989 to node 3: MetadataRequestData(topics=[], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false)
2023-03-04 00:41:21 [kafka-admin-client-thread | adminclient-1] DEBUG o.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Received METADATA response from node 3 for request with header RequestHeader(apiKey=METADATA, apiVersion=6, clientId=adminclient-1, correlationId=16): MetadataResponseData(throttleTimeMs=0, brokers=[MetadataResponseBroker(nodeId=2, host='localhost', port=29092, rack=null), MetadataResponseBroker(nodeId=1, host='localhost', port=19092, rack=null), MetadataResponseBroker(nodeId=3, host='localhost', port=39092, rack=null)], clusterId='QGDYypu5SSGtA9Bc36Rjow', controllerId=3, topics=[], clusterAuthorizedOperations=-2147483648)
2023-03-04 00:41:21 [kafka-admin-client-thread | adminclient-1] DEBUG o.a.k.c.a.i.AdminMetadataManager - [AdminClient clientId=adminclient-1] Updating cluster metadata to Cluster(id = QGDYypu5SSGtA9Bc36Rjow, nodes = [localhost:19092 (id: 1 rack: null), localhost:29092 (id: 2 rack: null), localhost:39092 (id: 3 rack: null)], partitions = [], controller = localhost:39092 (id: 3 rack: null))
2023-03-04 00:41:24 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text tempor commodo ante at commodo commodo Microservices sed a lacus arcu tempor sending to kafka topic twitter-topic
2023-03-04 00:41:24 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 5739215829262704970, "id": 5197280805179993969, "text": "tempor commodo ante at commodo commodo Microservices sed a lacus arcu tempor", "createdAt": 1677877884000}' to topic = 'twitter-topic'
2023-03-04 00:41:24 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:41:24 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 41 being sent to partition twitter-topic-1
2023-03-04 00:41:24 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=136) and timeout 60000 to node 1: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-1=199]}
2023-03-04 00:41:24 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 1 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=136): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=1, errorCode=0, baseOffset=41, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:41:24 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-1 to 41
2023-03-04 00:41:24 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:41:34 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text odio feugiat a odio Microservices odio lacinia sed sending to kafka topic twitter-topic
2023-03-04 00:41:34 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 7913315669759421543, "id": 2880005425923541905, "text": "odio feugiat a odio Microservices odio lacinia sed", "createdAt": 1677877894000}' to topic = 'twitter-topic'
2023-03-04 00:41:34 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:41:34 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 37 being sent to partition twitter-topic-0
2023-03-04 00:41:34 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=137) and timeout 60000 to node 2: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-0=178]}
2023-03-04 00:41:34 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 2 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=137): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=0, errorCode=0, baseOffset=37, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:41:34 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-0 to 37
2023-03-04 00:41:34 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:41:44 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text metus a at vestibulum lacus sed Microservices at ante sed a sending to kafka topic twitter-topic
2023-03-04 00:41:44 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 2037348494804257797, "id": 4426305331305999180, "text": "metus a at vestibulum lacus sed Microservices at ante sed a", "createdAt": 1677877904000}' to topic = 'twitter-topic'
2023-03-04 00:41:44 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:41:44 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 38 being sent to partition twitter-topic-0
2023-03-04 00:41:44 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=138) and timeout 60000 to node 2: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-0=191]}
2023-03-04 00:41:44 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 2 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=138): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=0, errorCode=0, baseOffset=38, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:41:44 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-0 to 38
2023-03-04 00:41:44 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:41:54 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text euismod tempor metus a Kafka euismod at dictum sending to kafka topic twitter-topic
2023-03-04 00:41:54 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 619299558285791026, "id": 9123681143754167192, "text": "euismod tempor metus a Kafka euismod at dictum", "createdAt": 1677877914000}' to topic = 'twitter-topic'
2023-03-04 00:41:54 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:41:54 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 42 being sent to partition twitter-topic-1
2023-03-04 00:41:54 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=139) and timeout 60000 to node 1: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-1=174]}
2023-03-04 00:41:54 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 1 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=139): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=1, errorCode=0, baseOffset=42, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:41:54 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-1 to 42
2023-03-04 00:41:54 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:42:04 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text metus quis feugiat a tempor euismod ante Java dictum dictum commodo ullamcorper non ante sending to kafka topic twitter-topic
2023-03-04 00:42:04 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 577734403195505097, "id": 1006015064374678454, "text": "metus quis feugiat a tempor euismod ante Java dictum dictum commodo ullamcorper non ante", "createdAt": 1677877924000}' to topic = 'twitter-topic'
2023-03-04 00:42:04 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:42:04 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 43 being sent to partition twitter-topic-1
2023-03-04 00:42:04 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=140) and timeout 60000 to node 1: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-1=223]}
2023-03-04 00:42:04 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 1 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=140): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=1, errorCode=0, baseOffset=43, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:42:04 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-1 to 43
2023-03-04 00:42:04 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:42:14 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text in feugiat euismod odio euismod Spring arcu tempor tempor a sending to kafka topic twitter-topic
2023-03-04 00:42:14 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 4535394323054467985, "id": 69100564895503441, "text": "in feugiat euismod odio euismod Spring arcu tempor tempor a", "createdAt": 1677877934000}' to topic = 'twitter-topic'
2023-03-04 00:42:14 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:42:14 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 44 being sent to partition twitter-topic-1
2023-03-04 00:42:14 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=141) and timeout 60000 to node 1: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-1=179]}
2023-03-04 00:42:14 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 1 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=141): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=1, errorCode=0, baseOffset=44, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:42:14 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-1 to 44
2023-03-04 00:42:14 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:42:24 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text feugiat odio sed feugiat Elasticsearch in ullamcorper sending to kafka topic twitter-topic
2023-03-04 00:42:24 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 68412972958568865, "id": 4282420439275300523, "text": "feugiat odio sed feugiat Elasticsearch in ullamcorper", "createdAt": 1677877944000}' to topic = 'twitter-topic'
2023-03-04 00:42:24 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:42:24 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 45 being sent to partition twitter-topic-1
2023-03-04 00:42:24 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=142) and timeout 60000 to node 1: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-1=183]}
2023-03-04 00:42:24 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 1 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=142): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=1, errorCode=0, baseOffset=45, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:42:24 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-1 to 45
2023-03-04 00:42:24 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:42:34 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text at at ante sed ullamcorper tempor Java ullamcorper metus at a sending to kafka topic twitter-topic
2023-03-04 00:42:34 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 4583380768379484292, "id": 52764677446387930, "text": "at at ante sed ullamcorper tempor Java ullamcorper metus at a", "createdAt": 1677877954000}' to topic = 'twitter-topic'
2023-03-04 00:42:34 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:42:34 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 42 being sent to partition twitter-topic-2
2023-03-04 00:42:34 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=143) and timeout 60000 to node 3: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-2=182]}
2023-03-04 00:42:34 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 3 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=143): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=2, errorCode=0, baseOffset=42, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:42:34 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-2 to 42
2023-03-04 00:42:34 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:42:44 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text arcu in vestibulum Elasticsearch odio at sending to kafka topic twitter-topic
2023-03-04 00:42:44 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 5041607635288548847, "id": 5673994312746926469, "text": "arcu in vestibulum Elasticsearch odio at", "createdAt": 1677877964000}' to topic = 'twitter-topic'
2023-03-04 00:42:44 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:42:44 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 46 being sent to partition twitter-topic-1
2023-03-04 00:42:44 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=144) and timeout 60000 to node 1: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-1=174]}
2023-03-04 00:42:44 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 1 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=144): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=1, errorCode=0, baseOffset=46, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:42:44 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-1 to 46
2023-03-04 00:42:44 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:42:54 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text at ante ante Kafka tempor ante sending to kafka topic twitter-topic
2023-03-04 00:42:54 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 1615192490552284339, "id": 6210302238898094186, "text": "at ante ante Kafka tempor ante", "createdAt": 1677877974000}' to topic = 'twitter-topic'
2023-03-04 00:42:54 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:42:54 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 39 being sent to partition twitter-topic-0
2023-03-04 00:42:54 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=145) and timeout 60000 to node 2: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-0=163]}
2023-03-04 00:42:54 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 2 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=145): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=0, errorCode=0, baseOffset=39, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:42:54 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-0 to 39
2023-03-04 00:42:54 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:43:04 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text lacus odio lacinia lacus at feugiat Elasticsearch euismod euismod at euismod at sending to kafka topic twitter-topic
2023-03-04 00:43:04 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 3581879931588157268, "id": 3944470993958700379, "text": "lacus odio lacinia lacus at feugiat Elasticsearch euismod euismod at euismod at", "createdAt": 1677877984000}' to topic = 'twitter-topic'
2023-03-04 00:43:04 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:43:04 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 43 being sent to partition twitter-topic-2
2023-03-04 00:43:04 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=146) and timeout 60000 to node 3: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-2=197]}
2023-03-04 00:43:04 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 3 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=146): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=2, errorCode=0, baseOffset=43, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:43:04 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-2 to 43
2023-03-04 00:43:04 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:43:14 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text ante arcu at in non Kafka sed commodo ante sending to kafka topic twitter-topic
2023-03-04 00:43:14 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 1296771039738965338, "id": 204432605593216415, "text": "ante arcu at in non Kafka sed commodo ante", "createdAt": 1677877994000}' to topic = 'twitter-topic'
2023-03-04 00:43:14 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:43:14 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 47 being sent to partition twitter-topic-1
2023-03-04 00:43:14 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=147) and timeout 60000 to node 1: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-1=174]}
2023-03-04 00:43:14 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 1 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=147): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=1, errorCode=0, baseOffset=47, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:43:14 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-1 to 47
2023-03-04 00:43:14 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:43:24 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text sed non metus at ante commodo Spring arcu dictum euismod arcu a sending to kafka topic twitter-topic
2023-03-04 00:43:24 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 8172923015792838089, "id": 453409459184896069, "text": "sed non metus at ante commodo Spring arcu dictum euismod arcu a", "createdAt": 1677878004000}' to topic = 'twitter-topic'
2023-03-04 00:43:24 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:43:24 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 40 being sent to partition twitter-topic-0
2023-03-04 00:43:24 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=148) and timeout 60000 to node 2: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-0=196]}
2023-03-04 00:43:24 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 2 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=148): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=0, errorCode=0, baseOffset=40, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:43:24 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-0 to 40
2023-03-04 00:43:24 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:43:34 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text non arcu ante non a Spring ante quis lacus sending to kafka topic twitter-topic
2023-03-04 00:43:34 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 7904221211365835301, "id": 5409363653886035140, "text": "non arcu ante non a Spring ante quis lacus", "createdAt": 1677878014000}' to topic = 'twitter-topic'
2023-03-04 00:43:34 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:43:34 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 44 being sent to partition twitter-topic-2
2023-03-04 00:43:34 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=149) and timeout 60000 to node 3: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-2=171]}
2023-03-04 00:43:34 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 3 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=149): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=2, errorCode=0, baseOffset=44, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:43:34 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-2 to 44
2023-03-04 00:43:34 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:43:44 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text a quis at Kafka arcu commodo sending to kafka topic twitter-topic
2023-03-04 00:43:44 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 680574246963041042, "id": 1124857156775499633, "text": "a quis at Kafka arcu commodo", "createdAt": 1677878024000}' to topic = 'twitter-topic'
2023-03-04 00:43:44 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:43:44 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 45 being sent to partition twitter-topic-2
2023-03-04 00:43:44 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=150) and timeout 60000 to node 3: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-2=160]}
2023-03-04 00:43:44 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 3 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=150): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=2, errorCode=0, baseOffset=45, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:43:44 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-2 to 45
2023-03-04 00:43:44 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:43:54 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text odio feugiat tempor Spring at non sending to kafka topic twitter-topic
2023-03-04 00:43:54 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 16298299538359159, "id": 2084103932173027002, "text": "odio feugiat tempor Spring at non", "createdAt": 1677878034000}' to topic = 'twitter-topic'
2023-03-04 00:43:54 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:43:54 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 46 being sent to partition twitter-topic-2
2023-03-04 00:43:54 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=151) and timeout 60000 to node 3: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-2=164]}
2023-03-04 00:43:54 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 3 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=151): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=2, errorCode=0, baseOffset=46, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:43:54 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-2 to 46
2023-03-04 00:43:54 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:44:04 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text tempor a commodo Microservices at sed sending to kafka topic twitter-topic
2023-03-04 00:44:04 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 3275159850946679940, "id": 8523760326168817332, "text": "tempor a commodo Microservices at sed", "createdAt": 1677878044000}' to topic = 'twitter-topic'
2023-03-04 00:44:04 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:44:04 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 47 being sent to partition twitter-topic-2
2023-03-04 00:44:04 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=152) and timeout 60000 to node 3: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-2=170]}
2023-03-04 00:44:04 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 3 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=152): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=2, errorCode=0, baseOffset=47, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:44:04 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-2 to 47
2023-03-04 00:44:04 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:44:14 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text non non non odio sed Kafka quis dictum a sed sending to kafka topic twitter-topic
2023-03-04 00:44:14 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 6118474307484876037, "id": 7662165714195817476, "text": "non non non odio sed Kafka quis dictum a sed", "createdAt": 1677878054000}' to topic = 'twitter-topic'
2023-03-04 00:44:14 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:44:14 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 48 being sent to partition twitter-topic-1
2023-03-04 00:44:14 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=153) and timeout 60000 to node 1: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-1=172]}
2023-03-04 00:44:14 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 1 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=153): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=1, errorCode=0, baseOffset=48, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:44:14 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-1 to 48
2023-03-04 00:44:14 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:44:24 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text commodo non euismod Elasticsearch lacinia ante sending to kafka topic twitter-topic
2023-03-04 00:44:24 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 7528059431881520105, "id": 5094836069781899827, "text": "commodo non euismod Elasticsearch lacinia ante", "createdAt": 1677878064000}' to topic = 'twitter-topic'
2023-03-04 00:44:24 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:44:24 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 49 being sent to partition twitter-topic-1
2023-03-04 00:44:24 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=154) and timeout 60000 to node 1: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-1=180]}
2023-03-04 00:44:24 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 1 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=154): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=1, errorCode=0, baseOffset=49, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:44:24 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-1 to 49
2023-03-04 00:44:24 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:44:34 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text arcu at at non Microservices lacinia lacus sending to kafka topic twitter-topic
2023-03-04 00:44:34 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 1106177128059944972, "id": 258770525865814502, "text": "arcu at at non Microservices lacinia lacus", "createdAt": 1677878074000}' to topic = 'twitter-topic'
2023-03-04 00:44:34 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:44:34 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 41 being sent to partition twitter-topic-0
2023-03-04 00:44:34 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=155) and timeout 60000 to node 2: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-0=172]}
2023-03-04 00:44:34 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 2 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=155): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=0, errorCode=0, baseOffset=41, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:44:34 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-0 to 41
2023-03-04 00:44:34 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:44:44 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text in at at ante arcu at feugiat quis Spring at vestibulum in in in at sending to kafka topic twitter-topic
2023-03-04 00:44:44 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 3587253075647620268, "id": 3995428216035548053, "text": "in at at ante arcu at feugiat quis Spring at vestibulum in in in at", "createdAt": 1677878084000}' to topic = 'twitter-topic'
2023-03-04 00:44:44 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:44:44 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 48 being sent to partition twitter-topic-2
2023-03-04 00:44:44 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=156) and timeout 60000 to node 3: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-2=196]}
2023-03-04 00:44:44 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 3 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=156): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=2, errorCode=0, baseOffset=48, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:44:44 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-2 to 48
2023-03-04 00:44:44 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:44:54 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text vestibulum commodo tempor feugiat Elasticsearch commodo in sending to kafka topic twitter-topic
2023-03-04 00:44:54 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 6274526104398862200, "id": 8999071133481750399, "text": "vestibulum commodo tempor feugiat Elasticsearch commodo in", "createdAt": 1677878094000}' to topic = 'twitter-topic'
2023-03-04 00:44:54 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:44:54 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 49 being sent to partition twitter-topic-2
2023-03-04 00:44:54 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=157) and timeout 60000 to node 3: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-2=192]}
2023-03-04 00:44:54 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 3 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=157): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=2, errorCode=0, baseOffset=49, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:44:54 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-2 to 49
2023-03-04 00:44:54 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:45:04 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text at tempor arcu sed commodo euismod Java at in ullamcorper feugiat sending to kafka topic twitter-topic
2023-03-04 00:45:04 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 8826650245744651017, "id": 2333389072716822085, "text": "at tempor arcu sed commodo euismod Java at in ullamcorper feugiat", "createdAt": 1677878104000}' to topic = 'twitter-topic'
2023-03-04 00:45:04 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:45:04 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 50 being sent to partition twitter-topic-2
2023-03-04 00:45:04 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=158) and timeout 60000 to node 3: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-2=199]}
2023-03-04 00:45:04 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 3 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=158): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=2, errorCode=0, baseOffset=50, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:45:04 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-2 to 50
2023-03-04 00:45:04 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:45:14 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text metus commodo in metus at sed Java metus non commodo euismod ante sending to kafka topic twitter-topic
2023-03-04 00:45:14 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 6540910644271829366, "id": 3763264670474476274, "text": "metus commodo in metus at sed Java metus non commodo euismod ante", "createdAt": 1677878114000}' to topic = 'twitter-topic'
2023-03-04 00:45:14 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:45:14 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 51 being sent to partition twitter-topic-2
2023-03-04 00:45:14 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=159) and timeout 60000 to node 3: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-2=186]}
2023-03-04 00:45:14 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 3 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=159): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=2, errorCode=0, baseOffset=51, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:45:14 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-2 to 51
2023-03-04 00:45:14 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:45:24 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending metadata request MetadataRequestData(topics=[MetadataRequestTopic(topicId=AAAAAAAAAAAAAAAAAAAAAA, name='twitter-topic')], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to node localhost:19092 (id: 1 rack: null)
2023-03-04 00:45:24 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending METADATA request with header RequestHeader(apiKey=METADATA, apiVersion=6, clientId=producer-1, correlationId=160) and timeout 60000 to node 1: MetadataRequestData(topics=[MetadataRequestTopic(topicId=AAAAAAAAAAAAAAAAAAAAAA, name='twitter-topic')], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false)
2023-03-04 00:45:24 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received METADATA response from node 1 for request with header RequestHeader(apiKey=METADATA, apiVersion=6, clientId=producer-1, correlationId=160): MetadataResponseData(throttleTimeMs=0, brokers=[MetadataResponseBroker(nodeId=2, host='localhost', port=29092, rack=null), MetadataResponseBroker(nodeId=1, host='localhost', port=19092, rack=null), MetadataResponseBroker(nodeId=3, host='localhost', port=39092, rack=null)], clusterId='QGDYypu5SSGtA9Bc36Rjow', controllerId=3, topics=[MetadataResponseTopic(errorCode=0, name='twitter-topic', topicId=AAAAAAAAAAAAAAAAAAAAAA, isInternal=false, partitions=[MetadataResponsePartition(errorCode=0, partitionIndex=2, leaderId=3, leaderEpoch=-1, replicaNodes=[3, 2, 1], isrNodes=[3, 2, 1], offlineReplicas=[]), MetadataResponsePartition(errorCode=0, partitionIndex=1, leaderId=1, leaderEpoch=-1, replicaNodes=[1, 3, 2], isrNodes=[1, 3, 2], offlineReplicas=[]), MetadataResponsePartition(errorCode=0, partitionIndex=0, leaderId=2, leaderEpoch=-1, replicaNodes=[2, 1, 3], isrNodes=[2, 1, 3], offlineReplicas=[])], topicAuthorizedOperations=-2147483648)], clusterAuthorizedOperations=-2147483648)
2023-03-04 00:45:24 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Updated cluster metadata updateVersion 7 to MetadataCache{clusterId='QGDYypu5SSGtA9Bc36Rjow', nodes={1=localhost:19092 (id: 1 rack: null), 2=localhost:29092 (id: 2 rack: null), 3=localhost:39092 (id: 3 rack: null)}, partitions=[PartitionMetadata(error=NONE, partition=twitter-topic-0, leader=Optional[2], leaderEpoch=Optional.empty, replicas=2,1,3, isr=2,1,3, offlineReplicas=), PartitionMetadata(error=NONE, partition=twitter-topic-1, leader=Optional[1], leaderEpoch=Optional.empty, replicas=1,3,2, isr=1,3,2, offlineReplicas=), PartitionMetadata(error=NONE, partition=twitter-topic-2, leader=Optional[3], leaderEpoch=Optional.empty, replicas=3,2,1, isr=3,2,1, offlineReplicas=)], controller=localhost:39092 (id: 3 rack: null)}
2023-03-04 00:45:24 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text at vestibulum at Elasticsearch ullamcorper euismod sending to kafka topic twitter-topic
2023-03-04 00:45:24 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 5772044536270419138, "id": 2307550695939516312, "text": "at vestibulum at Elasticsearch ullamcorper euismod", "createdAt": 1677878124000}' to topic = 'twitter-topic'
2023-03-04 00:45:24 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:45:24 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 50 being sent to partition twitter-topic-1
2023-03-04 00:45:24 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=161) and timeout 60000 to node 1: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-1=183]}
2023-03-04 00:45:24 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 1 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=161): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=1, errorCode=0, baseOffset=50, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:45:24 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-1 to 50
2023-03-04 00:45:24 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:45:34 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text a at at feugiat at lacus lacinia sed Elasticsearch vestibulum arcu a sed sed quis sending to kafka topic twitter-topic
2023-03-04 00:45:34 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 2842376599923315393, "id": 6138380325364360142, "text": "a at at feugiat at lacus lacinia sed Elasticsearch vestibulum arcu a sed sed quis", "createdAt": 1677878134000}' to topic = 'twitter-topic'
2023-03-04 00:45:34 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:45:34 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 52 being sent to partition twitter-topic-2
2023-03-04 00:45:34 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=162) and timeout 60000 to node 3: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-2=214]}
2023-03-04 00:45:34 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 3 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=162): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=2, errorCode=0, baseOffset=52, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:45:34 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-2 to 52
2023-03-04 00:45:34 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:45:44 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text non arcu in at at tempor tempor metus Kafka non tempor feugiat at euismod odio dictum sending to kafka topic twitter-topic
2023-03-04 00:45:44 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 4108855752061710997, "id": 5197437182652307560, "text": "non arcu in at at tempor tempor metus Kafka non tempor feugiat at euismod odio dictum", "createdAt": 1677878144000}' to topic = 'twitter-topic'
2023-03-04 00:45:44 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:45:44 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 51 being sent to partition twitter-topic-1
2023-03-04 00:45:44 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=163) and timeout 60000 to node 1: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-1=208]}
2023-03-04 00:45:44 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 1 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=163): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=1, errorCode=0, baseOffset=51, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:45:44 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-1 to 51
2023-03-04 00:45:44 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:45:54 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text quis arcu ante odio Elasticsearch ante odio sending to kafka topic twitter-topic
2023-03-04 00:45:54 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 2410713896890051945, "id": 3851837135354861847, "text": "quis arcu ante odio Elasticsearch ante odio", "createdAt": 1677878154000}' to topic = 'twitter-topic'
2023-03-04 00:45:54 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:45:54 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 52 being sent to partition twitter-topic-1
2023-03-04 00:45:54 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=164) and timeout 60000 to node 1: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-1=167]}
2023-03-04 00:45:54 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 1 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=164): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=1, errorCode=0, baseOffset=52, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:45:54 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-1 to 52
2023-03-04 00:45:54 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:46:04 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text lacus at dictum arcu metus commodo at Elasticsearch non lacinia lacinia ullamcorper odio sending to kafka topic twitter-topic
2023-03-04 00:46:04 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 7773970123271717547, "id": 8549420164758565137, "text": "lacus at dictum arcu metus commodo at Elasticsearch non lacinia lacinia ullamcorper odio", "createdAt": 1677878164000}' to topic = 'twitter-topic'
2023-03-04 00:46:04 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:46:04 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 53 being sent to partition twitter-topic-2
2023-03-04 00:46:04 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=165) and timeout 60000 to node 3: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-2=222]}
2023-03-04 00:46:04 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 3 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=165): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=2, errorCode=0, baseOffset=53, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:46:04 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-2 to 53
2023-03-04 00:46:04 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:46:14 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text euismod at dictum non metus euismod non Elasticsearch vestibulum lacinia a at commodo sending to kafka topic twitter-topic
2023-03-04 00:46:14 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 2236945920566410649, "id": 5183646434338862639, "text": "euismod at dictum non metus euismod non Elasticsearch vestibulum lacinia a at commodo", "createdAt": 1677878174000}' to topic = 'twitter-topic'
2023-03-04 00:46:14 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:46:14 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 42 being sent to partition twitter-topic-0
2023-03-04 00:46:14 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=166) and timeout 60000 to node 2: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-0=214]}
2023-03-04 00:46:14 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 2 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=166): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=0, errorCode=0, baseOffset=42, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:46:14 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-0 to 42
2023-03-04 00:46:14 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:46:21 [kafka-admin-client-thread | adminclient-1] INFO  o.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Node 3 disconnected.
2023-03-04 00:46:21 [kafka-admin-client-thread | adminclient-1] DEBUG o.a.k.c.a.i.AdminMetadataManager - [AdminClient clientId=adminclient-1] Requesting metadata update.
2023-03-04 00:46:21 [kafka-admin-client-thread | adminclient-1] DEBUG o.apache.kafka.clients.ClientUtils - Resolved host localhost as 127.0.0.1
2023-03-04 00:46:21 [kafka-admin-client-thread | adminclient-1] DEBUG o.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Initiating connection to node localhost:29092 (id: 2 rack: null) using address localhost/127.0.0.1
2023-03-04 00:46:21 [kafka-admin-client-thread | adminclient-1] DEBUG o.a.kafka.common.network.Selector - [AdminClient clientId=adminclient-1] Created socket with SO_RCVBUF = 342972, SO_SNDBUF = 146988, SO_TIMEOUT = 0 to node 2
2023-03-04 00:46:21 [kafka-admin-client-thread | adminclient-1] DEBUG o.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Completed connection to node 2. Fetching API versions.
2023-03-04 00:46:21 [kafka-admin-client-thread | adminclient-1] DEBUG o.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Initiating API versions fetch from node 2.
2023-03-04 00:46:21 [kafka-admin-client-thread | adminclient-1] DEBUG o.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Sending API_VERSIONS request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=adminclient-1, correlationId=17) and timeout 3600000 to node 2: ApiVersionsRequestData(clientSoftwareName='apache-kafka-java', clientSoftwareVersion='3.3.2')
2023-03-04 00:46:21 [kafka-admin-client-thread | adminclient-1] DEBUG o.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Received API_VERSIONS response from node 2 for request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=adminclient-1, correlationId=17): ApiVersionsResponseData(errorCode=35, apiKeys=[], throttleTimeMs=0, supportedFeatures=[], finalizedFeaturesEpoch=-1, finalizedFeatures=[])
2023-03-04 00:46:21 [kafka-admin-client-thread | adminclient-1] DEBUG o.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Initiating API versions fetch from node 2.
2023-03-04 00:46:21 [kafka-admin-client-thread | adminclient-1] DEBUG o.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Sending API_VERSIONS request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=0, clientId=adminclient-1, correlationId=18) and timeout 3600000 to node 2: ApiVersionsRequestData(clientSoftwareName='apache-kafka-java', clientSoftwareVersion='3.3.2')
2023-03-04 00:46:21 [kafka-admin-client-thread | adminclient-1] DEBUG o.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Received API_VERSIONS response from node 2 for request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=0, clientId=adminclient-1, correlationId=18): ApiVersionsResponseData(errorCode=0, apiKeys=[ApiVersion(apiKey=0, minVersion=0, maxVersion=6), ApiVersion(apiKey=1, minVersion=0, maxVersion=8), ApiVersion(apiKey=2, minVersion=0, maxVersion=3), ApiVersion(apiKey=3, minVersion=0, maxVersion=6), ApiVersion(apiKey=4, minVersion=0, maxVersion=1), ApiVersion(apiKey=5, minVersion=0, maxVersion=0), ApiVersion(apiKey=6, minVersion=0, maxVersion=4), ApiVersion(apiKey=7, minVersion=0, maxVersion=1), ApiVersion(apiKey=8, minVersion=0, maxVersion=4), ApiVersion(apiKey=9, minVersion=0, maxVersion=4), ApiVersion(apiKey=10, minVersion=0, maxVersion=2), ApiVersion(apiKey=11, minVersion=0, maxVersion=3), ApiVersion(apiKey=12, minVersion=0, maxVersion=2), ApiVersion(apiKey=13, minVersion=0, maxVersion=2), ApiVersion(apiKey=14, minVersion=0, maxVersion=2), ApiVersion(apiKey=15, minVersion=0, maxVersion=2), ApiVersion(apiKey=16, minVersion=0, maxVersion=2), ApiVersion(apiKey=17, minVersion=0, maxVersion=1), ApiVersion(apiKey=18, minVersion=0, maxVersion=2), ApiVersion(apiKey=19, minVersion=0, maxVersion=3), ApiVersion(apiKey=20, minVersion=0, maxVersion=2), ApiVersion(apiKey=21, minVersion=0, maxVersion=1), ApiVersion(apiKey=22, minVersion=0, maxVersion=1), ApiVersion(apiKey=23, minVersion=0, maxVersion=1), ApiVersion(apiKey=24, minVersion=0, maxVersion=1), ApiVersion(apiKey=25, minVersion=0, maxVersion=1), ApiVersion(apiKey=26, minVersion=0, maxVersion=1), ApiVersion(apiKey=27, minVersion=0, maxVersion=0), ApiVersion(apiKey=28, minVersion=0, maxVersion=1), ApiVersion(apiKey=29, minVersion=0, maxVersion=1), ApiVersion(apiKey=30, minVersion=0, maxVersion=1), ApiVersion(apiKey=31, minVersion=0, maxVersion=1), ApiVersion(apiKey=32, minVersion=0, maxVersion=2), ApiVersion(apiKey=33, minVersion=0, maxVersion=1), ApiVersion(apiKey=34, minVersion=0, maxVersion=1), ApiVersion(apiKey=35, minVersion=0, maxVersion=1), ApiVersion(apiKey=36, minVersion=0, maxVersion=0), ApiVersion(apiKey=37, minVersion=0, maxVersion=1), ApiVersion(apiKey=38, minVersion=0, maxVersion=1), ApiVersion(apiKey=39, minVersion=0, maxVersion=1), ApiVersion(apiKey=40, minVersion=0, maxVersion=1), ApiVersion(apiKey=41, minVersion=0, maxVersion=1), ApiVersion(apiKey=42, minVersion=0, maxVersion=1)], throttleTimeMs=0, supportedFeatures=[], finalizedFeaturesEpoch=-1, finalizedFeatures=[])
2023-03-04 00:46:21 [kafka-admin-client-thread | adminclient-1] DEBUG o.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Node 2 has finalized features epoch: -1, finalized features: [], supported features: [], API versions: (Produce(0): 0 to 6 [usable: 6], Fetch(1): 0 to 8 [usable: 8], ListOffsets(2): 0 to 3 [usable: 3], Metadata(3): 0 to 6 [usable: 6], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 4 [usable: 4], OffsetFetch(9): 0 to 4 [usable: 4], FindCoordinator(10): 0 to 2 [usable: 2], JoinGroup(11): 0 to 3 [usable: 3], Heartbeat(12): 0 to 2 [usable: 2], LeaveGroup(13): 0 to 2 [usable: 2], SyncGroup(14): 0 to 2 [usable: 2], DescribeGroups(15): 0 to 2 [usable: 2], ListGroups(16): 0 to 2 [usable: 2], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 2], CreateTopics(19): 0 to 3 [usable: 3], DeleteTopics(20): 0 to 2 [usable: 2], DeleteRecords(21): 0 to 1 [usable: 1], InitProducerId(22): 0 to 1 [usable: 1], OffsetForLeaderEpoch(23): 0 to 1 [usable: 1], AddPartitionsToTxn(24): 0 to 1 [usable: 1], AddOffsetsToTxn(25): 0 to 1 [usable: 1], EndTxn(26): 0 to 1 [usable: 1], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 1 [usable: 1], DescribeAcls(29): 0 to 1 [usable: 1], CreateAcls(30): 0 to 1 [usable: 1], DeleteAcls(31): 0 to 1 [usable: 1], DescribeConfigs(32): 0 to 2 [usable: 2], AlterConfigs(33): 0 to 1 [usable: 1], AlterReplicaLogDirs(34): 0 to 1 [usable: 1], DescribeLogDirs(35): 0 to 1 [usable: 1], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 1], CreateDelegationToken(38): 0 to 1 [usable: 1], RenewDelegationToken(39): 0 to 1 [usable: 1], ExpireDelegationToken(40): 0 to 1 [usable: 1], DescribeDelegationToken(41): 0 to 1 [usable: 1], DeleteGroups(42): 0 to 1 [usable: 1], ElectLeaders(43): UNSUPPORTED, IncrementalAlterConfigs(44): UNSUPPORTED, AlterPartitionReassignments(45): UNSUPPORTED, ListPartitionReassignments(46): UNSUPPORTED, OffsetDelete(47): UNSUPPORTED, DescribeClientQuotas(48): UNSUPPORTED, AlterClientQuotas(49): UNSUPPORTED, DescribeUserScramCredentials(50): UNSUPPORTED, AlterUserScramCredentials(51): UNSUPPORTED, AlterPartition(56): UNSUPPORTED, UpdateFeatures(57): UNSUPPORTED, DescribeCluster(60): UNSUPPORTED, DescribeProducers(61): UNSUPPORTED, DescribeTransactions(65): UNSUPPORTED, ListTransactions(66): UNSUPPORTED, AllocateProducerIds(67): UNSUPPORTED).
2023-03-04 00:46:21 [kafka-admin-client-thread | adminclient-1] DEBUG o.a.k.clients.admin.KafkaAdminClient - [AdminClient clientId=adminclient-1] Sending MetadataRequestData(topics=[], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to localhost:29092 (id: 2 rack: null). correlationId=19, timeoutMs=29981
2023-03-04 00:46:21 [kafka-admin-client-thread | adminclient-1] DEBUG o.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Sending METADATA request with header RequestHeader(apiKey=METADATA, apiVersion=6, clientId=adminclient-1, correlationId=19) and timeout 29981 to node 2: MetadataRequestData(topics=[], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false)
2023-03-04 00:46:21 [kafka-admin-client-thread | adminclient-1] DEBUG o.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Received METADATA response from node 2 for request with header RequestHeader(apiKey=METADATA, apiVersion=6, clientId=adminclient-1, correlationId=19): MetadataResponseData(throttleTimeMs=0, brokers=[MetadataResponseBroker(nodeId=2, host='localhost', port=29092, rack=null), MetadataResponseBroker(nodeId=1, host='localhost', port=19092, rack=null), MetadataResponseBroker(nodeId=3, host='localhost', port=39092, rack=null)], clusterId='QGDYypu5SSGtA9Bc36Rjow', controllerId=3, topics=[], clusterAuthorizedOperations=-2147483648)
2023-03-04 00:46:21 [kafka-admin-client-thread | adminclient-1] DEBUG o.a.k.c.a.i.AdminMetadataManager - [AdminClient clientId=adminclient-1] Updating cluster metadata to Cluster(id = QGDYypu5SSGtA9Bc36Rjow, nodes = [localhost:39092 (id: 3 rack: null), localhost:19092 (id: 1 rack: null), localhost:29092 (id: 2 rack: null)], partitions = [], controller = localhost:39092 (id: 3 rack: null))
2023-03-04 00:46:24 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text in feugiat dictum lacus euismod quis at lacinia Elasticsearch non ante lacinia sed lacus dictum a sending to kafka topic twitter-topic
2023-03-04 00:46:24 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 2773923908398201510, "id": 1404845673110542060, "text": "in feugiat dictum lacus euismod quis at lacinia Elasticsearch non ante lacinia sed lacus dictum a", "createdAt": 1677878184000}' to topic = 'twitter-topic'
2023-03-04 00:46:24 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:46:24 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 43 being sent to partition twitter-topic-0
2023-03-04 00:46:24 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=167) and timeout 60000 to node 2: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-0=228]}
2023-03-04 00:46:24 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 2 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=167): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=0, errorCode=0, baseOffset=43, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:46:24 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-0 to 43
2023-03-04 00:46:24 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:46:34 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text vestibulum ante euismod feugiat feugiat Spring ante lacus arcu sed sending to kafka topic twitter-topic
2023-03-04 00:46:34 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 5572108961517092343, "id": 1653923191612819498, "text": "vestibulum ante euismod feugiat feugiat Spring ante lacus arcu sed", "createdAt": 1677878194000}' to topic = 'twitter-topic'
2023-03-04 00:46:34 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:46:34 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 53 being sent to partition twitter-topic-1
2023-03-04 00:46:34 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=168) and timeout 60000 to node 1: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-1=191]}
2023-03-04 00:46:34 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 1 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=168): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=1, errorCode=0, baseOffset=53, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:46:34 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-1 to 53
2023-03-04 00:46:34 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:46:44 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text in ante arcu ante tempor metus sed Java odio odio metus lacus lacinia sending to kafka topic twitter-topic
2023-03-04 00:46:44 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 1292787762534523374, "id": 8414701551407420821, "text": "in ante arcu ante tempor metus sed Java odio odio metus lacus lacinia", "createdAt": 1677878204000}' to topic = 'twitter-topic'
2023-03-04 00:46:44 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:46:44 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 54 being sent to partition twitter-topic-2
2023-03-04 00:46:44 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=169) and timeout 60000 to node 3: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-2=192]}
2023-03-04 00:46:44 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 3 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=169): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=2, errorCode=0, baseOffset=54, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:46:44 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-2 to 54
2023-03-04 00:46:44 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:46:54 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text in quis sed commodo Microservices in ante sending to kafka topic twitter-topic
2023-03-04 00:46:54 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 6144011747964027581, "id": 1754643637506205213, "text": "in quis sed commodo Microservices in ante", "createdAt": 1677878214000}' to topic = 'twitter-topic'
2023-03-04 00:46:54 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:46:54 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 44 being sent to partition twitter-topic-0
2023-03-04 00:46:54 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=170) and timeout 60000 to node 2: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-0=174]}
2023-03-04 00:46:55 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 2 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=170): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=0, errorCode=0, baseOffset=44, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:46:55 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-0 to 44
2023-03-04 00:46:55 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:47:04 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text in odio lacus quis ante quis Java commodo at tempor in arcu sending to kafka topic twitter-topic
2023-03-04 00:47:04 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 4817944182545640987, "id": 1510083088298091380, "text": "in odio lacus quis ante quis Java commodo at tempor in arcu", "createdAt": 1677878224000}' to topic = 'twitter-topic'
2023-03-04 00:47:04 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:47:04 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 54 being sent to partition twitter-topic-1
2023-03-04 00:47:04 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=171) and timeout 60000 to node 1: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-1=189]}
2023-03-04 00:47:05 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 1 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=171): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=1, errorCode=0, baseOffset=54, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:47:05 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-1 to 54
2023-03-04 00:47:05 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:47:14 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text ullamcorper lacus tempor at in Elasticsearch tempor vestibulum lacinia sending to kafka topic twitter-topic
2023-03-04 00:47:14 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 1807567045746823846, "id": 7166467597848275605, "text": "ullamcorper lacus tempor at in Elasticsearch tempor vestibulum lacinia", "createdAt": 1677878234000}' to topic = 'twitter-topic'
2023-03-04 00:47:14 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:47:15 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 55 being sent to partition twitter-topic-1
2023-03-04 00:47:15 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=172) and timeout 60000 to node 1: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-1=198]}
2023-03-04 00:47:15 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 1 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=172): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=1, errorCode=0, baseOffset=55, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:47:15 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-1 to 55
2023-03-04 00:47:15 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:47:24 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text dictum dictum at ullamcorper feugiat commodo vestibulum Spring commodo dictum quis metus metus at sending to kafka topic twitter-topic
2023-03-04 00:47:24 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 7391262926837199160, "id": 7620731494533339506, "text": "dictum dictum at ullamcorper feugiat commodo vestibulum Spring commodo dictum quis metus metus at", "createdAt": 1677878244000}' to topic = 'twitter-topic'
2023-03-04 00:47:25 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:47:25 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 45 being sent to partition twitter-topic-0
2023-03-04 00:47:25 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=173) and timeout 60000 to node 2: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-0=215]}
2023-03-04 00:47:25 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 2 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=173): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=0, errorCode=0, baseOffset=45, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:47:25 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-0 to 45
2023-03-04 00:47:25 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:47:35 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text quis non vestibulum dictum commodo Kafka tempor euismod at commodo sending to kafka topic twitter-topic
2023-03-04 00:47:35 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 6869703792224727431, "id": 5547148076931115879, "text": "quis non vestibulum dictum commodo Kafka tempor euismod at commodo", "createdAt": 1677878255000}' to topic = 'twitter-topic'
2023-03-04 00:47:35 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:47:35 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 46 being sent to partition twitter-topic-0
2023-03-04 00:47:35 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=174) and timeout 60000 to node 2: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-0=201]}
2023-03-04 00:47:35 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 2 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=174): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=0, errorCode=0, baseOffset=46, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:47:35 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-0 to 46
2023-03-04 00:47:35 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:47:45 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text feugiat at feugiat quis arcu a feugiat commodo Microservices non a metus sed tempor euismod sending to kafka topic twitter-topic
2023-03-04 00:47:45 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 3164585415752985235, "id": 7055578884307818290, "text": "feugiat at feugiat quis arcu a feugiat commodo Microservices non a metus sed tempor euismod", "createdAt": 1677878265000}' to topic = 'twitter-topic'
2023-03-04 00:47:45 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:47:45 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 55 being sent to partition twitter-topic-2
2023-03-04 00:47:45 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=175) and timeout 60000 to node 3: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-2=222]}
2023-03-04 00:47:45 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 3 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=175): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=2, errorCode=0, baseOffset=55, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:47:45 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-2 to 55
2023-03-04 00:47:45 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:47:55 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text arcu in arcu tempor in quis sed Kafka feugiat euismod a sed odio sending to kafka topic twitter-topic
2023-03-04 00:47:55 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 5069711482772094629, "id": 823748261507660197, "text": "arcu in arcu tempor in quis sed Kafka feugiat euismod a sed odio", "createdAt": 1677878275000}' to topic = 'twitter-topic'
2023-03-04 00:47:55 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:47:55 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 56 being sent to partition twitter-topic-1
2023-03-04 00:47:55 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=176) and timeout 60000 to node 1: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-1=192]}
2023-03-04 00:47:55 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 1 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=176): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=1, errorCode=0, baseOffset=56, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:47:55 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-1 to 56
2023-03-04 00:47:55 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:48:05 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text ullamcorper sed a feugiat Kafka lacinia quis lacus sending to kafka topic twitter-topic
2023-03-04 00:48:05 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 5643354113995828560, "id": 7794046659894246259, "text": "ullamcorper sed a feugiat Kafka lacinia quis lacus", "createdAt": 1677878285000}' to topic = 'twitter-topic'
2023-03-04 00:48:05 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:48:05 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 57 being sent to partition twitter-topic-1
2023-03-04 00:48:05 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=177) and timeout 60000 to node 1: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-1=184]}
2023-03-04 00:48:05 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 1 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=177): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=1, errorCode=0, baseOffset=57, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:48:05 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-1 to 57
2023-03-04 00:48:05 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:48:15 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text lacinia non dictum quis ullamcorper euismod Elasticsearch commodo ante quis lacinia ullamcorper sending to kafka topic twitter-topic
2023-03-04 00:48:15 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 3297166918733045075, "id": 7896150965377716435, "text": "lacinia non dictum quis ullamcorper euismod Elasticsearch commodo ante quis lacinia ullamcorper", "createdAt": 1677878295000}' to topic = 'twitter-topic'
2023-03-04 00:48:15 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:48:15 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 56 being sent to partition twitter-topic-2
2023-03-04 00:48:15 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=178) and timeout 60000 to node 3: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-2=217]}
2023-03-04 00:48:15 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 3 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=178): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=2, errorCode=0, baseOffset=56, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:48:15 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-2 to 56
2023-03-04 00:48:15 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:48:25 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text lacus at non lacinia non lacinia commodo euismod Elasticsearch euismod commodo quis tempor odio euismod euismod sending to kafka topic twitter-topic
2023-03-04 00:48:25 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 7780746917394726021, "id": 662608880620956782, "text": "lacus at non lacinia non lacinia commodo euismod Elasticsearch euismod commodo quis tempor odio euismod euismod", "createdAt": 1677878305000}' to topic = 'twitter-topic'
2023-03-04 00:48:25 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:48:25 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 58 being sent to partition twitter-topic-1
2023-03-04 00:48:25 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=179) and timeout 60000 to node 1: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-1=218]}
2023-03-04 00:48:25 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 1 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=179): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=1, errorCode=0, baseOffset=58, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:48:25 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-1 to 58
2023-03-04 00:48:25 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:48:35 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text metus lacinia feugiat in sed ante ullamcorper at Java arcu sed vestibulum feugiat a feugiat sending to kafka topic twitter-topic
2023-03-04 00:48:35 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 6211819375085100939, "id": 7734266387573861433, "text": "metus lacinia feugiat in sed ante ullamcorper at Java arcu sed vestibulum feugiat a feugiat", "createdAt": 1677878315000}' to topic = 'twitter-topic'
2023-03-04 00:48:35 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:48:35 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 59 being sent to partition twitter-topic-1
2023-03-04 00:48:35 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=180) and timeout 60000 to node 1: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-1=215]}
2023-03-04 00:48:35 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 1 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=180): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=1, errorCode=0, baseOffset=59, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:48:35 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-1 to 59
2023-03-04 00:48:35 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:48:45 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text commodo at at lacus Microservices vestibulum lacus at sending to kafka topic twitter-topic
2023-03-04 00:48:45 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 2333486688731124201, "id": 7492824890203610432, "text": "commodo at at lacus Microservices vestibulum lacus at", "createdAt": 1677878325000}' to topic = 'twitter-topic'
2023-03-04 00:48:45 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:48:45 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 60 being sent to partition twitter-topic-1
2023-03-04 00:48:45 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=181) and timeout 60000 to node 1: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-1=180]}
2023-03-04 00:48:45 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 1 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=181): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=1, errorCode=0, baseOffset=60, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:48:45 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-1 to 60
2023-03-04 00:48:45 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:48:55 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text at arcu at arcu a lacinia feugiat a Kafka non feugiat dictum feugiat arcu commodo at sending to kafka topic twitter-topic
2023-03-04 00:48:55 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 5306980276727996305, "id": 6826187218776846480, "text": "at arcu at arcu a lacinia feugiat a Kafka non feugiat dictum feugiat arcu commodo at", "createdAt": 1677878335000}' to topic = 'twitter-topic'
2023-03-04 00:48:55 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:48:55 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 47 being sent to partition twitter-topic-0
2023-03-04 00:48:55 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=182) and timeout 60000 to node 2: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-0=200]}
2023-03-04 00:48:55 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 2 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=182): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=0, errorCode=0, baseOffset=47, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:48:55 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-0 to 47
2023-03-04 00:48:55 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:49:05 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text at euismod euismod quis ullamcorper Java quis odio tempor sending to kafka topic twitter-topic
2023-03-04 00:49:05 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 7599135636021136421, "id": 6738227023808708898, "text": "at euismod euismod quis ullamcorper Java quis odio tempor", "createdAt": 1677878345000}' to topic = 'twitter-topic'
2023-03-04 00:49:05 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:49:05 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 48 being sent to partition twitter-topic-0
2023-03-04 00:49:05 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=183) and timeout 60000 to node 2: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-0=182]}
2023-03-04 00:49:05 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 2 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=183): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=0, errorCode=0, baseOffset=48, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:49:05 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-0 to 48
2023-03-04 00:49:05 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:49:15 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text vestibulum at tempor Microservices a at sending to kafka topic twitter-topic
2023-03-04 00:49:15 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 1385806621994929625, "id": 5346845210762959280, "text": "vestibulum at tempor Microservices a at", "createdAt": 1677878355000}' to topic = 'twitter-topic'
2023-03-04 00:49:15 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:49:15 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 61 being sent to partition twitter-topic-1
2023-03-04 00:49:15 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=184) and timeout 60000 to node 1: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-1=172]}
2023-03-04 00:49:15 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 1 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=184): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=1, errorCode=0, baseOffset=61, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:49:15 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-1 to 61
2023-03-04 00:49:15 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:49:25 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text a feugiat a ante quis euismod Microservices euismod metus lacus sed lacus sending to kafka topic twitter-topic
2023-03-04 00:49:25 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 1425401734823087023, "id": 2200225275402127691, "text": "a feugiat a ante quis euismod Microservices euismod metus lacus sed lacus", "createdAt": 1677878365000}' to topic = 'twitter-topic'
2023-03-04 00:49:25 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:49:25 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 57 being sent to partition twitter-topic-2
2023-03-04 00:49:25 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=185) and timeout 60000 to node 3: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-2=199]}
2023-03-04 00:49:25 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 3 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=185): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=2, errorCode=0, baseOffset=57, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:49:25 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-2 to 57
2023-03-04 00:49:25 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:49:35 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text non metus lacus ante metus at lacus Spring arcu lacinia vestibulum a lacinia lacus sending to kafka topic twitter-topic
2023-03-04 00:49:35 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 8173339351813773068, "id": 2655418161885190160, "text": "non metus lacus ante metus at lacus Spring arcu lacinia vestibulum a lacinia lacus", "createdAt": 1677878375000}' to topic = 'twitter-topic'
2023-03-04 00:49:35 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:49:35 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 49 being sent to partition twitter-topic-0
2023-03-04 00:49:35 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=186) and timeout 60000 to node 2: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-0=218]}
2023-03-04 00:49:35 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 2 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=186): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=0, errorCode=0, baseOffset=49, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:49:35 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-0 to 49
2023-03-04 00:49:35 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:49:45 [pool-3-thread-1] INFO  x.g.m.d.t.t.k.s.l.TwitterKafkaStatusListener - Received status text arcu at quis Kafka vestibulum commodo sending to kafka topic twitter-topic
2023-03-04 00:49:45 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Sending message = '{"userId": 2682355696114458000, "id": 3982560052316707289, "text": "arcu at quis Kafka vestibulum commodo", "createdAt": 1677878385000}' to topic = 'twitter-topic'
2023-03-04 00:49:45 [pool-3-thread-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - ADDING THE CALLBACK
2023-03-04 00:49:45 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 3000 and producerEpoch 0 to batch with base sequence 58 being sent to partition twitter-topic-2
2023-03-04 00:49:45 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=187) and timeout 60000 to node 3: {acks=-1,timeout=60000,partitionSizes=[twitter-topic-2=169]}
2023-03-04 00:49:45 [kafka-producer-network-thread | producer-1] DEBUG o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 3 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=6, clientId=producer-1, correlationId=187): ProduceResponseData(responses=[TopicProduceResponse(name='twitter-topic', partitionResponses=[PartitionProduceResponse(index=2, errorCode=0, baseOffset=58, logAppendTimeMs=-1, logStartOffset=0, recordErrors=[], errorMessage=null)])], throttleTimeMs=0)
2023-03-04 00:49:45 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId: 3000; Set last ack'd sequence number for topic-partition twitter-topic-2 to 58
2023-03-04 00:49:45 [kafka-producer-network-thread | producer-1] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - CALLBACK IS RUNNING
2023-03-04 00:49:50 [SpringApplicationShutdownHook] DEBUG o.s.b.a.ApplicationAvailabilityBean - Application availability state ReadinessState changed from ACCEPTING_TRAFFIC to REFUSING_TRAFFIC
2023-03-04 00:49:50 [SpringApplicationShutdownHook] DEBUG o.s.b.w.r.c.AnnotationConfigReactiveWebServerApplicationContext - Closing org.springframework.boot.web.reactive.context.AnnotationConfigReactiveWebServerApplicationContext@15cafec7, started on Sat Mar 04 00:21:19 IRST 2023
2023-03-04 00:49:50 [SpringApplicationShutdownHook] DEBUG o.s.c.s.DefaultLifecycleProcessor - Stopping beans in phase 2147483547
2023-03-04 00:49:50 [SpringApplicationShutdownHook] DEBUG o.s.c.s.DefaultLifecycleProcessor - Bean 'org.springframework.kafka.config.internalKafkaListenerEndpointRegistry' completed its stop procedure
2023-03-04 00:49:50 [SpringApplicationShutdownHook] DEBUG o.s.c.s.DefaultLifecycleProcessor - Stopping beans in phase 2147482623
2023-03-04 00:49:50 [SpringApplicationShutdownHook] DEBUG o.s.c.s.DefaultLifecycleProcessor - Bean 'webServerGracefulShutdown' completed its stop procedure
2023-03-04 00:49:50 [SpringApplicationShutdownHook] DEBUG o.s.c.s.DefaultLifecycleProcessor - Stopping beans in phase 2147481599
2023-03-04 00:49:50 [SpringApplicationShutdownHook] DEBUG o.s.c.s.DefaultLifecycleProcessor - Bean 'webServerStartStop' completed its stop procedure
2023-03-04 00:49:50 [SpringApplicationShutdownHook] DEBUG o.s.c.s.DefaultLifecycleProcessor - Stopping beans in phase -2147483647
2023-03-04 00:49:50 [SpringApplicationShutdownHook] DEBUG o.s.c.s.DefaultLifecycleProcessor - Bean 'springBootLoggingLifecycle' completed its stop procedure
2023-03-04 00:49:50 [SpringApplicationShutdownHook] DEBUG o.s.j.e.a.AnnotationMBeanExporter - Unregistering JMX-exposed beans on shutdown
2023-03-04 00:49:50 [SpringApplicationShutdownHook] INFO  x.g.m.d.k.p.s.i.TwitterKafkaProducer - Closing kafka producer!
2023-03-04 00:49:50 [SpringApplicationShutdownHook] INFO  o.a.k.clients.producer.KafkaProducer - [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 30000 ms.
2023-03-04 00:49:50 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Beginning shutdown of Kafka producer I/O thread, sending remaining records.
2023-03-04 00:49:50 [kafka-producer-network-thread | producer-1] DEBUG o.a.k.c.producer.internals.Sender - [Producer clientId=producer-1] Shutdown of Kafka producer I/O thread has completed.
2023-03-04 00:49:50 [SpringApplicationShutdownHook] INFO  o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2023-03-04 00:49:50 [SpringApplicationShutdownHook] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2023-03-04 00:49:50 [SpringApplicationShutdownHook] INFO  o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2023-03-04 00:49:50 [SpringApplicationShutdownHook] INFO  o.a.kafka.common.utils.AppInfoParser - App info kafka.producer for producer-1 unregistered
2023-03-04 00:49:50 [SpringApplicationShutdownHook] DEBUG o.a.k.clients.producer.KafkaProducer - [Producer clientId=producer-1] Kafka producer has been closed
2023-03-04 00:49:50 [SpringApplicationShutdownHook] DEBUG o.a.k.clients.admin.KafkaAdminClient - [AdminClient clientId=adminclient-1] Initiating close operation.
2023-03-04 00:49:50 [SpringApplicationShutdownHook] DEBUG o.a.k.clients.admin.KafkaAdminClient - [AdminClient clientId=adminclient-1] Waiting for the I/O thread to exit. Hard shutdown in 31535999999 ms.
2023-03-04 00:49:50 [kafka-admin-client-thread | adminclient-1] INFO  o.a.kafka.common.utils.AppInfoParser - App info kafka.admin.client for adminclient-1 unregistered
2023-03-04 00:49:50 [kafka-admin-client-thread | adminclient-1] INFO  o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2023-03-04 00:49:50 [kafka-admin-client-thread | adminclient-1] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2023-03-04 00:49:50 [kafka-admin-client-thread | adminclient-1] INFO  o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2023-03-04 00:49:50 [kafka-admin-client-thread | adminclient-1] DEBUG o.a.k.clients.admin.KafkaAdminClient - [AdminClient clientId=adminclient-1] Exiting AdminClientRunnable thread.
2023-03-04 00:49:50 [SpringApplicationShutdownHook] DEBUG o.a.k.clients.admin.KafkaAdminClient - [AdminClient clientId=adminclient-1] Kafka admin client closed.
2023-03-04 00:49:52 [reactor-http-nio-3] DEBUG io.netty.buffer.PoolThreadCache - Freed 2 thread-local buffer(s) from thread: reactor-http-nio-3
